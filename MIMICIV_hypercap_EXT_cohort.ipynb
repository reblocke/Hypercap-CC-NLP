{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab24b37",
   "metadata": {},
   "source": [
    "\n",
    "# MIMIC‑IV Hypercapnia Cohort — **ICD ∪ Physiologic Thresholds** (BigQuery)\n",
    "\n",
    "TODO: \n",
    "\n",
    "[ ] want to add comorbidity data (any codes)\n",
    "\n",
    "[ ] want to add ED-rendered diagnoses\n",
    "\n",
    "[ ] want to see if we can pull info on potential causative diagnoses rendered when making this data-set\n",
    "\n",
    "\n",
    "**Goal:** Build an admissions‑level tabular dataset that **enrolls** any hospital admission (`hadm_id`) meeting **_any_** of:\n",
    "\n",
    "1. **ICD** codes for hypercapnic respiratory failure (legacy cohort).\n",
    "2. **Any arterial blood gas** (LAB or POC) with **PaCO₂ ≥ 45.0 mmHg** anywhere during the episode.\n",
    "3. **Any venous blood gas** (LAB or POC) with **PaCO₂ ≥ 50.0 mmHg** anywhere during the episode.\n",
    "\n",
    "Then, keep all downstream columns/logic from the current workflow:\n",
    "- Per‑code ICD indicators and an `any_hypercap_icd` flag.\n",
    "- Robust extraction of **first ABG** and **first VBG** (across LAB + POC) with standardized units (mmHg) and pairing logic.\n",
    "- Demographics/outcomes, NIH/OMB race & ethnicity, ED triage + first ED vitals, ICU meta (first stay + LOS), ventilation flags.\n",
    "- Sanity checks.\n",
    "\n",
    "> **Assumptions**\n",
    "> - You already configured BigQuery auth (`gcloud auth application-default login`) and `.env` variables as in the previous notebook.\n",
    "> - The PhysioNet hosting project is `physionet-data`.\n",
    "> - Datasets exist (e.g., `mimiciv_3_1_hosp`, `mimiciv_3_1_icu`, and an ED dataset such as `mimiciv_ed`). This notebook auto-detects the ED dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c264b",
   "metadata": {},
   "source": [
    "**Execution timing note:** To capture per-cell runtimes, enable cell execution timing in VS Code (Notebook: Show Cell Execution Time) or enable ExecuteTime in Jupyter. Then re-run and save to allow runtime summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd99a86",
   "metadata": {},
   "source": [
    "## Pipeline stages (readable map)\n",
    "1. **Stage A — Config & helpers**: dataset IDs, thresholds, shared helper functions.\n",
    "2. **Stage B — Cohort spine**: ICD + gas thresholds → `hadm_list` / `ed_stay_list`.\n",
    "3. **Stage C — Bulk pulls**: one query per table where possible.\n",
    "4. **Stage D — Transforms**: panels, flags, timing, comorbidities, vitals.\n",
    "5. **Stage E — QA checks**: deterministic assertions and range checks.\n",
    "6. **Stage F — Outputs**: parquet + Excel exports.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceac90f",
   "metadata": {},
   "source": [
    "## SQL registry (centralized query templates)\n",
    "All BigQuery SQL is defined in one place below, then referenced by name in subsequent cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854e25ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:17.787862Z",
     "iopub.status.busy": "2026-02-04T23:25:17.787570Z",
     "iopub.status.idle": "2026-02-04T23:25:17.796239Z",
     "shell.execute_reply": "2026-02-04T23:25:17.795905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# Central SQL registry (define all query templates here)\n",
    "SQL = {}\n",
    "\n",
    "def sql(name: str) -> str:\n",
    "    if name not in SQL:\n",
    "        raise KeyError(f\"SQL template not found: {name}\")\n",
    "    return SQL[name]\n",
    "\n",
    "# SQL templates (populated below in-place to keep notebook linear)\n",
    "# Names: admit_sql, co2_thresholds_sql, cohort_icd_sql, counts_sql, demo_sql, ditems_sql, ed_counts_sql, ed_first_vitals_sql, ed_spine_sql, ed_to_icu_sql, ed_triage_sql, ed_vitals_sql, icd_sql, icu_meta_sql, icu_sql, labitems_sql, labs_sql, vent_chart_sql, vent_sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3127a0f",
   "metadata": {},
   "source": [
    "**Rationale:** Define a reproducible, admission-level cohort that captures hypercapnia using complementary diagnostic (ICD) and physiologic (blood gas) criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1731fe",
   "metadata": {},
   "source": [
    "# MIMIC‑IV on BigQuery\n",
    "\n",
    "## Environment Bootstrap & Smoke Test\n",
    "\n",
    "Purpose: make a clean, reproducible start on a new machine.\n",
    "\n",
    "Outcome: verify auth, project config, and dataset access; provide a reusable BigQuery runner for the build notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a73e95",
   "metadata": {},
   "source": [
    "**Rationale:** Establish the BigQuery environment and dataset configuration so queries are consistent and reproducible across runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8408759",
   "metadata": {},
   "source": [
    "## 0. Prerequisites (one-time)\n",
    "\n",
    "**Accounts & access**\n",
    "- PhysioNet access to MIMIC-IV on BigQuery; in BigQuery Console star project `physionet-data`.\n",
    "- A Google Cloud **Project ID** with BigQuery API enabled (this is your **billing** project).\n",
    "\n",
    "**CLI & environment**\n",
    "- Google Cloud SDK (gcloud) installed and on PATH.\n",
    "- Python environment created with `uv` (see README) and Jupyter kernel selected.\n",
    "- A project-local **`.env`** with the variables below.\n",
    "\n",
    "**.env variables**\n",
    "```ini\n",
    "MIMIC_BACKEND=bigquery\n",
    "WORK_PROJECT=<your-billing-project-id>\n",
    "BQ_PHYSIONET_PROJECT=physionet-data\n",
    "BQ_DATASET_HOSP=mimiciv_3_1_hosp\n",
    "BQ_DATASET_ICU=mimiciv_3_1_icu\n",
    "BQ_DATASET_ED=mimiciv_ed\n",
    "WORK_DIR=/path/to/Hypercap-CC-NLP\n",
    "# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json\n",
    "```\n",
    "\n",
    "**Command line quickstart**\n",
    "```bash\n",
    "brew install --cask google-cloud-sdk\n",
    "gcloud init\n",
    "gcloud auth application-default login\n",
    "gcloud services enable bigquery.googleapis.com --project <your-billing-project-id>\n",
    "ls -l ~/.config/gcloud/application_default_credentials.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2adf93",
   "metadata": {},
   "source": [
    "**Rationale:** Verify access and credentials up front to prevent silent failures later in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf7fc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:17.798480Z",
     "iopub.status.busy": "2026-02-04T23:25:17.798318Z",
     "iopub.status.idle": "2026-02-04T23:25:19.888883Z",
     "shell.execute_reply": "2026-02-04T23:25:19.888472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: mimic-hypercapnia\n",
      "PhysioNet host: physionet-data\n",
      "HOSP: mimiciv_3_1_hosp ICU: mimiciv_3_1_icu ED (pref): mimiciv_ed\n",
      "WORK_DIR: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP\n"
     ]
    }
   ],
   "source": [
    "# --- Imports & environment\n",
    "import os, re, json, math, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "WORK_DIR = Path(os.getenv(\"WORK_DIR\", Path.cwd())).expanduser().resolve()\n",
    "DATA_DIR = WORK_DIR / \"MIMIC tabular data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Backend selection (we use BigQuery)\n",
    "BACKEND = os.getenv(\"MIMIC_BACKEND\", \"bigquery\").strip().lower()\n",
    "assert BACKEND == \"bigquery\", \"This notebook is BigQuery-specific.\"\n",
    "\n",
    "WORK_PROJECT = os.getenv(\"WORK_PROJECT\", \"\").strip()  # your billing project\n",
    "PHYS = os.getenv(\"BQ_PHYSIONET_PROJECT\", \"physionet-data\").strip()  # hosting project (read-only)\n",
    "\n",
    "# Default to MIMIC-IV v3.1 datasets\n",
    "HOSP = os.getenv(\"BQ_DATASET_HOSP\", \"mimiciv_3_1_hosp\").strip()\n",
    "ICU  = os.getenv(\"BQ_DATASET_ICU\",  \"mimiciv_3_1_icu\").strip()\n",
    "ED   = os.getenv(\"BQ_DATASET_ED\",   \"\").strip()  # may be empty; we will auto-detect\n",
    "\n",
    "# BigQuery client\n",
    "client = bigquery.Client(project=WORK_PROJECT)\n",
    "\n",
    "print(\"Project:\", WORK_PROJECT)\n",
    "print(\"PhysioNet host:\", PHYS)\n",
    "print(\"HOSP:\", HOSP, \"ICU:\", ICU, \"ED (pref):\", ED)\n",
    "print(\"WORK_DIR:\", WORK_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a0b813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:19.890782Z",
     "iopub.status.busy": "2026-02-04T23:25:19.890509Z",
     "iopub.status.idle": "2026-02-04T23:25:19.895206Z",
     "shell.execute_reply": "2026-02-04T23:25:19.894975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ED dataset: mimiciv_ed\n"
     ]
    }
   ],
   "source": [
    "# --- Helper: run SQL with optional named parameters\n",
    "def run_sql_bq(sql: str, params: dict | None = None) -> pd.DataFrame:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    if params:\n",
    "        bq_params = []\n",
    "        for k, v in params.items():\n",
    "            if isinstance(v, (list, tuple, np.ndarray, pd.Series)):\n",
    "                # BigQuery ARRAY<INT64> if all ints; else ARRAY<STRING>\n",
    "                v_list = list(v)\n",
    "                if all(isinstance(x, (int, np.integer)) for x in v_list):\n",
    "                    bq_params.append(bigquery.ArrayQueryParameter(k, \"INT64\", list(map(int, v_list))))\n",
    "                else:\n",
    "                    bq_params.append(bigquery.ArrayQueryParameter(k, \"STRING\", list(map(str, v_list))))\n",
    "            else:\n",
    "                # scalar\n",
    "                if isinstance(v, (int, np.integer)):\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(k, \"INT64\", int(v)))\n",
    "                elif isinstance(v, float):\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(k, \"FLOAT64\", float(v)))\n",
    "                else:\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(k, \"STRING\", str(v)))\n",
    "        job_config.query_parameters = bq_params\n",
    "    job = client.query(sql, job_config=job_config)\n",
    "    try:\n",
    "        return job.result().to_dataframe(create_bqstorage_client=True)\n",
    "    except TypeError:\n",
    "        return job.result().to_dataframe()\n",
    "\n",
    "# --- Helper: test if a fully-qualified table exists and is accessible\n",
    "def table_exists(fqtn: str) -> bool:\n",
    "    try:\n",
    "        _ = run_sql_bq(f\"SELECT 1 FROM `{fqtn}` LIMIT 1\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# --- Auto-detect ED dataset if not set\n",
    "if not ED:\n",
    "    candidates = [\n",
    "        f\"{PHYS}.mimiciv_ed.edstays\",\n",
    "        f\"{PHYS}.mimiciv_3_1_ed.edstays\",\n",
    "    ]\n",
    "    for cand in candidates:\n",
    "        if table_exists(cand):\n",
    "            ED = cand.split(\".\")[1]  # dataset\n",
    "            break\n",
    "if not ED:\n",
    "    raise RuntimeError(\"No accessible ED dataset found. Request access to MIMIC-IV-ED in PhysioNet (BigQuery).\")\n",
    "\n",
    "print(\"Using ED dataset:\", ED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d112076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:19.896324Z",
     "iopub.status.busy": "2026-02-04T23:25:19.896239Z",
     "iopub.status.idle": "2026-02-04T23:25:19.899444Z",
     "shell.execute_reply": "2026-02-04T23:25:19.899227Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Helper utilities for reproducibility and safe joins\n",
    "def require_cols(df: pd.DataFrame, cols: list[str], name: str) -> None:\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"{name} missing columns: {missing}\")\n",
    "\n",
    "def assert_unique(df: pd.DataFrame, key: str, name: str) -> None:\n",
    "    if df[key].duplicated().any():\n",
    "        n = int(df[key].duplicated().sum())\n",
    "        raise ValueError(f\"{name} has {n} duplicate {key} values\")\n",
    "\n",
    "def safe_merge(left: pd.DataFrame, right: pd.DataFrame, on: list[str] | str, how: str, name: str) -> pd.DataFrame:\n",
    "    # guard against accidental duplicate columns\n",
    "    overlap = set(left.columns) & set(right.columns)\n",
    "    if isinstance(on, str):\n",
    "        on_cols = {on}\n",
    "    else:\n",
    "        on_cols = set(on)\n",
    "    overlap = overlap - on_cols\n",
    "    if overlap:\n",
    "        raise ValueError(f\"{name} merge would duplicate columns: {sorted(overlap)}\")\n",
    "    return left.merge(right, on=on, how=how)\n",
    "\n",
    "def check_ranges(df: pd.DataFrame, ranges: dict[str, tuple[float, float]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for col, (lo, hi) in ranges.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        bad = df[col].notna() & ((df[col] < lo) | (df[col] > hi))\n",
    "        rows.append({\"col\": col, \"n_bad\": int(bad.sum())})\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a51c8",
   "metadata": {},
   "source": [
    "## 1) ICD cohort flags (hypercapnic respiratory failure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8291e",
   "metadata": {},
   "source": [
    "**Rationale:** Capture diagnosis-based hypercapnia from ED and hospital discharge codes to define a broad, clinically recognized cohort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3507bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:19.900991Z",
     "iopub.status.busy": "2026-02-04T23:25:19.900916Z",
     "iopub.status.idle": "2026-02-04T23:25:22.560535Z",
     "shell.execute_reply": "2026-02-04T23:25:22.560284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD cohort admissions: 4237\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9602",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9612",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9622",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9692",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_E662",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD9_27803",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_hosp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_ed",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "icd_source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5263d9b0-77b2-4dc3-93a7-02e9549f15ce",
       "rows": [
        [
         "0",
         "10485425",
         "21207827",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "HOSP"
        ],
        [
         "1",
         "16826447",
         "21830147",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "HOSP"
        ],
        [
         "2",
         "11482582",
         "22869017",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "1",
         "0",
         "HOSP"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>ICD10_J9602</th>\n",
       "      <th>ICD10_J9612</th>\n",
       "      <th>ICD10_J9622</th>\n",
       "      <th>ICD10_J9692</th>\n",
       "      <th>ICD10_E662</th>\n",
       "      <th>ICD9_27803</th>\n",
       "      <th>any_hypercap_icd</th>\n",
       "      <th>any_hypercap_icd_hosp</th>\n",
       "      <th>any_hypercap_icd_ed</th>\n",
       "      <th>icd_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10485425</td>\n",
       "      <td>21207827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16826447</td>\n",
       "      <td>21830147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11482582</td>\n",
       "      <td>22869017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  ICD10_J9602  ICD10_J9612  ICD10_J9622  ICD10_J9692  \\\n",
       "0    10485425  21207827            0            0            1            0   \n",
       "1    16826447  21830147            0            1            0            0   \n",
       "2    11482582  22869017            0            0            0            0   \n",
       "\n",
       "   ICD10_E662  ICD9_27803  any_hypercap_icd  any_hypercap_icd_hosp  \\\n",
       "0           1           0                 1                      1   \n",
       "1           1           0                 1                      1   \n",
       "2           0           1                 1                      1   \n",
       "\n",
       "   any_hypercap_icd_ed icd_source  \n",
       "0                    0       HOSP  \n",
       "1                    0       HOSP  \n",
       "2                    0       HOSP  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target ICD codes (dotless, uppercase)\n",
    "ICD10_CODES = ['J9602','J9612','J9622','J9692','E662']\n",
    "ICD9_CODES  = ['27803']\n",
    "\n",
    "SQL[\"cohort_icd_sql\"] = f\"\"\"\n",
    "-- ICD-based cohort flags per admission\n",
    "WITH target_codes AS (\n",
    "  SELECT 'J9602' AS code, 10 AS ver UNION ALL\n",
    "  SELECT 'J9612', 10 UNION ALL\n",
    "  SELECT 'J9622', 10 UNION ALL\n",
    "  SELECT 'J9692', 10 UNION ALL\n",
    "  SELECT 'E662',  10 UNION ALL\n",
    "  SELECT '27803', 9\n",
    "),\n",
    "\n",
    "-- Hospital ICDs restricted to target codes\n",
    "hosp_dx AS (\n",
    "  SELECT\n",
    "    d.subject_id,\n",
    "    d.hadm_id,\n",
    "    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,\n",
    "    d.icd_version\n",
    "  FROM `{PHYS}.{HOSP}.diagnoses_icd` d\n",
    "  JOIN target_codes t\n",
    "    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))\n",
    "  WHERE d.hadm_id IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Hospital flags per admission\n",
    "hosp_flags AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,\n",
    "    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,\n",
    "    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803\n",
    "  FROM hosp_dx\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- ED ICDs restricted to target codes (map to hadm via edstays)\n",
    "ed_dx AS (\n",
    "  SELECT\n",
    "    s.subject_id,\n",
    "    s.hadm_id,\n",
    "    s.stay_id,\n",
    "    s.intime AS ed_intime,\n",
    "    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,\n",
    "    d.icd_version\n",
    "  FROM `{PHYS}.{ED}.diagnosis` d\n",
    "  JOIN `{PHYS}.{ED}.edstays` s\n",
    "    ON s.subject_id = d.subject_id AND s.stay_id = d.stay_id\n",
    "  JOIN target_codes t\n",
    "    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))\n",
    "  WHERE s.hadm_id IS NOT NULL\n",
    "),\n",
    "\n",
    "-- ED flags per ED stay (so we can both: OR flags across stays and also pick earliest stay_id)\n",
    "ed_flags_by_stay AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id, stay_id, MIN(ed_intime) AS ed_intime,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,\n",
    "    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,\n",
    "    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803\n",
    "  FROM ed_dx\n",
    "  GROUP BY subject_id, hadm_id, stay_id\n",
    "),\n",
    "\n",
    "-- OR the ED flags across all ED stays mapped to the same hadm\n",
    "ed_flags_or AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id,\n",
    "    MAX(ICD10_J9602) AS ICD10_J9602,\n",
    "    MAX(ICD10_J9612) AS ICD10_J9612,\n",
    "    MAX(ICD10_J9622) AS ICD10_J9622,\n",
    "    MAX(ICD10_J9692) AS ICD10_J9692,\n",
    "    MAX(ICD10_E662 ) AS ICD10_E662,\n",
    "    MAX(ICD9_27803) AS ICD9_27803\n",
    "  FROM ed_flags_by_stay\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- Earliest ED stay_id per hadm (NO UNNEST of aggregates; use [OFFSET(0)])\n",
    "ed_earliest AS (\n",
    "  SELECT\n",
    "    subject_id,\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(stay_id, ed_intime) ORDER BY ed_intime LIMIT 1))[OFFSET(0)].stay_id AS stay_id\n",
    "  FROM ed_flags_by_stay\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- Bring flags and earliest stay_id together\n",
    "ed_by_hadm AS (\n",
    "  SELECT\n",
    "    f.subject_id,\n",
    "    f.hadm_id,\n",
    "    e.stay_id,\n",
    "    f.ICD10_J9602,\n",
    "    f.ICD10_J9612,\n",
    "    f.ICD10_J9622,\n",
    "    f.ICD10_J9692,\n",
    "    f.ICD10_E662,\n",
    "    f.ICD9_27803\n",
    "  FROM ed_flags_or f\n",
    "  LEFT JOIN ed_earliest e\n",
    "    USING (subject_id, hadm_id)\n",
    "),\n",
    "\n",
    "-- Combine ED and hospital flags at the admission level\n",
    "combined AS (\n",
    "  SELECT\n",
    "    COALESCE(h.subject_id, e.subject_id) AS subject_id,\n",
    "    COALESCE(h.hadm_id,     e.hadm_id)   AS hadm_id,\n",
    "    GREATEST(IFNULL(h.ICD10_J9602,0), IFNULL(e.ICD10_J9602,0)) AS ICD10_J9602,\n",
    "    GREATEST(IFNULL(h.ICD10_J9612,0), IFNULL(e.ICD10_J9612,0)) AS ICD10_J9612,\n",
    "    GREATEST(IFNULL(h.ICD10_J9622,0), IFNULL(e.ICD10_J9622,0)) AS ICD10_J9622,\n",
    "    GREATEST(IFNULL(h.ICD10_J9692,0), IFNULL(e.ICD10_J9692,0)) AS ICD10_J9692,\n",
    "    GREATEST(IFNULL(h.ICD10_E662 ,0), IFNULL(e.ICD10_E662 ,0)) AS ICD10_E662,\n",
    "    GREATEST(IFNULL(h.ICD9_27803,0), IFNULL(e.ICD9_27803,0)) AS ICD9_27803,\n",
    "    IF((IFNULL(h.ICD10_J9602,0)+IFNULL(h.ICD10_J9612,0)+IFNULL(h.ICD10_J9622,0)+IFNULL(h.ICD10_J9692,0)+IFNULL(h.ICD10_E662,0)+IFNULL(h.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_hosp,\n",
    "    IF((IFNULL(e.ICD10_J9602,0)+IFNULL(e.ICD10_J9612,0)+IFNULL(e.ICD10_J9622,0)+IFNULL(e.ICD10_J9692,0)+IFNULL(e.ICD10_E662,0)+IFNULL(e.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_ed\n",
    "  FROM hosp_flags h\n",
    "  FULL OUTER JOIN ed_by_hadm e\n",
    "    ON h.hadm_id = e.hadm_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  subject_id, hadm_id,\n",
    "  ICD10_J9602, ICD10_J9612, ICD10_J9622, ICD10_J9692, ICD10_E662, ICD9_27803,\n",
    "  IF((ICD10_J9602+ICD10_J9612+ICD10_J9622+ICD10_J9692+ICD10_E662+ICD9_27803) > 0, 1, 0) AS any_hypercap_icd,\n",
    "  any_hypercap_icd_hosp,\n",
    "  any_hypercap_icd_ed,\n",
    "  CASE\n",
    "    WHEN any_hypercap_icd_hosp=1 AND any_hypercap_icd_ed=1 THEN 'ED+HOSP'\n",
    "    WHEN any_hypercap_icd_ed=1 THEN 'ED'\n",
    "    WHEN any_hypercap_icd_hosp=1 THEN 'HOSP'\n",
    "    ELSE 'NONE'\n",
    "  END AS icd_source\n",
    "FROM combined\n",
    "\"\"\"\n",
    "\n",
    "cohort_icd = run_sql_bq(sql(\"cohort_icd_sql\"))\n",
    "print(\"ICD cohort admissions:\", len(cohort_icd))\n",
    "cohort_icd.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29e962",
   "metadata": {},
   "source": [
    "## 2) Blood gas inclusion thresholds — ANY PaCO₂ meeting cutoffs (LAB + POC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b779a",
   "metadata": {},
   "source": [
    "**Rationale:** Identify physiologic hypercapnia using ABG/VBG thresholds, independent of diagnostic coding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb134f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:22.565065Z",
     "iopub.status.busy": "2026-02-04T23:25:22.564828Z",
     "iopub.status.idle": "2026-02-04T23:25:24.826810Z",
     "shell.execute_reply": "2026-02-04T23:25:24.826225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions meeting thresholds: 52715\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "abg_hypercap_threshold",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "vbg_hypercap_threshold",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "f617831b-52e9-4cb5-ba55-d628b2c7d973",
       "rows": [
        [
         "0",
         "26892251",
         "0",
         "0"
        ],
        [
         "1",
         "21943565",
         "0",
         "0"
        ],
        [
         "2",
         "27109430",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>abg_hypercap_threshold</th>\n",
       "      <th>vbg_hypercap_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26892251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21943565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27109430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  abg_hypercap_threshold  vbg_hypercap_threshold\n",
       "0  26892251                       0                       0\n",
       "1  21943565                       0                       0\n",
       "2  27109430                       0                       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL[\"co2_thresholds_sql\"] = f\"\"\"\n",
    "/* ---- LAB (HOSP) pCO2 across entire dataset ---- */\n",
    "WITH hosp_cand AS (\n",
    "  SELECT\n",
    "    le.hadm_id, le.charttime, le.specimen_id,\n",
    "    COALESCE(\n",
    "      CAST(le.valuenum AS FLOAT64),\n",
    "      SAFE_CAST(REGEXP_EXTRACT(LOWER(le.value), r'(-?\\d+(?:\\.\\d+)?)') AS FLOAT64)\n",
    "    ) AS val,\n",
    "    LOWER(REPLACE(COALESCE(le.valueuom,''),' ','')) AS uom_nospace,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(COALESCE(di.fluid,'')) AS fl\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE (le.valuenum IS NOT NULL OR le.value IS NOT NULL)\n",
    "    AND (\n",
    "      LOWER(COALESCE(di.category,'')) LIKE '%blood gas%' OR\n",
    "      LOWER(di.label) LIKE '%pco2%' OR\n",
    "      REGEXP_CONTAINS(LOWER(di.label), r'\\bpa?\\s*co(?:2|₂)\\b')\n",
    "    )\n",
    "    AND NOT REGEXP_CONTAINS(LOWER(di.label),\n",
    "        r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar)')\n",
    "),\n",
    "hosp_spec AS (\n",
    "  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE le.specimen_id IS NOT NULL\n",
    "    AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')\n",
    "),\n",
    "hosp_pco2 AS (\n",
    "  SELECT\n",
    "    c.hadm_id, c.charttime,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\\bart\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'\n",
    "      WHEN REGEXP_CONTAINS(c.fl, r'arter') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(c.fl, r'ven') THEN 'venous'\n",
    "      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\\b(abg|art|arterial|a[- ]?line)\\b') THEN 'arterial'\n",
    "      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\\b(vbg|ven|venous|mixed|central)\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site,\n",
    "    CASE WHEN c.uom_nospace='kpa' THEN c.val*7.50062 ELSE c.val END AS pco2_mmHg\n",
    "  FROM hosp_cand c\n",
    "  LEFT JOIN hosp_spec s USING (specimen_id)\n",
    "  WHERE c.val IS NOT NULL\n",
    "),\n",
    "hosp_pco2_std AS (\n",
    "  SELECT hadm_id, site, charttime, pco2_mmHg\n",
    "  FROM hosp_pco2\n",
    "  WHERE site IN ('arterial','venous') AND pco2_mmHg BETWEEN 5 AND 200\n",
    "),\n",
    "\n",
    "/* ---- ICU (POC) pCO2 across entire dataset ---- */\n",
    "icu_raw AS (\n",
    "  SELECT\n",
    "    ie.hadm_id,\n",
    "    ce.stay_id,\n",
    "    ce.charttime,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(REPLACE(COALESCE(ce.valueuom,''),' ','')) AS uom_nospace,\n",
    "    LOWER(COALESCE(ce.value,'')) AS valstr,\n",
    "    COALESCE(\n",
    "      CAST(ce.valuenum AS FLOAT64),\n",
    "      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r'(-?\\d+(?:\\.\\d+)?)') AS FLOAT64)\n",
    "    ) AS val\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n",
    "  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n",
    "),\n",
    "icu_cand AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,\n",
    "    CASE\n",
    "      WHEN (\n",
    "            REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)')\n",
    "            OR uom_nospace IN ('mmhg','kpa')\n",
    "            OR REGEXP_CONTAINS(valstr, r'\\b(mm\\s*hg|kpa)\\b')\n",
    "           )\n",
    "           AND NOT REGEXP_CONTAINS(lbl,\n",
    "               r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))')\n",
    "      THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\b(abg|art|arterial|a[- ]?line)\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\b(vbg|ven|venous|mixed|central)\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM icu_raw\n",
    "  WHERE val IS NOT NULL\n",
    "    AND (\n",
    "      REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)')\n",
    "      OR uom_nospace IN ('mmhg','kpa')\n",
    "      OR REGEXP_CONTAINS(valstr, r'\\b(mm\\s*hg|kpa)\\b')\n",
    "    )\n",
    "    AND NOT REGEXP_CONTAINS(lbl,\n",
    "        r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))')\n",
    "),\n",
    "icu_co2_std AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    site,\n",
    "    charttime,\n",
    "    CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\\bkpa\\b') THEN val*7.50062 ELSE val END AS pco2_mmHg\n",
    "  FROM icu_cand\n",
    "  WHERE analyte='pco2' AND site IN ('arterial','venous') AND val BETWEEN 5 AND 200\n",
    "),\n",
    "\n",
    "/* ---- Combine and threshold per admission ---- */\n",
    "all_pco2 AS (\n",
    "  SELECT * FROM hosp_pco2_std\n",
    "  UNION ALL\n",
    "  SELECT * FROM icu_co2_std\n",
    "),\n",
    "thresh AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    MAX(IF(site='arterial' AND pco2_mmHg >= 45.0, 1, 0)) AS abg_hypercap_threshold,\n",
    "    MAX(IF(site='venous'   AND pco2_mmHg >= 50.0, 1, 0)) AS vbg_hypercap_threshold\n",
    "  FROM all_pco2\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "SELECT * FROM thresh\n",
    "\"\"\"\n",
    "\n",
    "co2_thresh = run_sql_bq(sql(\"co2_thresholds_sql\"))\n",
    "print(\"Admissions meeting thresholds:\", len(co2_thresh))\n",
    "co2_thresh.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d0066",
   "metadata": {},
   "source": [
    "## 3) Cohort union (ICD ∪ thresholds) and `hadm_list` for downstream queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73cdc3",
   "metadata": {},
   "source": [
    "**Rationale:** Combine ICD and physiologic routes to maximize sensitivity, then define a stable hadm_id list for downstream joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db1a7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:24.830803Z",
     "iopub.status.busy": "2026-02-04T23:25:24.830485Z",
     "iopub.status.idle": "2026-02-04T23:25:24.873745Z",
     "shell.execute_reply": "2026-02-04T23:25:24.873482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD-only admissions        : 4237\n",
      "Threshold-only admissions  : 35915\n",
      "Both ICD and threshold     : 3102\n",
      "Total enrolled (union)     : 40152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40151"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outer-join because thresholds can identify hadm_id with no ICD codes and vice versa\n",
    "cohort_any = cohort_icd.merge(co2_thresh, how=\"outer\", on=\"hadm_id\")\n",
    "\n",
    "# Fill missing flags with 0 where appropriate\n",
    "icd_cols = [\"ICD10_J9602\",\"ICD10_J9612\",\"ICD10_J9622\",\"ICD10_J9692\",\"ICD10_E662\",\"ICD9_27803\",\"any_hypercap_icd\",\"any_hypercap_icd_hosp\",\"any_hypercap_icd_ed\"]\n",
    "for c in icd_cols:\n",
    "    if c in cohort_any.columns:\n",
    "        cohort_any[c] = cohort_any[c].fillna(0).astype(int)\n",
    "\n",
    "for c in [\"abg_hypercap_threshold\",\"vbg_hypercap_threshold\"]:\n",
    "    if c in cohort_any.columns:\n",
    "        cohort_any[c] = cohort_any[c].fillna(0).astype(int)\n",
    "\n",
    "# Final enrollment flag\n",
    "cohort_any[\"pco2_threshold_any\"] = ((cohort_any[\"abg_hypercap_threshold\"]==1) | (cohort_any[\"vbg_hypercap_threshold\"]==1)).astype(int)\n",
    "cohort_any[\"enrolled_any\"] = ((cohort_any[\"any_hypercap_icd\"]==1) | (cohort_any[\"pco2_threshold_any\"]==1)).astype(int)\n",
    "\n",
    "print(\"ICD-only admissions        :\", int((cohort_any[\"any_hypercap_icd\"]==1).sum()))\n",
    "print(\"Threshold-only admissions  :\", int(((cohort_any[\"pco2_threshold_any\"]==1) & (cohort_any[\"any_hypercap_icd\"]==0)).sum()))\n",
    "print(\"Both ICD and threshold     :\", int(((cohort_any[\"pco2_threshold_any\"]==1) & (cohort_any[\"any_hypercap_icd\"]==1)).sum()))\n",
    "print(\"Total enrolled (union)     :\", int((cohort_any[\"enrolled_any\"]==1).sum()))\n",
    "\n",
    "# New hadm list used for the rest of the notebook\n",
    "hadm_list = cohort_any.loc[cohort_any[\"enrolled_any\"]==1, \"hadm_id\"].dropna().astype(\"int64\").tolist()\n",
    "len(hadm_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe110d70",
   "metadata": {},
   "source": [
    "## 4) First ABG and First VBG (LAB + POC, standardized to mmHg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd25d61",
   "metadata": {},
   "source": [
    "**Rationale:** Extract earliest ABG/VBG measurements to characterize baseline physiology with standardized units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d61ad70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:24.875538Z",
     "iopub.status.busy": "2026-02-04T23:25:24.875393Z",
     "iopub.status.idle": "2026-02-04T23:25:30.214624Z",
     "shell.execute_reply": "2026-02-04T23:25:30.214082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "lab_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "lab_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_ph_uom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lab_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_paco2_uom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lab_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "first_abg_src",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_abg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_abg_pco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_src",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "first_vbg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_pco2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6209b359-1c2b-4044-8df9-0b7cf16c4d2b",
       "rows": [
        [
         "0",
         "20000094",
         null,
         null,
         null,
         null,
         null,
         "7.41",
         "units",
         "47.0",
         "mmhg",
         "2150-03-02 15:53:00",
         null,
         null,
         null,
         null,
         null,
         "7.36",
         null,
         "38.0",
         "mmhg",
         "2150-03-02 22:05:00",
         null,
         null,
         null,
         null,
         "LAB",
         "2150-03-02 15:53:00",
         "7.41",
         "47.0"
        ],
        [
         "1",
         "20000694",
         null,
         null,
         null,
         null,
         null,
         "7.29",
         "units",
         "43.0",
         "mmhg",
         "2144-09-01 05:15:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "LAB",
         "2144-09-01 05:15:00",
         "7.29",
         "43.0"
        ],
        [
         "2",
         "20001305",
         null,
         null,
         null,
         null,
         null,
         "7.29",
         "units",
         "77.0",
         "mmhg",
         "2178-03-25 04:28:00",
         null,
         null,
         null,
         null,
         null,
         "7.29",
         null,
         "34.0",
         "mmhg",
         "2178-03-25 04:28:00",
         null,
         null,
         null,
         null,
         "LAB",
         "2178-03-25 04:28:00",
         "7.29",
         "77.0"
        ]
       ],
       "shape": {
        "columns": 29,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>lab_abg_ph</th>\n",
       "      <th>lab_abg_ph_uom</th>\n",
       "      <th>lab_abg_paco2</th>\n",
       "      <th>lab_abg_paco2_uom</th>\n",
       "      <th>lab_abg_time</th>\n",
       "      <th>lab_vbg_ph</th>\n",
       "      <th>lab_vbg_ph_uom</th>\n",
       "      <th>lab_vbg_paco2</th>\n",
       "      <th>lab_vbg_paco2_uom</th>\n",
       "      <th>...</th>\n",
       "      <th>poc_vbg_paco2_uom</th>\n",
       "      <th>poc_vbg_time</th>\n",
       "      <th>first_abg_src</th>\n",
       "      <th>first_abg_time</th>\n",
       "      <th>first_abg_ph</th>\n",
       "      <th>first_abg_pco2</th>\n",
       "      <th>first_vbg_src</th>\n",
       "      <th>first_vbg_time</th>\n",
       "      <th>first_vbg_ph</th>\n",
       "      <th>first_vbg_pco2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.41</td>\n",
       "      <td>units</td>\n",
       "      <td>47.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>...</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>2150-03-02 22:05:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2150-03-02 15:53:00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.29</td>\n",
       "      <td>units</td>\n",
       "      <td>43.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2144-09-01 05:15:00</td>\n",
       "      <td>7.29</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.29</td>\n",
       "      <td>units</td>\n",
       "      <td>77.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>...</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>2178-03-25 04:28:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2178-03-25 04:28:00</td>\n",
       "      <td>7.29</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  lab_abg_ph lab_abg_ph_uom  lab_abg_paco2 lab_abg_paco2_uom  \\\n",
       "0  20000094         NaN           None            NaN              None   \n",
       "1  20000694         NaN           None            NaN              None   \n",
       "2  20001305         NaN           None            NaN              None   \n",
       "\n",
       "  lab_abg_time  lab_vbg_ph lab_vbg_ph_uom  lab_vbg_paco2 lab_vbg_paco2_uom  \\\n",
       "0          NaT        7.41          units           47.0              mmhg   \n",
       "1          NaT        7.29          units           43.0              mmhg   \n",
       "2          NaT        7.29          units           77.0              mmhg   \n",
       "\n",
       "   ... poc_vbg_paco2_uom        poc_vbg_time first_abg_src  first_abg_time  \\\n",
       "0  ...              mmhg 2150-03-02 22:05:00          None             NaT   \n",
       "1  ...              None                 NaT          None             NaT   \n",
       "2  ...              mmhg 2178-03-25 04:28:00          None             NaT   \n",
       "\n",
       "  first_abg_ph first_abg_pco2  first_vbg_src      first_vbg_time  \\\n",
       "0          NaN            NaN            LAB 2150-03-02 15:53:00   \n",
       "1          NaN            NaN            LAB 2144-09-01 05:15:00   \n",
       "2          NaN            NaN            LAB 2178-03-25 04:28:00   \n",
       "\n",
       "   first_vbg_ph first_vbg_pco2  \n",
       "0          7.41           47.0  \n",
       "1          7.29           43.0  \n",
       "2          7.29           77.0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"hadms\": hadm_list}\n",
    "\n",
    "bg_pairs_sql = rf\"\"\"\n",
    "WITH hadms AS (SELECT hadm_id FROM UNNEST(@hadms) AS hadm_id),\n",
    "\n",
    "/* ---------------- LAB (HOSP) ---------------- */\n",
    "hosp_cand AS (\n",
    "  SELECT\n",
    "    le.subject_id, le.hadm_id, le.charttime, le.specimen_id,\n",
    "    CAST(le.valuenum AS FLOAT64) AS val,\n",
    "    LOWER(COALESCE(le.valueuom,'')) AS uom,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(COALESCE(di.fluid,'')) AS fl,\n",
    "    LOWER(COALESCE(di.category,'')) AS cat\n",
    "  FROM `{PHYS}.{HOSP}.labevents`  le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  JOIN hadms h ON h.hadm_id = le.hadm_id\n",
    "  WHERE le.valuenum IS NOT NULL\n",
    "    AND (\n",
    "         LOWER(COALESCE(di.category,'')) LIKE '%blood gas%' OR\n",
    "         LOWER(di.label) LIKE '%pco2%' OR\n",
    "         REGEXP_CONTAINS(LOWER(di.label), r'\\bph\\b') OR\n",
    "         REGEXP_CONTAINS(LOWER(di.label), r'\\bpa?\\s*co(?:2|₂)\\b')\n",
    "        )\n",
    "    AND NOT REGEXP_CONTAINS(LOWER(di.label), r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar)')\n",
    "),\n",
    "hosp_spec AS (\n",
    "  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE le.specimen_id IS NOT NULL\n",
    "    AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')\n",
    "),\n",
    "hosp_class AS (\n",
    "  SELECT\n",
    "    c.hadm_id, c.charttime, c.specimen_id, c.val, c.uom, c.lbl, c.fl,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(c.lbl, r'\\b(?:blood\\s*)?ph\\b') THEN 'ph'\n",
    "      WHEN (c.lbl LIKE '%pco2%' OR REGEXP_CONTAINS(c.lbl, r'\\bpa?\\s*co(?:2|₂)\\b')) THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\\bart\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'\n",
    "      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\\b(abg|art|arterial|a[- ]?line)\\b') THEN 'arterial'\n",
    "      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\\b(vbg|ven|venous|mixed|central)\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM hosp_cand c\n",
    "  LEFT JOIN hosp_spec s USING (specimen_id)\n",
    "),\n",
    "hosp_pairs AS (\n",
    "  SELECT\n",
    "    hadm_id, specimen_id,\n",
    "    MIN(charttime) AS sample_time,\n",
    "    MAX(IF(analyte='ph',   val, NULL)) AS ph,\n",
    "    MAX(IF(analyte='pco2', val, NULL)) AS pco2_raw,\n",
    "    (ARRAY_AGG(IF(analyte='pco2', uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS pco2_uom,\n",
    "    (ARRAY_AGG(IF(analyte='ph',   uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS ph_uom,\n",
    "    (ARRAY_AGG(site IGNORE NULLS LIMIT 1))[OFFSET(0)] AS site\n",
    "  FROM hosp_class\n",
    "  GROUP BY hadm_id, specimen_id\n",
    "  HAVING (ph IS NOT NULL OR pco2_raw IS NOT NULL) AND site IN ('arterial','venous')\n",
    "),\n",
    "hosp_pairs_std AS (\n",
    "  SELECT\n",
    "    hadm_id, specimen_id, sample_time, site,\n",
    "    ph, ph_uom,\n",
    "    CASE WHEN pco2_uom = 'kpa' THEN pco2_raw * 7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    'mmhg' AS pco2_uom_norm\n",
    "  FROM hosp_pairs\n",
    "  WHERE (ph IS NULL OR (ph BETWEEN 6.3 AND 7.8))\n",
    "    AND (pco2_raw IS NULL OR (CASE WHEN pco2_uom='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200)\n",
    "),\n",
    "lab_abg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS lab_abg_ph,\n",
    "         ph_uom        AS lab_abg_ph_uom,\n",
    "         pco2_mmHg     AS lab_abg_paco2,\n",
    "         'mmhg'        AS lab_abg_paco2_uom,\n",
    "         sample_time   AS lab_abg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM hosp_pairs_std WHERE site='arterial') WHERE rn=1\n",
    "),\n",
    "lab_vbg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS lab_vbg_ph,\n",
    "         ph_uom        AS lab_vbg_ph_uom,\n",
    "         pco2_mmHg     AS lab_vbg_paco2,\n",
    "         'mmhg'        AS lab_vbg_paco2_uom,\n",
    "         sample_time   AS lab_vbg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM hosp_pairs_std WHERE site='venous') WHERE rn=1\n",
    "),\n",
    "\n",
    "/* ---------------- POC (ICU) ---------------- */\n",
    "icu_raw AS (\n",
    "  SELECT\n",
    "    ie.hadm_id, ce.stay_id, ce.charttime,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(REPLACE(COALESCE(ce.valueuom,''),' ','')) AS uom_nospace,\n",
    "    LOWER(COALESCE(ce.value,'')) AS valstr,\n",
    "    COALESCE(\n",
    "      CAST(ce.valuenum AS FLOAT64),\n",
    "      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r'(-?\\d+(?:\\.\\d+)?)') AS FLOAT64)\n",
    "    ) AS val\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n",
    "  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n",
    "  JOIN hadms h ON h.hadm_id = ie.hadm_id\n",
    "),\n",
    "icu_cand AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'(^|[^a-z])ph([^a-z]|$)') OR (val BETWEEN 6.3 AND 7.8) THEN 'ph'\n",
    "      WHEN (\n",
    "             REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)')\n",
    "             OR uom_nospace IN ('mmhg','kpa')\n",
    "             OR REGEXP_CONTAINS(valstr, r'\\b(mm\\s*hg|kpa)\\b')\n",
    "           )\n",
    "           AND NOT REGEXP_CONTAINS(lbl, r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))')\n",
    "      THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\b(abg|art|arterial|a[- ]?line)\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\b(vbg|ven|venous|mixed|central)\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM icu_raw\n",
    "  WHERE val IS NOT NULL\n",
    "    AND (\n",
    "      REGEXP_CONTAINS(lbl, r'(^|[^a-z])ph([^a-z]|$)') OR\n",
    "      REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)') OR\n",
    "      uom_nospace IN ('mmhg','kpa') OR\n",
    "      REGEXP_CONTAINS(valstr, r'\\b(mm\\s*hg|kpa)\\b')\n",
    "    )\n",
    "    AND NOT REGEXP_CONTAINS(lbl, r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))')\n",
    "),\n",
    "icu_ph AS (\n",
    "  SELECT hadm_id, stay_id, charttime, val AS ph, site AS site_ph\n",
    "  FROM icu_cand WHERE analyte='ph'\n",
    "),\n",
    "icu_co2 AS (\n",
    "  SELECT hadm_id, stay_id, charttime, val AS pco2_raw, uom_nospace, valstr, site AS site_co2\n",
    "  FROM icu_cand WHERE analyte='pco2'\n",
    "),\n",
    "icu_pair_win AS (\n",
    "  SELECT\n",
    "    p.hadm_id, p.stay_id,\n",
    "    COALESCE(p.site_ph, c.site_co2) AS site,\n",
    "    p.charttime AS ph_time, c.charttime AS co2_time,\n",
    "    p.ph,\n",
    "    CASE\n",
    "      WHEN c.uom_nospace='kpa' OR REGEXP_CONTAINS(c.valstr, r'\\bkpa\\b') THEN 'kpa'\n",
    "      WHEN c.uom_nospace='mmhg' OR REGEXP_CONTAINS(c.valstr, r'mm\\s*hg') THEN 'mmhg'\n",
    "      ELSE c.uom_nospace\n",
    "    END AS pco2_uom_norm_raw,\n",
    "    c.pco2_raw,\n",
    "    ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, SECOND)) AS dt_sec\n",
    "  FROM icu_ph p\n",
    "  JOIN icu_co2 c\n",
    "    ON c.hadm_id = p.hadm_id\n",
    "   AND c.stay_id = p.stay_id\n",
    "   AND (COALESCE(p.site_ph, c.site_co2) IN ('arterial','venous'))\n",
    "   AND ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, MINUTE)) <= 10\n",
    "  QUALIFY ROW_NUMBER() OVER (\n",
    "    PARTITION BY p.hadm_id, p.stay_id, p.charttime\n",
    "    ORDER BY dt_sec\n",
    "  ) = 1\n",
    "),\n",
    "icu_pairs_std AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, site,\n",
    "    LEAST(ph_time, co2_time) AS sample_time,\n",
    "    ph,\n",
    "    CAST(NULL AS STRING) AS ph_uom,              -- POC pH is unitless/null\n",
    "    CASE WHEN pco2_uom_norm_raw='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    'mmhg' AS pco2_uom_norm\n",
    "  FROM icu_pair_win\n",
    "  WHERE (ph BETWEEN 6.3 AND 7.8 OR ph IS NULL)\n",
    "    AND (CASE WHEN pco2_uom_norm_raw='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200\n",
    "),\n",
    "icu_solo_pco2_std AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, site_co2 AS site,\n",
    "    charttime AS sample_time,\n",
    "    CAST(NULL AS FLOAT64) AS ph,\n",
    "    CAST(NULL AS STRING)  AS ph_uom,            -- no pH here\n",
    "    CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\\bkpa\\b') THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    'mmhg' AS pco2_uom_norm\n",
    "  FROM icu_co2\n",
    "  WHERE site_co2 IN ('arterial','venous')\n",
    "    AND pco2_raw BETWEEN 5 AND 200\n",
    "),\n",
    "icu_all AS (\n",
    "  SELECT * FROM icu_pairs_std\n",
    "  UNION ALL\n",
    "  SELECT * FROM icu_solo_pco2_std\n",
    "),\n",
    "\n",
    "poc_abg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS poc_abg_ph,\n",
    "         ph_uom        AS poc_abg_ph_uom,\n",
    "         pco2_mmHg     AS poc_abg_paco2,\n",
    "         'mmhg'        AS poc_abg_paco2_uom,\n",
    "         sample_time   AS poc_abg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM icu_all WHERE site='arterial') WHERE rn=1\n",
    "),\n",
    "poc_vbg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS poc_vbg_ph,\n",
    "         ph_uom        AS poc_vbg_ph_uom,\n",
    "         pco2_mmHg     AS poc_vbg_paco2,\n",
    "         'mmhg'        AS poc_vbg_paco2_uom,\n",
    "         sample_time   AS poc_vbg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM icu_all WHERE site='venous') WHERE rn=1\n",
    ")\n",
    "\n",
    "/* ---------------- Final one row per hadm ---------------- */\n",
    "SELECT\n",
    "  h.hadm_id,\n",
    "  -- LAB-ABG / LAB-VBG\n",
    "  la.lab_abg_ph, la.lab_abg_ph_uom, la.lab_abg_paco2, la.lab_abg_paco2_uom, la.lab_abg_time,\n",
    "  lv.lab_vbg_ph, lv.lab_vbg_ph_uom, lv.lab_vbg_paco2, lv.lab_vbg_paco2_uom, lv.lab_vbg_time,\n",
    "  -- POC-ABG / POC-VBG\n",
    "  pa.poc_abg_ph, pa.poc_abg_ph_uom, pa.poc_abg_paco2, pa.poc_abg_paco2_uom, pa.poc_abg_time,\n",
    "  pv.poc_vbg_ph, pv.poc_vbg_ph_uom, pv.poc_vbg_paco2, pv.poc_vbg_paco2_uom, pv.poc_vbg_time,\n",
    "  -- First ABG across LAB+POC\n",
    "  (SELECT AS STRUCT src, t, ph, pco2\n",
    "   FROM (SELECT 'LAB' AS src, la.lab_abg_time AS t, la.lab_abg_ph AS ph, la.lab_abg_paco2 AS pco2\n",
    "         UNION ALL\n",
    "         SELECT 'POC', pa.poc_abg_time, pa.poc_abg_ph, pa.poc_abg_paco2)\n",
    "   WHERE t IS NOT NULL\n",
    "   ORDER BY t LIMIT 1) AS first_abg,\n",
    "  -- First VBG across LAB+POC\n",
    "  (SELECT AS STRUCT src, t, ph, pco2\n",
    "   FROM (SELECT 'LAB' AS src, lv.lab_vbg_time AS t, lv.lab_vbg_ph AS ph, lv.lab_vbg_paco2 AS pco2\n",
    "         UNION ALL\n",
    "         SELECT 'POC', pv.poc_vbg_time, pv.poc_vbg_ph, pv.poc_vbg_paco2)\n",
    "   WHERE t IS NOT NULL\n",
    "   ORDER BY t LIMIT 1) AS first_vbg\n",
    "FROM hadms h\n",
    "LEFT JOIN lab_abg la USING (hadm_id)\n",
    "LEFT JOIN lab_vbg lv USING (hadm_id)\n",
    "LEFT JOIN poc_abg pa USING (hadm_id)\n",
    "LEFT JOIN poc_vbg pv USING (hadm_id)\n",
    "\"\"\"\n",
    "\n",
    "bg_pairs = run_sql_bq(bg_pairs_sql, params)\n",
    "\n",
    "# Flatten STRUCTs for first_abg and first_vbg\n",
    "for col in [\"first_abg\",\"first_vbg\"]:\n",
    "    if col in bg_pairs.columns:\n",
    "        bg_pairs[f\"{col}_src\"]  = bg_pairs[col].apply(lambda x: x.get(\"src\") if isinstance(x, dict) else None)\n",
    "        bg_pairs[f\"{col}_time\"] = bg_pairs[col].apply(lambda x: x.get(\"t\")   if isinstance(x, dict) else None)\n",
    "        bg_pairs[f\"{col}_ph\"]   = bg_pairs[col].apply(lambda x: x.get(\"ph\")  if isinstance(x, dict) else None)\n",
    "        bg_pairs[f\"{col}_pco2\"] = bg_pairs[col].apply(lambda x: x.get(\"pco2\")if isinstance(x, dict) else None)\n",
    "        bg_pairs = bg_pairs.drop(columns=[col])\n",
    "\n",
    "bg_pairs.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eba414",
   "metadata": {},
   "source": [
    "## 5) Demographics & outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36c218",
   "metadata": {},
   "source": [
    "**Rationale:** Build baseline covariates used for descriptive statistics and potential confounding adjustment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f2d449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:30.221033Z",
     "iopub.status.busy": "2026-02-04T23:25:30.220901Z",
     "iopub.status.idle": "2026-02-04T23:25:35.152557Z",
     "shell.execute_reply": "2026-02-04T23:25:35.152099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo rows: 40151\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "admittime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "dischtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "deathtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "admission_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "admission_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "discharge_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "insurance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hosp_los_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_in_hosp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age_at_admit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_30d",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "2735abd4-1d2b-432c-b587-20950e8eb97c",
       "rows": [
        [
         "0",
         "23485217",
         "10584718",
         "2165-02-12 15:41:00",
         "2165-03-06 08:20:00",
         "2165-03-06 08:20:00",
         "EW EMER.",
         "TRANSFER FROM SKILLED NURSING FACILITY",
         "DIED",
         "Medicare",
         "21.708333333333332",
         "1",
         "M",
         "78.0",
         "1"
        ],
        [
         "1",
         "22661627",
         "10032409",
         "2130-01-12 18:42:00",
         "2130-01-21 14:32:00",
         null,
         "EW EMER.",
         "EMERGENCY ROOM",
         "SKILLED NURSING FACILITY",
         "Medicare",
         "8.833333333333334",
         "0",
         "F",
         "77.0",
         "0"
        ],
        [
         "2",
         "22447711",
         "13352386",
         "2188-03-25 01:17:00",
         "2188-03-26 16:00:00",
         null,
         "EW EMER.",
         "EMERGENCY ROOM",
         "HOME",
         "Private",
         "1.625",
         "0",
         "F",
         "64.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hosp_los_days</th>\n",
       "      <th>death_in_hosp</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_at_admit</th>\n",
       "      <th>death_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23485217</td>\n",
       "      <td>10584718</td>\n",
       "      <td>2165-02-12 15:41:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>DIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>21.708333</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22661627</td>\n",
       "      <td>10032409</td>\n",
       "      <td>2130-01-12 18:42:00</td>\n",
       "      <td>2130-01-21 14:32:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22447711</td>\n",
       "      <td>13352386</td>\n",
       "      <td>2188-03-25 01:17:00</td>\n",
       "      <td>2188-03-26 16:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  subject_id           admittime           dischtime  \\\n",
       "0  23485217    10584718 2165-02-12 15:41:00 2165-03-06 08:20:00   \n",
       "1  22661627    10032409 2130-01-12 18:42:00 2130-01-21 14:32:00   \n",
       "2  22447711    13352386 2188-03-25 01:17:00 2188-03-26 16:00:00   \n",
       "\n",
       "            deathtime admission_type                      admission_location  \\\n",
       "0 2165-03-06 08:20:00       EW EMER.  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "1                 NaT       EW EMER.                          EMERGENCY ROOM   \n",
       "2                 NaT       EW EMER.                          EMERGENCY ROOM   \n",
       "\n",
       "         discharge_location insurance  hosp_los_days  death_in_hosp gender  \\\n",
       "0                      DIED  Medicare      21.708333              1      M   \n",
       "1  SKILLED NURSING FACILITY  Medicare       8.833333              0      F   \n",
       "2                      HOME   Private       1.625000              0      F   \n",
       "\n",
       "   age_at_admit  death_30d  \n",
       "0          78.0          1  \n",
       "1          77.0          0  \n",
       "2          64.0          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SQL[\"demo_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  a.hadm_id,\n",
    "  a.subject_id,\n",
    "  a.admittime,\n",
    "  a.dischtime,\n",
    "  a.deathtime,\n",
    "  a.admission_type,\n",
    "  a.admission_location,\n",
    "  a.discharge_location,\n",
    "  a.insurance,\n",
    "  -- LOS (days)\n",
    "  TIMESTAMP_DIFF(a.dischtime, a.admittime, HOUR) / 24.0 AS hosp_los_days,\n",
    "  -- in-hospital death\n",
    "  IF(a.deathtime IS NOT NULL, 1, 0) AS death_in_hosp,\n",
    "  -- demographics\n",
    "  p.gender,\n",
    "  SAFE_CAST(ROUND(p.anchor_age + (EXTRACT(YEAR FROM a.admittime) - p.anchor_year), 1) AS FLOAT64) AS age_at_admit,\n",
    "  -- 30-day all-cause mortality from admission\n",
    "  IF(p.dod IS NOT NULL AND DATE_DIFF(DATE(p.dod), DATE(a.admittime), DAY) BETWEEN 0 AND 30, 1, 0) AS death_30d\n",
    "FROM `{PHYS}.{HOSP}.admissions` a\n",
    "JOIN hadms h USING (hadm_id)\n",
    "JOIN `{PHYS}.{HOSP}.patients` p USING (subject_id)\n",
    "\"\"\"\n",
    "demo = run_sql_bq(sql(\"demo_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"Demo rows:\", len(demo))\n",
    "demo.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fee13e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:35.155647Z",
     "iopub.status.busy": "2026-02-04T23:25:35.155412Z",
     "iopub.status.idle": "2026-02-04T23:25:35.171016Z",
     "shell.execute_reply": "2026-02-04T23:25:35.170551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe merge helpers loaded.\n"
     ]
    }
   ],
   "source": [
    "# ==== Drop-in: safe merge utilities (one cell, run once) ====\n",
    "import pandas as pd\n",
    "from typing import Iterable, Optional, Literal\n",
    "\n",
    "def _ensure_Int64(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce to pandas nullable Int64 (preserves NA).\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "def strip_subject_cols(fr: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove any subject_id-like columns from a frame (e.g., 'subject_id', 'Subject_ID').\"\"\"\n",
    "    return fr.drop(columns=[c for c in fr.columns if c.lower().startswith(\"subject_id\")],\n",
    "                   errors=\"ignore\")\n",
    "\n",
    "def safe_merge_on_hadm(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    *,\n",
    "    right_name: str,\n",
    "    take: Optional[Iterable[str]] = None,\n",
    "    order_by: Optional[Iterable[str]] = None,\n",
    "    check_subject: Literal[False, \"warn\", \"raise\"] = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Left-merge 'right' into 'left' on hadm_id, returning a copy of left with right's columns.\n",
    "    - Dedupes right on hadm_id (optionally using order_by to pick the first row).\n",
    "    - Optionally restricts right columns via `take`.\n",
    "    - Optionally audits subject_id agreement before dropping subject_id from right.\n",
    "    - Always strips subject_id-like columns from the right to prevent *_x/_y suffixes.\n",
    "    - Raises if any *_x/_y suffixes still appear (indicates overlapping names besides hadm_id).\n",
    "    \"\"\"\n",
    "    if \"hadm_id\" not in left.columns:\n",
    "        raise KeyError(f\"left frame lacks hadm_id before merging {right_name}\")\n",
    "    if \"hadm_id\" not in right.columns:\n",
    "        raise KeyError(f\"{right_name} lacks hadm_id\")\n",
    "\n",
    "    L = left.copy()\n",
    "    R = right.copy()\n",
    "\n",
    "    # Standardize dtypes of keys\n",
    "    L[\"hadm_id\"] = _ensure_Int64(L[\"hadm_id\"])\n",
    "    R[\"hadm_id\"] = _ensure_Int64(R[\"hadm_id\"])\n",
    "    if \"subject_id\" in L.columns:\n",
    "        L[\"subject_id\"] = _ensure_Int64(L[\"subject_id\"])\n",
    "    if \"subject_id\" in R.columns:\n",
    "        R[\"subject_id\"] = _ensure_Int64(R[\"subject_id\"])\n",
    "\n",
    "    # Dedupe RIGHT by hadm_id (optionally order_by first)\n",
    "    if order_by:\n",
    "        R = (R.sort_values(list(order_by))\n",
    "               .drop_duplicates(subset=[\"hadm_id\"], keep=\"first\"))\n",
    "    else:\n",
    "        R = R.drop_duplicates(subset=[\"hadm_id\"], keep=\"first\")\n",
    "\n",
    "    # Optional subject_id consistency audit (before stripping)\n",
    "    if check_subject and (\"subject_id\" in L.columns) and (\"subject_id\" in R.columns):\n",
    "        # Join only on hadm_id where both sides have subject_id\n",
    "        tmp = (L[[\"hadm_id\", \"subject_id\"]]\n",
    "                 .merge(R[[\"hadm_id\", \"subject_id\"]],\n",
    "                        on=\"hadm_id\", how=\"inner\", suffixes=(\"_L\",\"_R\")))\n",
    "        mism = (tmp[\"subject_id_L\"].notna() & tmp[\"subject_id_R\"].notna() &\n",
    "                (tmp[\"subject_id_L\"] != tmp[\"subject_id_R\"]))\n",
    "        n_mism = int(mism.sum())\n",
    "        if n_mism > 0:\n",
    "            sample_ids = tmp.loc[mism, \"hadm_id\"].head(10).tolist()\n",
    "            msg = (f\"[{right_name}] subject_id mismatch on {n_mism} hadm_id(s). \"\n",
    "                   f\"Examples: {sample_ids}\")\n",
    "            if check_subject == \"raise\":\n",
    "                raise ValueError(msg)\n",
    "            else:\n",
    "                print(\"WARNING:\", msg)\n",
    "\n",
    "    # Limit right columns (avoid accidental overlaps)\n",
    "    if take is not None:\n",
    "        keep = [\"hadm_id\"] + [c for c in take if c != \"hadm_id\"]\n",
    "        R = R[[c for c in keep if c in R.columns]]\n",
    "\n",
    "    # Always strip subject_id-like columns from right to prevent *_x/_y\n",
    "    R = strip_subject_cols(R)\n",
    "\n",
    "    # Final merge\n",
    "    out = L.merge(R, on=\"hadm_id\", how=\"left\", suffixes=(\"\", \"\"))\n",
    "\n",
    "    # Guard: no suffixes should be present\n",
    "    bad = [c for c in out.columns if c.endswith(\"_x\") or c.endswith(\"_y\")]\n",
    "    if bad:\n",
    "        raise RuntimeError(\n",
    "            f\"Merge with {right_name} produced suffixed columns {bad}. \"\n",
    "            \"You likely have overlapping column names other than hadm_id.\"\n",
    "        )\n",
    "    return out\n",
    "\n",
    "print(\"Safe merge helpers loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c42e42",
   "metadata": {},
   "source": [
    "## 6) NIH/OMB race & ethnicity (ED + Hospital)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02bf38",
   "metadata": {},
   "source": [
    "**Rationale:** Harmonize race/ethnicity across sources using NIH/OMB categories for consistent reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb57c105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:35.172698Z",
     "iopub.status.busy": "2026-02-04T23:25:35.172574Z",
     "iopub.status.idle": "2026-02-04T23:25:40.058362Z",
     "shell.execute_reply": "2026-02-04T23:25:40.057723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race/Eth rows: 40151\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "race_hosp_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race_ed_raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "nih_race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nih_ethnicity",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1d1ebd2a-d211-4444-bfd2-724c7e1ecd97",
       "rows": [
        [
         "0",
         "20000094",
         "white",
         null,
         "White",
         "Not Hispanic or Latino"
        ],
        [
         "1",
         "20000694",
         "white",
         "white",
         "White",
         "Not Hispanic or Latino"
        ],
        [
         "2",
         "20001305",
         "white",
         "white",
         "White",
         "Not Hispanic or Latino"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>race_hosp_raw</th>\n",
       "      <th>race_ed_raw</th>\n",
       "      <th>nih_race</th>\n",
       "      <th>nih_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000094</td>\n",
       "      <td>white</td>\n",
       "      <td>None</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000694</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001305</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>White</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id race_hosp_raw race_ed_raw nih_race           nih_ethnicity\n",
       "0  20000094         white        None    White  Not Hispanic or Latino\n",
       "1  20000694         white       white    White  Not Hispanic or Latino\n",
       "2  20001305         white       white    White  Not Hispanic or Latino"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_eth_sql = rf\"\"\"\n",
    "WITH hadms AS (\n",
    "  SELECT x AS hadm_id\n",
    "  FROM UNNEST(@hadms) AS x\n",
    "),\n",
    "\n",
    "-- Hospital admission \"race\" text\n",
    "hosp AS (\n",
    "  SELECT a.hadm_id, LOWER(TRIM(a.race)) AS race_hosp_raw\n",
    "  FROM `{PHYS}.{HOSP}.admissions` a\n",
    "  JOIN hadms hm USING (hadm_id)\n",
    "),\n",
    "\n",
    "-- Earliest ED stay leading to the admission; take its \"race\" text if present\n",
    "ed_first AS (\n",
    "  SELECT\n",
    "    e.hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(e.intime AS intime, LOWER(TRIM(e.race)) AS race_ed_raw)\n",
    "               ORDER BY e.intime ASC LIMIT 1))[OFFSET(0)] AS pick\n",
    "  FROM `{PHYS}.{ED}.edstays` e\n",
    "  JOIN hadms hm USING (hadm_id)\n",
    "  GROUP BY e.hadm_id\n",
    "),\n",
    "ed AS (\n",
    "  SELECT hadm_id, pick.race_ed_raw\n",
    "  FROM ed_first\n",
    "),\n",
    "\n",
    "-- Combine ED + Hospital for maximum coverage\n",
    "comb AS (\n",
    "  SELECT\n",
    "    hm.hadm_id,\n",
    "    ho.race_hosp_raw,\n",
    "    ed.race_ed_raw,\n",
    "    TRIM(REGEXP_REPLACE(CONCAT(COALESCE(ho.race_hosp_raw,''), ' ', COALESCE(ed.race_ed_raw,'')), r'\\s+', ' ')) AS race_text_any\n",
    "  FROM hadms hm\n",
    "  LEFT JOIN hosp ho USING (hadm_id)\n",
    "  LEFT JOIN ed   ed USING (hadm_id)\n",
    "),\n",
    "\n",
    "-- Tokenization to OMB families + Hispanic ethnicity\n",
    "tok AS (\n",
    "  SELECT\n",
    "    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,\n",
    "\n",
    "    -- Ethnicity (Hispanic)\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\b(hispanic|latinx|latino|latina)\\b') AS is_hisp,\n",
    "\n",
    "    -- Race families (use boundaries to reduce false positives)\n",
    "    REGEXP_CONTAINS(race_text_any, r'american\\s+indian|\\balaska\\b') AS is_aian,\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\basian\\b') AS is_asian,\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\b(black|african\\s+american)\\b') AS is_black,\n",
    "    REGEXP_CONTAINS(race_text_any, r'hawaiian|pacific\\s+islander') AS is_nhopi,\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\bwhite\\b|caucasian') AS is_white,\n",
    "\n",
    "    -- Unknown/other indicators\n",
    "    REGEXP_CONTAINS(race_text_any, r'unknown|other|declined|unable|not\\s+reported|missing|null') AS is_unknown_any,\n",
    "\n",
    "    -- Multi-race hints\n",
    "    REGEXP_CONTAINS(race_text_any, r'(two|2)\\s+or\\s+more|multi|biracial|multiracial') AS is_multi_hint\n",
    "  FROM comb\n",
    "),\n",
    "\n",
    "-- Decide ethnicity per NIH\n",
    "ethn AS (\n",
    "  SELECT\n",
    "    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,\n",
    "    CASE\n",
    "      WHEN is_hisp THEN 'Hispanic or Latino'\n",
    "      WHEN (race_text_any IS NULL OR race_text_any = '' OR is_unknown_any) THEN 'Unknown or Not Reported'\n",
    "      ELSE 'Not Hispanic or Latino'\n",
    "    END AS nih_ethnicity,\n",
    "    (CAST(is_aian AS INT64) + CAST(is_asian AS INT64) + CAST(is_black AS INT64)\n",
    "     + CAST(is_nhopi AS INT64) + CAST(is_white AS INT64)) AS race_hits,\n",
    "    is_aian, is_asian, is_black, is_nhopi, is_white, is_multi_hint, is_unknown_any\n",
    "  FROM tok\n",
    "),\n",
    "\n",
    "-- Decide race per NIH/OMB (1997)\n",
    "race_assign AS (\n",
    "  SELECT\n",
    "    hadm_id, race_hosp_raw, race_ed_raw, race_text_any, nih_ethnicity,\n",
    "    CASE\n",
    "      WHEN race_hits >= 2 OR is_multi_hint THEN 'More than one race'\n",
    "      WHEN is_aian THEN 'American Indian or Alaska Native'\n",
    "      WHEN is_asian THEN 'Asian'\n",
    "      WHEN is_black THEN 'Black or African American'\n",
    "      WHEN is_nhopi THEN 'Native Hawaiian or Other Pacific Islander'\n",
    "      WHEN is_white THEN 'White'\n",
    "      WHEN is_unknown_any OR race_text_any IS NULL OR race_text_any = '' THEN 'Unknown or Not Reported'\n",
    "      ELSE 'Unknown or Not Reported'\n",
    "    END AS nih_race\n",
    "  FROM ethn\n",
    ")\n",
    "\n",
    "SELECT hadm_id, race_hosp_raw, race_ed_raw, nih_race, nih_ethnicity\n",
    "FROM race_assign\n",
    "\"\"\"\n",
    "race_eth = run_sql_bq(race_eth_sql, {\"hadms\": hadm_list})\n",
    "print(\"Race/Eth rows:\", len(race_eth))\n",
    "race_eth.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46324987",
   "metadata": {},
   "source": [
    "## 7) ED triage (linked to hadm) and first ED vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cbc23",
   "metadata": {},
   "source": [
    "**Rationale:** Capture ED presentation features (vitals and chief complaint) for symptom and severity analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36d4797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:40.064345Z",
     "iopub.status.busy": "2026-02-04T23:25:40.064150Z",
     "iopub.status.idle": "2026-02-04T23:25:49.060669Z",
     "shell.execute_reply": "2026-02-04T23:25:49.060265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED triage rows: 17424\n",
      "ED first vitals rows: 16746\n"
     ]
    }
   ],
   "source": [
    "# ED triage\n",
    "SQL[\"ed_triage_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "edmap AS (\n",
    "  SELECT stay_id, hadm_id, intime\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "),\n",
    "tri AS (\n",
    "  SELECT stay_id, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint\n",
    "  FROM `{PHYS}.{ED}.triage`\n",
    "),\n",
    "tri_by_stay AS (\n",
    "  SELECT m.hadm_id, m.intime, t.*\n",
    "  FROM edmap m\n",
    "  JOIN tri t USING (stay_id)\n",
    "),\n",
    "tri_by_hadm AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(intime, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint)\n",
    "               ORDER BY intime LIMIT 1))[OFFSET(0)] AS pick\n",
    "  FROM tri_by_stay\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  pick.temperature    AS ed_triage_temp,\n",
    "  pick.heartrate      AS ed_triage_hr,\n",
    "  pick.resprate       AS ed_triage_rr,\n",
    "  pick.o2sat          AS ed_triage_o2sat,\n",
    "  pick.sbp            AS ed_triage_sbp,\n",
    "  pick.dbp            AS ed_triage_dbp,\n",
    "  pick.pain           AS ed_triage_pain,\n",
    "  pick.acuity         AS ed_triage_acuity,\n",
    "  pick.chiefcomplaint AS ed_triage_cc\n",
    "FROM tri_by_hadm\n",
    "\"\"\"\n",
    "ed_triage = run_sql_bq(sql(\"ed_triage_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"ED triage rows:\", len(ed_triage))\n",
    "\n",
    "# First ED vitals\n",
    "SQL[\"ed_first_vitals_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "edmap AS (\n",
    "  SELECT stay_id, hadm_id\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "),\n",
    "vs AS (\n",
    "  SELECT stay_id, charttime, temperature, heartrate, resprate, o2sat, sbp, dbp, rhythm, pain\n",
    "  FROM `{PHYS}.{ED}.vitalsign`\n",
    "),\n",
    "first_vs AS (\n",
    "  SELECT\n",
    "    m.hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(v.charttime, v.temperature, v.heartrate, v.resprate, v.o2sat, v.sbp, v.dbp, v.rhythm, v.pain)\n",
    "               ORDER BY v.charttime LIMIT 1))[OFFSET(0)] AS pick\n",
    "  FROM edmap m JOIN vs v USING (stay_id)\n",
    "  GROUP BY m.hadm_id\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  pick.charttime   AS ed_first_vitals_time,\n",
    "  pick.temperature AS ed_first_temp,\n",
    "  pick.heartrate   AS ed_first_hr,\n",
    "  pick.resprate    AS ed_first_rr,\n",
    "  pick.o2sat       AS ed_first_o2sat,\n",
    "  pick.sbp         AS ed_first_sbp,\n",
    "  pick.dbp         AS ed_first_dbp,\n",
    "  pick.rhythm      AS ed_first_rhythm,\n",
    "  pick.pain        AS ed_first_pain\n",
    "FROM first_vs\n",
    "\"\"\"\n",
    "ed_first = run_sql_bq(sql(\"ed_first_vitals_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"ED first vitals rows:\", len(ed_first))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097df55c",
   "metadata": {},
   "source": [
    "## 8) ICU meta (first ICU stay, LOS days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6f8d8",
   "metadata": {},
   "source": [
    "**Rationale:** Summarize ICU exposure and length of stay to contextualize disease severity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356b3163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:49.064150Z",
     "iopub.status.busy": "2026-02-04T23:25:49.064034Z",
     "iopub.status.idle": "2026-02-04T23:25:53.262012Z",
     "shell.execute_reply": "2026-02-04T23:25:53.261371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU meta rows: 26059\n"
     ]
    }
   ],
   "source": [
    "SQL[\"icu_meta_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "first_icu AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(stay_id, intime, outtime) ORDER BY intime LIMIT 1))[OFFSET(0)] AS s\n",
    "  FROM `{PHYS}.{ICU}.icustays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  s.stay_id AS first_icu_stay_id,\n",
    "  s.intime  AS icu_intime,\n",
    "  s.outtime AS icu_outtime,\n",
    "  TIMESTAMP_DIFF(s.outtime, s.intime, HOUR)/24.0 AS icu_los_days\n",
    "FROM first_icu\n",
    "\"\"\"\n",
    "icu_meta = run_sql_bq(sql(\"icu_meta_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"ICU meta rows:\", len(icu_meta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04241211",
   "metadata": {},
   "source": [
    "## 9) Ventilation flags (ICD procedures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8dc04",
   "metadata": {},
   "source": [
    "**Rationale:** Identify IMV/NIV exposure as clinically relevant respiratory support indicators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d411472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:53.266119Z",
     "iopub.status.busy": "2026-02-04T23:25:53.265809Z",
     "iopub.status.idle": "2026-02-04T23:25:58.011836Z",
     "shell.execute_reply": "2026-02-04T23:25:58.010567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vent rows: 40151\n"
     ]
    }
   ],
   "source": [
    "# Cheaper ventilation flags: yes/no for IMV and NIV (ICD-9/ICD-10), plus any_vent_flag\n",
    "SQL[\"vent_sql\"] = f\"\"\"\n",
    "WITH hadms AS (\n",
    "  SELECT x AS hadm_id\n",
    "  FROM UNNEST(@hadms) AS x\n",
    "),\n",
    "\n",
    "-- Restrict to admissions of interest early to minimize CPU\n",
    "proc AS (\n",
    "  SELECT hadm_id, icd_version, icd_code\n",
    "  FROM `{PHYS}.{HOSP}.procedures_icd`\n",
    "  JOIN hadms USING (hadm_id)\n",
    "),\n",
    "\n",
    "-- ICU Invasive Mechanical Ventilation (IMV)\n",
    "-- ICD-10-PCS (usually stored without a dot)\n",
    "imv10 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 10\n",
    "    AND icd_code IN ('5A1935Z','5A1945Z','5A1955Z','0BH17EZ','0BH18EZ')\n",
    "),\n",
    "\n",
    "-- ICD-9-CM procedures (stored sometimes with dot, sometimes without)\n",
    "imv9 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 9\n",
    "    AND (\n",
    "          icd_code IN ('96.70','96.71','96.72','96.04')  -- dotted forms\n",
    "          OR REPLACE(icd_code, '.', '') IN ('9670','9671','9672','9604') -- dotless match\n",
    "        )\n",
    "),\n",
    "\n",
    "-- Noninvasive Ventilation (NIV)\n",
    "-- ICD-10-PCS (no dot)\n",
    "niv10 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 10\n",
    "    AND icd_code IN ('5A09357','5A09457','5A09557')\n",
    "),\n",
    "\n",
    "-- ICD-9-CM (with/without dot)\n",
    "niv9 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 9\n",
    "    AND (\n",
    "          icd_code IN ('93.90','93.91','93.99')            -- dotted\n",
    "          OR REPLACE(icd_code, '.', '') IN ('9390','9391','9399')  -- dotless\n",
    "        )\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  h.hadm_id,\n",
    "  IF(i10.hadm_id IS NOT NULL OR i9.hadm_id IS NOT NULL, 1, 0) AS imv_flag,\n",
    "  IF(n10.hadm_id IS NOT NULL OR n9.hadm_id IS NOT NULL, 1, 0) AS niv_flag,\n",
    "  -- any_vent = either IMV or NIV\n",
    "  IF(\n",
    "    (i10.hadm_id IS NOT NULL OR i9.hadm_id IS NOT NULL)\n",
    "    OR (n10.hadm_id IS NOT NULL OR n9.hadm_id IS NOT NULL),\n",
    "    1, 0\n",
    "  ) AS any_vent_flag\n",
    "FROM hadms h\n",
    "LEFT JOIN imv10 i10 ON h.hadm_id = i10.hadm_id\n",
    "LEFT JOIN imv9  i9  ON h.hadm_id = i9.hadm_id\n",
    "LEFT JOIN niv10 n10 ON h.hadm_id = n10.hadm_id\n",
    "LEFT JOIN niv9  n9  ON h.hadm_id = n9.hadm_id\n",
    "\"\"\"\n",
    "\n",
    "vent = run_sql_bq(sql(\"vent_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"Vent rows:\", len(vent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cd724",
   "metadata": {},
   "source": [
    "and from charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9834f4e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:25:58.026941Z",
     "iopub.status.busy": "2026-02-04T23:25:58.026689Z",
     "iopub.status.idle": "2026-02-04T23:26:02.213781Z",
     "shell.execute_reply": "2026-02-04T23:26:02.212892Z"
    }
   },
   "outputs": [],
   "source": [
    "SQL[\"vent_chart_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "\n",
    "stays AS (\n",
    "  SELECT hadm_id, stay_id\n",
    "  FROM `{PHYS}.{ICU}.icustays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "),\n",
    "\n",
    "cand AS (\n",
    "  SELECT\n",
    "    s.hadm_id,\n",
    "    ce.stay_id,\n",
    "    ce.charttime,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(COALESCE(ce.value,'')) AS valstr\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`    di ON di.itemid = ce.itemid\n",
    "  JOIN stays s ON s.stay_id = ce.stay_id\n",
    "  WHERE\n",
    "    (\n",
    "      REGEXP_CONTAINS(LOWER(di.label), r'(vent|ventilator|mode|bipap|bi[- ]?pap|cpap|nippv|niv|mask|ett|endotracheal)')\n",
    "      OR REGEXP_CONTAINS(LOWER(ce.value), r'(bipap|bi[- ]?pap|cpap|nippv|niv|endotracheal|ett|ac/|simv|prvc|aprv|pcv|vcv|assist\\s*control)')\n",
    "    )\n",
    "),\n",
    "\n",
    "flags AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    MIN(IF(\n",
    "          REGEXP_CONTAINS(lbl,   r'(non[- ]?invasive|niv|nippv|bipap|bi[- ]?pap|cpap)')\n",
    "          OR REGEXP_CONTAINS(valstr,r'(non[- ]?invasive|niv|nippv|bipap|bi[- ]?pap|cpap)'),\n",
    "          charttime, NULL)) AS first_niv_time,\n",
    "    MIN(IF(\n",
    "          REGEXP_CONTAINS(lbl,   r'(invasive ventilation|endotracheal|ett|mech(|anical)? vent|ventilator mode|ac/|simv|prvc|aprv|pcv|vcv|assist\\s*control)')\n",
    "          OR REGEXP_CONTAINS(valstr,r'(invasive ventilation|endotracheal|ett|ac/|simv|prvc|aprv|pcv|vcv|assist\\s*control)'),\n",
    "          charttime, NULL)) AS first_imv_time,\n",
    "    MAX( CASE\n",
    "            WHEN REGEXP_CONTAINS(lbl,   r'(non[- ]?invasive|niv|nippv|bipap|bi[- ]?pap|cpap)')\n",
    "              OR REGEXP_CONTAINS(valstr,r'(non[- ]?invasive|niv|nippv|bipap|bi[- ]?pap|cpap)')\n",
    "            THEN 1 ELSE 0\n",
    "        END ) AS niv_chart_flag,\n",
    "    MAX( CASE\n",
    "            WHEN REGEXP_CONTAINS(lbl,   r'(invasive ventilation|endotracheal|ett|mech(|anical)? vent|ventilator mode|ac/|simv|prvc|aprv|pcv|vcv|assist\\s*control)')\n",
    "              OR REGEXP_CONTAINS(valstr,r'(invasive ventilation|endotracheal|ett|ac/|simv|prvc|aprv|pcv|vcv|assist\\s*control)')\n",
    "            THEN 1 ELSE 0\n",
    "        END ) AS imv_chart_flag\n",
    "  FROM cand\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "\n",
    "SELECT hadm_id, niv_chart_flag, imv_chart_flag, first_niv_time, first_imv_time\n",
    "FROM flags\n",
    "\"\"\"\n",
    "vent_chart = run_sql_bq(sql(\"vent_chart_sql\"), {\"hadms\": hadm_list})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c096d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:02.218365Z",
     "iopub.status.busy": "2026-02-04T23:26:02.218098Z",
     "iopub.status.idle": "2026-02-04T23:26:02.257882Z",
     "shell.execute_reply": "2026-02-04T23:26:02.257062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After combining ICD + chart signals: \n",
      "IMV=1: 23655 \n",
      "NIV=1: 10540\n"
     ]
    }
   ],
   "source": [
    "# If your existing ICD-only result is called `vent`, rename for clarity:\n",
    "vent_proc = vent.copy()\n",
    "\n",
    "# Outer merge so we keep hadm_ids that appear in only one source\n",
    "vent_combined = vent_proc.merge(vent_chart, on=\"hadm_id\", how=\"outer\")\n",
    "\n",
    "# Fill missing with 0 before taking maxima\n",
    "for c in [\"imv_flag\",\"niv_flag\",\"any_vent_flag\",\"imv_chart_flag\",\"niv_chart_flag\"]:\n",
    "    if c in vent_combined.columns:\n",
    "        vent_combined[c] = vent_combined[c].fillna(0).astype(\"Int64\")\n",
    "\n",
    "# Final \"any-source\" flags\n",
    "vent_combined[\"imv_flag\"]       = vent_combined[[\"imv_flag\",\"imv_chart_flag\"]].max(axis=1).astype(\"Int64\")\n",
    "vent_combined[\"niv_flag\"]       = vent_combined[[\"niv_flag\",\"niv_chart_flag\"]].max(axis=1).astype(\"Int64\")\n",
    "vent_combined[\"any_vent_flag\"]  = vent_combined[[\"imv_flag\",\"niv_flag\"]].max(axis=1).astype(\"Int64\")\n",
    "\n",
    "vent_combined = vent_combined[[\"hadm_id\",\"imv_flag\",\"niv_flag\",\"any_vent_flag\",\"first_imv_time\",\"first_niv_time\"]]\n",
    "print(\"After combining ICD + chart signals:\",\n",
    "      \"\\nIMV=1:\", int((vent_combined[\"imv_flag\"]==1).sum()),\n",
    "      \"\\nNIV=1:\", int((vent_combined[\"niv_flag\"]==1).sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81ddd8",
   "metadata": {},
   "source": [
    "## 10) Assemble final DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af830bbe",
   "metadata": {},
   "source": [
    "**Rationale:** Merge all derived features into a single analytic table keyed by hadm_id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43442b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:02.261279Z",
     "iopub.status.busy": "2026-02-04T23:26:02.261128Z",
     "iopub.status.idle": "2026-02-04T23:26:02.585666Z",
     "shell.execute_reply": "2026-02-04T23:26:02.584537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final df rows: 40151 cols: 89\n",
      "Final df rows: 40151 cols: 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "admittime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "dischtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "deathtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "admission_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "admission_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "discharge_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "insurance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hosp_los_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_in_hosp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age_at_admit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_30d",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9602",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9612",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9622",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9692",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_E662",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD9_27803",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_hosp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_ed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "icd_source",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "abg_hypercap_threshold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "vbg_hypercap_threshold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pco2_threshold_any",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "enrolled_any",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lab_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "lab_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_ph_uom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lab_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_paco2_uom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lab_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "first_abg_src",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_abg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_abg_pco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_src",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "first_vbg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_pco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "race_hosp_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race_ed_raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "nih_race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nih_ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ed_triage_temp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_hr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_rr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_o2sat",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_sbp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_dbp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_pain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_acuity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_cc",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_vitals_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "ed_first_temp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_hr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_rr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_o2sat",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_sbp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ed_first_dbp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ed_first_rhythm",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_pain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_icu_stay_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "icu_intime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "icu_outtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "icu_los_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "imv_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "niv_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_vent_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "first_imv_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "first_niv_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "abg_before_imv",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "vbg_before_imv",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "a3f8dd8c-85b0-4dc1-a49d-179be594593a",
       "rows": [
        [
         "0",
         "23485217",
         "10584718",
         "2165-02-12 15:41:00",
         "2165-03-06 08:20:00",
         "2165-03-06 08:20:00",
         "EW EMER.",
         "TRANSFER FROM SKILLED NURSING FACILITY",
         "DIED",
         "Medicare",
         "21.708333333333332",
         "1",
         "M",
         "78.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         "0",
         "1",
         "1",
         "1",
         null,
         null,
         null,
         null,
         null,
         "7.26",
         "units",
         "50.0",
         "mmhg",
         "2165-02-27 13:43:00",
         null,
         null,
         "160.0",
         "mmhg",
         "2165-03-02 07:34:00",
         "7.22",
         null,
         "109.0",
         "mmhg",
         "2165-02-27 23:07:00",
         "POC",
         "2165-03-02 07:34:00",
         null,
         "160.0",
         "LAB",
         "2165-02-27 13:43:00",
         "7.26",
         "50.0",
         "white",
         null,
         "White",
         "Not Hispanic or Latino",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "36809832",
         "2165-02-27 21:41:10",
         "2165-03-06 11:09:58",
         "6.583333333333333",
         "1",
         "0",
         "1",
         "2165-02-27 22:00:00",
         null,
         "0",
         "1"
        ],
        [
         "1",
         "22661627",
         "10032409",
         "2130-01-12 18:42:00",
         "2130-01-21 14:32:00",
         null,
         "EW EMER.",
         "EMERGENCY ROOM",
         "SKILLED NURSING FACILITY",
         "Medicare",
         "8.833333333333334",
         "0",
         "F",
         "77.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         "0",
         "1",
         "1",
         "1",
         "7.44",
         "units",
         "45.0",
         "mmhg",
         "2130-01-15 20:26:00",
         "7.4",
         "units",
         "49.0",
         "mmhg",
         "2130-01-13 07:41:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "LAB",
         "2130-01-15 20:26:00",
         "7.44",
         "45.0",
         "LAB",
         "2130-01-13 07:41:00",
         "7.4",
         "49.0",
         "black/african american",
         "black/african american",
         "Black or African American",
         "Not Hispanic or Latino",
         "98.300000000",
         "72.000000000",
         "20.000000000",
         "100.000000000",
         "143.000000000",
         "71.000000000",
         "0",
         "3.000000000",
         "DYSPNEA",
         "2130-01-12 15:05:00",
         null,
         "74.000000000",
         "19.000000000",
         "95.000000000",
         "149",
         "95",
         null,
         "0",
         null,
         null,
         null,
         null,
         "0",
         "0",
         "0",
         null,
         null,
         "0",
         "0"
        ],
        [
         "2",
         "22447711",
         "13352386",
         "2188-03-25 01:17:00",
         "2188-03-26 16:00:00",
         null,
         "EW EMER.",
         "EMERGENCY ROOM",
         "HOME",
         "Private",
         "1.625",
         "0",
         "F",
         "64.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         "0",
         "1",
         "1",
         "1",
         null,
         null,
         null,
         null,
         null,
         "7.38",
         "units",
         "56.0",
         "mmhg",
         "2188-03-25 10:06:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "LAB",
         "2188-03-25 10:06:00",
         "7.38",
         "56.0",
         "black/african american",
         "black/african american",
         "Black or African American",
         "Not Hispanic or Latino",
         "102.800000000",
         "114.000000000",
         "20.000000000",
         "94.000000000",
         "138.000000000",
         "49.000000000",
         "0",
         "2.000000000",
         "DYSPNEA",
         "2188-03-24 22:49:00",
         null,
         "115.000000000",
         "21.000000000",
         "100.000000000",
         "136",
         "49",
         null,
         "0",
         null,
         null,
         null,
         null,
         "0",
         "0",
         "0",
         null,
         null,
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 89,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hosp_los_days</th>\n",
       "      <th>...</th>\n",
       "      <th>icu_intime</th>\n",
       "      <th>icu_outtime</th>\n",
       "      <th>icu_los_days</th>\n",
       "      <th>imv_flag</th>\n",
       "      <th>niv_flag</th>\n",
       "      <th>any_vent_flag</th>\n",
       "      <th>first_imv_time</th>\n",
       "      <th>first_niv_time</th>\n",
       "      <th>abg_before_imv</th>\n",
       "      <th>vbg_before_imv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23485217</td>\n",
       "      <td>10584718</td>\n",
       "      <td>2165-02-12 15:41:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>DIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>21.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>2165-02-27 21:41:10</td>\n",
       "      <td>2165-03-06 11:09:58</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2165-02-27 22:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22661627</td>\n",
       "      <td>10032409</td>\n",
       "      <td>2130-01-12 18:42:00</td>\n",
       "      <td>2130-01-21 14:32:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22447711</td>\n",
       "      <td>13352386</td>\n",
       "      <td>2188-03-25 01:17:00</td>\n",
       "      <td>2188-03-26 16:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  subject_id           admittime           dischtime  \\\n",
       "0  23485217    10584718 2165-02-12 15:41:00 2165-03-06 08:20:00   \n",
       "1  22661627    10032409 2130-01-12 18:42:00 2130-01-21 14:32:00   \n",
       "2  22447711    13352386 2188-03-25 01:17:00 2188-03-26 16:00:00   \n",
       "\n",
       "            deathtime admission_type                      admission_location  \\\n",
       "0 2165-03-06 08:20:00       EW EMER.  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "1                 NaT       EW EMER.                          EMERGENCY ROOM   \n",
       "2                 NaT       EW EMER.                          EMERGENCY ROOM   \n",
       "\n",
       "         discharge_location insurance  hosp_los_days  ...          icu_intime  \\\n",
       "0                      DIED  Medicare      21.708333  ... 2165-02-27 21:41:10   \n",
       "1  SKILLED NURSING FACILITY  Medicare       8.833333  ...                 NaT   \n",
       "2                      HOME   Private       1.625000  ...                 NaT   \n",
       "\n",
       "          icu_outtime  icu_los_days  imv_flag  niv_flag  any_vent_flag  \\\n",
       "0 2165-03-06 11:09:58      6.583333         1         0              1   \n",
       "1                 NaT           NaN         0         0              0   \n",
       "2                 NaT           NaN         0         0              0   \n",
       "\n",
       "       first_imv_time  first_niv_time  abg_before_imv  vbg_before_imv  \n",
       "0 2165-02-27 22:00:00             NaT               0               1  \n",
       "1                 NaT             NaT               0               0  \n",
       "2                 NaT             NaT               0               0  \n",
       "\n",
       "[3 rows x 89 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Canonical base (carries authoritative subject_id)\n",
    "df = demo.copy()\n",
    "\n",
    "# Cohort flags / thresholds / labs / etc.\n",
    "df = safe_merge_on_hadm(df, cohort_any, right_name=\"cohort_any\", check_subject=\"warn\")\n",
    "df = safe_merge_on_hadm(df, bg_pairs,   right_name=\"bg_pairs\")\n",
    "df = safe_merge_on_hadm(df, race_eth,   right_name=\"race_eth\")\n",
    "df = safe_merge_on_hadm(df, ed_triage,  right_name=\"ed_triage\")\n",
    "df = safe_merge_on_hadm(df, ed_first,   right_name=\"ed_first\")\n",
    "df = safe_merge_on_hadm(df, icu_meta,   right_name=\"icu_meta\")\n",
    "df = safe_merge_on_hadm(df, vent_combined,       right_name=\"vent_combined\")\n",
    "\n",
    "# Anchor to first ED presentation (per admission)\n",
    "if \"ed_intime_first\" in globals():\n",
    "    df = safe_merge_on_hadm(df, ed_intime_first, right_name=\"ed_intime_first\")\n",
    "\n",
    "# Derived timing: first NIV/IMV relative to ED presentation\n",
    "if \"ed_intime_first\" in df.columns and \"first_imv_time\" in df.columns:\n",
    "    df[\"dt_first_imv_hours\"] = (df[\"first_imv_time\"] - df[\"ed_intime_first\"]).dt.total_seconds() / 3600.0\n",
    "if \"ed_intime_first\" in df.columns and \"first_niv_time\" in df.columns:\n",
    "    df[\"dt_first_niv_hours\"] = (df[\"first_niv_time\"] - df[\"ed_intime_first\"]).dt.total_seconds() / 3600.0\n",
    "\n",
    "# ABG/VBG before IMV (hadm-level)\n",
    "if {\"first_abg_time\", \"first_imv_time\"}.issubset(df.columns):\n",
    "    df[\"abg_before_imv\"] = (\n",
    "        df[\"first_abg_time\"].notna() & df[\"first_imv_time\"].notna() &\n",
    "        (df[\"first_abg_time\"] < df[\"first_imv_time\"])\n",
    "    ).astype(\"Int64\")\n",
    "if {\"first_vbg_time\", \"first_imv_time\"}.issubset(df.columns):\n",
    "    df[\"vbg_before_imv\"] = (\n",
    "        df[\"first_vbg_time\"].notna() & df[\"first_imv_time\"].notna() &\n",
    "        (df[\"first_vbg_time\"] < df[\"first_imv_time\"])\n",
    "    ).astype(\"Int64\")\n",
    "\n",
    "print(\"Final df rows:\", len(df), \"cols:\", len(df.columns))\n",
    "\n",
    "# Safety checks\n",
    "assert \"subject_id\" in df.columns, \"subject_id missing from final df\"\n",
    "assert not any(c.endswith(\"_x\") or c.endswith(\"_y\") for c in df.columns), \"Found suffixed columns\"\n",
    "print(\"Final df rows:\", len(df), \"cols:\", len(df.columns))\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "806f96a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:02.590043Z",
     "iopub.status.busy": "2026-02-04T23:26:02.589821Z",
     "iopub.status.idle": "2026-02-04T23:26:06.464588Z",
     "shell.execute_reply": "2026-02-04T23:26:06.464042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "scope",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a8171f06-56de-40d8-8876-62062da11988",
       "rows": [
        [
         "0",
         "Total ED encounters (edstays)",
         "425087",
         "All ED dataset"
        ],
        [
         "1",
         "ED encounters with hadm_id",
         "203016",
         "All ED dataset"
        ],
        [
         "2",
         "ED→ICU admissions (distinct hadm_id)",
         "31862",
         "All ED+ICU"
        ],
        [
         "3",
         "ED→ICU ED-stays (distinct stay_id)",
         "31916",
         "All ED+ICU"
        ],
        [
         "4",
         "Cohort admissions (union ICD ∪ thresholds)",
         "40152",
         "Cohort"
        ],
        [
         "5",
         "Cohort admissions after merges (df rows)",
         "40151",
         "Cohort"
        ],
        [
         "6",
         "Cohort with any ABG/VBG (LAB or POC)",
         "37887",
         "Cohort"
        ],
        [
         "7",
         "Cohort meeting hypercapnia thresholds",
         "39016",
         "Cohort"
        ],
        [
         "8",
         "Cohort meeting ICD code criteria",
         "4237",
         "Cohort"
        ],
        [
         "9",
         "Cohort with ED chief complaint present",
         "17424",
         "Cohort"
        ],
        [
         "10",
         "Cohort excluded for missing ED chief complaint",
         "22727",
         "Cohort"
        ],
        [
         "11",
         "Cohort ED→ICU (ED CC present + ICU stay)",
         "11542",
         "Cohort"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>count</th>\n",
       "      <th>scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total ED encounters (edstays)</td>\n",
       "      <td>425087</td>\n",
       "      <td>All ED dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ED encounters with hadm_id</td>\n",
       "      <td>203016</td>\n",
       "      <td>All ED dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ED→ICU admissions (distinct hadm_id)</td>\n",
       "      <td>31862</td>\n",
       "      <td>All ED+ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ED→ICU ED-stays (distinct stay_id)</td>\n",
       "      <td>31916</td>\n",
       "      <td>All ED+ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cohort admissions (union ICD ∪ thresholds)</td>\n",
       "      <td>40152</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cohort admissions after merges (df rows)</td>\n",
       "      <td>40151</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cohort with any ABG/VBG (LAB or POC)</td>\n",
       "      <td>37887</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cohort meeting hypercapnia thresholds</td>\n",
       "      <td>39016</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cohort meeting ICD code criteria</td>\n",
       "      <td>4237</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cohort with ED chief complaint present</td>\n",
       "      <td>17424</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cohort excluded for missing ED chief complaint</td>\n",
       "      <td>22727</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cohort ED→ICU (ED CC present + ICU stay)</td>\n",
       "      <td>11542</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              step   count           scope\n",
       "0                    Total ED encounters (edstays)  425087  All ED dataset\n",
       "1                       ED encounters with hadm_id  203016  All ED dataset\n",
       "2             ED→ICU admissions (distinct hadm_id)   31862      All ED+ICU\n",
       "3               ED→ICU ED-stays (distinct stay_id)   31916      All ED+ICU\n",
       "4       Cohort admissions (union ICD ∪ thresholds)   40152          Cohort\n",
       "5         Cohort admissions after merges (df rows)   40151          Cohort\n",
       "6             Cohort with any ABG/VBG (LAB or POC)   37887          Cohort\n",
       "7            Cohort meeting hypercapnia thresholds   39016          Cohort\n",
       "8                 Cohort meeting ICD code criteria    4237          Cohort\n",
       "9           Cohort with ED chief complaint present   17424          Cohort\n",
       "10  Cohort excluded for missing ED chief complaint   22727          Cohort\n",
       "11        Cohort ED→ICU (ED CC present + ICU stay)   11542          Cohort"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cohort flow counts (ED / ICU / blood gas / hypercapnia / CC) ---\n",
    "\n",
    "# 1) Dataset-level ED counts\n",
    "SQL[\"ed_counts_sql\"] = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS total_ed_encounters,\n",
    "  COUNTIF(hadm_id IS NOT NULL) AS ed_encounters_with_hadm\n",
    "FROM `{PHYS}.{ED}.edstays`\n",
    "\"\"\"\n",
    "\n",
    "SQL[\"ed_to_icu_sql\"] = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(DISTINCT e.hadm_id) AS ed_to_icu_hadm,\n",
    "  COUNT(DISTINCT e.stay_id) AS ed_to_icu_edstays\n",
    "FROM `{PHYS}.{ED}.edstays` e\n",
    "JOIN `{PHYS}.{ICU}.icustays` i USING (hadm_id)\n",
    "WHERE e.hadm_id IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    ed_counts = run_sql_bq(sql(\"ed_counts_sql\"))\n",
    "    ed_to_icu = run_sql_bq(sql(\"ed_to_icu_sql\"))\n",
    "except Exception as e:\n",
    "    print(\"Warning: ED/ICU counts query failed:\", e)\n",
    "    ed_counts = None\n",
    "    ed_to_icu = None\n",
    "\n",
    "# 2) Cohort-level counts (admission-level)\n",
    "cohort_union = int((cohort_any[\"enrolled_any\"] == 1).sum()) if \"cohort_any\" in globals() and \"enrolled_any\" in cohort_any.columns else len(hadm_list)\n",
    "cohort_df_n = len(df)\n",
    "\n",
    "# Any blood gas present (ABG/VBG, LAB/POC)\n",
    "co2_cols = [c for c in [\n",
    "    \"lab_abg_paco2\", \"lab_vbg_paco2\", \"poc_abg_paco2\", \"poc_vbg_paco2\"\n",
    "] if c in df.columns]\n",
    "any_bg = int(df[co2_cols].notna().any(axis=1).sum()) if co2_cols else None\n",
    "\n",
    "# Hypercapnia thresholds and ICD\n",
    "icd_count = int((df[\"any_hypercap_icd\"] == 1).sum()) if \"any_hypercap_icd\" in df.columns else None\n",
    "threshold_count = int((df[\"pco2_threshold_any\"] == 1).sum()) if \"pco2_threshold_any\" in df.columns else None\n",
    "\n",
    "# ED chief complaint missing / present (within cohort)\n",
    "if \"ed_triage_cc\" in df.columns:\n",
    "    mask_cc_present = df[\"ed_triage_cc\"].notna() & (df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "    cc_present = int(mask_cc_present.sum())\n",
    "    cc_missing = int((~mask_cc_present).sum())\n",
    "else:\n",
    "    cc_present = None\n",
    "    cc_missing = None\n",
    "\n",
    "# ED→ICU within cohort (admissions with ED triage data and ICU stay)\n",
    "if \"first_icu_stay_id\" in df.columns and \"ed_triage_cc\" in df.columns:\n",
    "    cohort_ed_to_icu = int((df[\"first_icu_stay_id\"].notna() & mask_cc_present).sum())\n",
    "else:\n",
    "    cohort_ed_to_icu = None\n",
    "\n",
    "rows = []\n",
    "if ed_counts is not None:\n",
    "    rows.append({\"step\": \"Total ED encounters (edstays)\", \"count\": int(ed_counts.loc[0, \"total_ed_encounters\"]), \"scope\": \"All ED dataset\"})\n",
    "    rows.append({\"step\": \"ED encounters with hadm_id\", \"count\": int(ed_counts.loc[0, \"ed_encounters_with_hadm\"]), \"scope\": \"All ED dataset\"})\n",
    "if ed_to_icu is not None:\n",
    "    rows.append({\"step\": \"ED→ICU admissions (distinct hadm_id)\", \"count\": int(ed_to_icu.loc[0, \"ed_to_icu_hadm\"]), \"scope\": \"All ED+ICU\"})\n",
    "    rows.append({\"step\": \"ED→ICU ED-stays (distinct stay_id)\", \"count\": int(ed_to_icu.loc[0, \"ed_to_icu_edstays\"]), \"scope\": \"All ED+ICU\"})\n",
    "\n",
    "rows.append({\"step\": \"Cohort admissions (union ICD ∪ thresholds)\", \"count\": cohort_union, \"scope\": \"Cohort\"})\n",
    "rows.append({\"step\": \"Cohort admissions after merges (df rows)\", \"count\": cohort_df_n, \"scope\": \"Cohort\"})\n",
    "if any_bg is not None:\n",
    "    rows.append({\"step\": \"Cohort with any ABG/VBG (LAB or POC)\", \"count\": any_bg, \"scope\": \"Cohort\"})\n",
    "if threshold_count is not None:\n",
    "    rows.append({\"step\": \"Cohort meeting hypercapnia thresholds\", \"count\": threshold_count, \"scope\": \"Cohort\"})\n",
    "if icd_count is not None:\n",
    "    rows.append({\"step\": \"Cohort meeting ICD code criteria\", \"count\": icd_count, \"scope\": \"Cohort\"})\n",
    "if cc_present is not None:\n",
    "    rows.append({\"step\": \"Cohort with ED chief complaint present\", \"count\": cc_present, \"scope\": \"Cohort\"})\n",
    "if cc_missing is not None:\n",
    "    rows.append({\"step\": \"Cohort excluded for missing ED chief complaint\", \"count\": cc_missing, \"scope\": \"Cohort\"})\n",
    "if cohort_ed_to_icu is not None:\n",
    "    rows.append({\"step\": \"Cohort ED→ICU (ED CC present + ICU stay)\", \"count\": cohort_ed_to_icu, \"scope\": \"Cohort\"})\n",
    "\n",
    "flow_counts = pd.DataFrame(rows)\n",
    "flow_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0f3d240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:06.470992Z",
     "iopub.status.busy": "2026-02-04T23:26:06.470789Z",
     "iopub.status.idle": "2026-02-04T23:26:06.484405Z",
     "shell.execute_reply": "2026-02-04T23:26:06.484102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABG/VBG overlap (among gas-positive):\n",
      "   group  count  pct_of_gas  pct_of_cohort\n",
      "ABG-only      0         0.0            0.0\n",
      "VBG-only  39016       100.0           97.2\n",
      " ABG+VBG      0         0.0            0.0\n",
      "ICD vs Gas overlap (cohort-level):\n",
      "   group  count  pct_of_cohort\n",
      " ICD+Gas   3102            7.7\n",
      "ICD-only   1135            2.8\n",
      "Gas-only  35914           89.4\n",
      " Neither      0            0.0\n"
     ]
    }
   ],
   "source": [
    "# --- Ascertainment overlap counts (ABG/VBG/ICD) ---\n",
    "\n",
    "required = [\"abg_hypercap_threshold\", \"vbg_hypercap_threshold\", \"any_hypercap_icd\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns for overlap counts: {missing}\")\n",
    "\n",
    "abg = pd.to_numeric(df[\"abg_hypercap_threshold\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "vbg = pd.to_numeric(df[\"vbg_hypercap_threshold\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "gas_any = (\n",
    "    pd.to_numeric(df.get(\"pco2_threshold_any\", None), errors=\"coerce\")\n",
    "    if \"pco2_threshold_any\" in df.columns else (abg | vbg)\n",
    ")\n",
    "if hasattr(gas_any, \"fillna\"):\n",
    "    gas_any = gas_any.fillna(0).astype(int)\n",
    "else:\n",
    "    gas_any = gas_any.astype(int)\n",
    "\n",
    "icd = pd.to_numeric(df[\"any_hypercap_icd\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "total_n = len(df)\n",
    "ngas = int((gas_any == 1).sum())\n",
    "\n",
    "abg_vbg_overlap = pd.DataFrame([\n",
    "    {\"group\": \"ABG-only\", \"count\": int(((abg==1) & (vbg==0)).sum())},\n",
    "    {\"group\": \"VBG-only\", \"count\": int(((vbg==1) & (abg==0)).sum())},\n",
    "    {\"group\": \"ABG+VBG\", \"count\": int(((abg==1) & (vbg==1)).sum())},\n",
    "])\n",
    "if ngas > 0:\n",
    "    abg_vbg_overlap[\"pct_of_gas\"] = (abg_vbg_overlap[\"count\"] / ngas * 100).round(1)\n",
    "else:\n",
    "    abg_vbg_overlap[\"pct_of_gas\"] = 0.0\n",
    "abg_vbg_overlap[\"pct_of_cohort\"] = (abg_vbg_overlap[\"count\"] / max(total_n,1) * 100).round(1)\n",
    "\n",
    "icd_gas_overlap = pd.DataFrame([\n",
    "    {\"group\": \"ICD+Gas\", \"count\": int(((icd==1) & (gas_any==1)).sum())},\n",
    "    {\"group\": \"ICD-only\", \"count\": int(((icd==1) & (gas_any==0)).sum())},\n",
    "    {\"group\": \"Gas-only\", \"count\": int(((icd==0) & (gas_any==1)).sum())},\n",
    "    {\"group\": \"Neither\", \"count\": int(((icd==0) & (gas_any==0)).sum())},\n",
    "])\n",
    "icd_gas_overlap[\"pct_of_cohort\"] = (icd_gas_overlap[\"count\"] / max(total_n,1) * 100).round(1)\n",
    "\n",
    "print(\"ABG/VBG overlap (among gas-positive):\")\n",
    "print(abg_vbg_overlap.to_string(index=False))\n",
    "print(\"ICD vs Gas overlap (cohort-level):\")\n",
    "print(icd_gas_overlap.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb306488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:06.485999Z",
     "iopub.status.busy": "2026-02-04T23:26:06.485882Z",
     "iopub.status.idle": "2026-02-04T23:26:06.601555Z",
     "shell.execute_reply": "2026-02-04T23:26:06.601158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness summary (key variables):\n",
      "Missingness summary (ED triage + first ED vitals):\n"
     ]
    }
   ],
   "source": [
    "# --- Missingness summary (chief complaint, race/ethnicity, ED triage/vitals) ---\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# Chief complaint missingness (ED triage CC)\n",
    "if \"ed_triage_cc\" in df.columns:\n",
    "    cc_present = df[\"ed_triage_cc\"].notna() & (df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "    summary_rows.append({\n",
    "        \"variable\": \"ed_triage_cc_present\",\n",
    "        \"missing_n\": int((~cc_present).sum()),\n",
    "        \"missing_pct\": float((~cc_present).mean())\n",
    "    })\n",
    "\n",
    "# Race/Ethnicity missingness (NIH categories + raw sources)\n",
    "unknown_tokens = {\n",
    "    \"unknown or not reported\",\n",
    "    \"unknown\",\n",
    "    \"not reported\",\n",
    "    \"missing\",\n",
    "    \"declined\",\n",
    "    \"unable\"\n",
    "}\n",
    "\n",
    "def _missing_rate(series):\n",
    "    if series is None:\n",
    "        return None, None\n",
    "    s = series.astype(str).str.strip()\n",
    "    is_missing = series.isna() | (s == \"\") | s.str.lower().isin(unknown_tokens)\n",
    "    return int(is_missing.sum()), float(is_missing.mean())\n",
    "\n",
    "for col in [\"nih_race\", \"nih_ethnicity\", \"race_hosp_raw\", \"race_ed_raw\"]:\n",
    "    if col in df.columns:\n",
    "        m_n, m_p = _missing_rate(df[col])\n",
    "        summary_rows.append({\n",
    "            \"variable\": col,\n",
    "            \"missing_n\": m_n,\n",
    "            \"missing_pct\": m_p\n",
    "        })\n",
    "\n",
    "missing_summary = pd.DataFrame(summary_rows)\n",
    "print(\"Missingness summary (key variables):\")\n",
    "missing_summary\n",
    "\n",
    "# ED triage + first ED vitals missingness\n",
    "triage_cols = [c for c in df.columns if c.startswith(\"ed_triage_\")]\n",
    "first_cols  = [c for c in df.columns if c.startswith(\"ed_first_\")]\n",
    "\n",
    "vital_cols = triage_cols + first_cols\n",
    "if vital_cols:\n",
    "    miss_tbl = (\n",
    "        pd.DataFrame({\"variable\": vital_cols})\n",
    "        .assign(\n",
    "            missing_n=lambda d: [int(df[c].isna().sum()) for c in d[\"variable\"]],\n",
    "            missing_pct=lambda d: [float(df[c].isna().mean()) for c in d[\"variable\"]]\n",
    "        )\n",
    "        .sort_values(\"missing_pct\", ascending=False)\n",
    "    )\n",
    "    print(\"Missingness summary (ED triage + first ED vitals):\")\n",
    "    miss_tbl\n",
    "else:\n",
    "    miss_tbl = pd.DataFrame(columns=[\"variable\", \"missing_n\", \"missing_pct\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e172e",
   "metadata": {},
   "source": [
    "## 11) Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761e99a",
   "metadata": {},
   "source": [
    "**Rationale:** Run QC checks to validate units, flags, and basic data integrity before export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39f00e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:06.603084Z",
     "iopub.status.busy": "2026-02-04T23:26:06.602982Z",
     "iopub.status.idle": "2026-02-04T23:26:06.633055Z",
     "shell.execute_reply": "2026-02-04T23:26:06.632795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative ICU LOS rows: 0\n",
      "any_vent_flag mismatches vs (imv|niv): 0\n",
      "lab_abg_paco2_uom ['mmhg']\n",
      "lab_vbg_paco2_uom ['mmhg']\n",
      "poc_abg_paco2_uom ['mmhg']\n",
      "poc_vbg_paco2_uom ['mmhg']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pair",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "present_any",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "present_both",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "only_ph",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "only_pco2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ph_oob",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pco2_oob",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9fe72e47-5bc2-4814-82a1-370ad6dd117a",
       "rows": [
        [
         "0",
         "LAB ABG",
         "17368",
         "17168",
         "195",
         "5",
         "0",
         "0"
        ],
        [
         "1",
         "LAB VBG",
         "36980",
         "33600",
         "3372",
         "8",
         "0",
         "0"
        ],
        [
         "2",
         "POC ABG",
         "15411",
         "7046",
         "0",
         "8365",
         "0",
         "0"
        ],
        [
         "3",
         "POC VBG",
         "22413",
         "16476",
         "0",
         "5937",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>present_any</th>\n",
       "      <th>present_both</th>\n",
       "      <th>only_ph</th>\n",
       "      <th>only_pco2</th>\n",
       "      <th>ph_oob</th>\n",
       "      <th>pco2_oob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAB ABG</td>\n",
       "      <td>17368</td>\n",
       "      <td>17168</td>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAB VBG</td>\n",
       "      <td>36980</td>\n",
       "      <td>33600</td>\n",
       "      <td>3372</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POC ABG</td>\n",
       "      <td>15411</td>\n",
       "      <td>7046</td>\n",
       "      <td>0</td>\n",
       "      <td>8365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POC VBG</td>\n",
       "      <td>22413</td>\n",
       "      <td>16476</td>\n",
       "      <td>0</td>\n",
       "      <td>5937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair  present_any  present_both  only_ph  only_pco2  ph_oob  pco2_oob\n",
       "0  LAB ABG        17368         17168      195          5       0         0\n",
       "1  LAB VBG        36980         33600     3372          8       0         0\n",
       "2  POC ABG        15411          7046        0       8365       0         0\n",
       "3  POC VBG        22413         16476        0       5937       0         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ICU LOS negative?\n",
    "if {\"icu_los_days\",\"first_icu_stay_id\"}.issubset(df.columns):\n",
    "    neg_los = int((df[\"icu_los_days\"] < 0).fillna(False).sum())\n",
    "    print(\"Negative ICU LOS rows:\", neg_los)\n",
    "\n",
    "# Vent flags consistency\n",
    "vent_cols = {\"imv_flag\",\"niv_flag\",\"any_vent_flag\"}\n",
    "if vent_cols.issubset(df.columns):\n",
    "    any_calc = ((df[\"imv_flag\"]==1) | (df[\"niv_flag\"]==1)).fillna(False).astype(int)\n",
    "    any_flag = pd.to_numeric(df[\"any_vent_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    mism = int((any_calc != any_flag).sum())\n",
    "    print(\"any_vent_flag mismatches vs (imv|niv):\", mism)\n",
    "\n",
    "# UOMs: expect mmhg only\n",
    "uom_cols = [c for c in df.columns if c.endswith(\"_paco2_uom\")]\n",
    "for c in uom_cols:\n",
    "    vals = sorted(pd.Series(df[c]).dropna().astype(str).str.lower().str.strip().unique().tolist())\n",
    "    print(c, vals)\n",
    "\n",
    "# ABG/VBG coverage QC\n",
    "def qc_pair(df, ph_col, co2_col, label, ph_lo=6.3, ph_hi=7.8, co2_lo=5, co2_hi=200):\n",
    "    ph  = pd.to_numeric(df.get(ph_col), errors=\"coerce\")\n",
    "    co2 = pd.to_numeric(df.get(co2_col), errors=\"coerce\")\n",
    "    return {\n",
    "        \"pair\": label,\n",
    "        \"present_any\":  int(((ph.notna()) | (co2.notna())).sum()),\n",
    "        \"present_both\": int(((ph.notna()) & (co2.notna())).sum()),\n",
    "        \"only_ph\":      int(((ph.notna()) & (~co2.notna())).sum()),\n",
    "        \"only_pco2\":    int(((co2.notna()) & (~ph.notna())).sum()),\n",
    "        \"ph_oob\":       int((((ph  < ph_lo)  | (ph  > ph_hi))  & ph.notna()).sum()),\n",
    "        \"pco2_oob\":     int((((co2 < co2_lo) | (co2 > co2_hi)) & co2.notna()).sum()),\n",
    "    }\n",
    "\n",
    "qc = pd.DataFrame([\n",
    "    qc_pair(df, \"lab_abg_ph\",\"lab_abg_paco2\",\"LAB ABG\"),\n",
    "    qc_pair(df, \"lab_vbg_ph\",\"lab_vbg_paco2\",\"LAB VBG\"),\n",
    "    qc_pair(df, \"poc_abg_ph\",\"poc_abg_paco2\",\"POC ABG\"),\n",
    "    qc_pair(df, \"poc_vbg_ph\",\"poc_vbg_paco2\",\"POC VBG\"),\n",
    "])\n",
    "qc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9634bf",
   "metadata": {},
   "source": [
    "## 12) Save to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5f147",
   "metadata": {},
   "source": [
    "**Rationale:** Persist cohort outputs for downstream annotation and NLP analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cd24b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:06.634458Z",
     "iopub.status.busy": "2026-02-04T23:26:06.634379Z",
     "iopub.status.idle": "2026-02-04T23:26:38.555228Z",
     "shell.execute_reply": "2026-02-04T23:26:38.554461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_bq_abg_vbg_20260204_210911.xlsx')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "out_path = DATA_DIR / f\"mimic_hypercap_EXT_bq_abg_vbg_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xw:\n",
    "    df.to_excel(xw, sheet_name=\"cohort\", index=False)\n",
    "    try:\n",
    "        qc.to_excel(xw, sheet_name=\"qc_abg_vbg\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "out_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28e47c",
   "metadata": {},
   "source": [
    "## Create Annotation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a607a4",
   "metadata": {},
   "source": [
    "**Rationale:** Create ED chief-complaint subsets and a reproducible sample for manual annotation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd4b4ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:38.560362Z",
     "iopub.status.busy": "2026-02-04T23:26:38.560237Z",
     "iopub.status.idle": "2026-02-04T23:26:51.875068Z",
     "shell.execute_reply": "2026-02-04T23:26:51.874538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED-CC present rows: 17424 of 40151 (43.4% of cohort).\n",
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_EDcc_only_bq_abg_vbg_20260204_210948.xlsx\n",
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_EDcc_sample160_bq_abg_vbg_20260204_210948.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---- Extra exports: (1) ED chief-complaint only; (2) random sample of 160 patients ----\n",
    "from datetime import datetime\n",
    "\n",
    "# Where to write\n",
    "out_dir = DATA_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 1) Filter to rows with a non-empty ED chief complaint\n",
    "if \"ed_triage_cc\" not in df.columns:\n",
    "    raise KeyError(\n",
    "        \"Column 'ed_triage_cc' not found in df. \"\n",
    "        \"Ensure the ED triage merge cell ran earlier.\"\n",
    "    )\n",
    "\n",
    "mask_cc = df[\"ed_triage_cc\"].notna() & (df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "df_cc = df.loc[mask_cc].copy()\n",
    "\n",
    "print(f\"ED-CC present rows: {len(df_cc)} of {len(df)} \"\n",
    "      f\"({(len(df_cc) / max(len(df),1)):.1%} of cohort).\")\n",
    "\n",
    "# Save ED-CC-only cohort\n",
    "out_path_cc = out_dir / f\"mimic_hypercap_EXT_EDcc_only_bq_abg_vbg_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(out_path_cc, engine=\"openpyxl\") as xw:\n",
    "    df_cc.to_excel(xw, sheet_name=\"cohort_cc_only\", index=False)\n",
    "    try:\n",
    "        qc.to_excel(xw, sheet_name=\"qc_abg_vbg\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"Saved:\", out_path_cc)\n",
    "\n",
    "# 2) Random sample of n = 160 patients (distinct subject_id), one row per patient\n",
    "if \"subject_id\" not in df_cc.columns:\n",
    "    raise KeyError(\"Column 'subject_id' missing; cannot sample by patient.\")\n",
    "\n",
    "# Make a one-row-per-patient frame by earliest admission\n",
    "if \"admittime\" in df_cc.columns:\n",
    "    df_cc_one = (\n",
    "        df_cc.sort_values([\"subject_id\", \"admittime\"])\n",
    "             .groupby(\"subject_id\", as_index=False)\n",
    "             .head(1)\n",
    "    )\n",
    "else:\n",
    "    # Fallback if admittime not present: choose the smallest hadm_id per patient\n",
    "    df_cc_one = (\n",
    "        df_cc.sort_values([\"subject_id\", \"hadm_id\"])\n",
    "             .groupby(\"subject_id\", as_index=False)\n",
    "             .head(1)\n",
    "    )\n",
    "\n",
    "N = 160\n",
    "n_avail = len(df_cc_one)\n",
    "n_take = min(N, n_avail)\n",
    "if n_avail < N:\n",
    "    print(f\"Warning: only {n_avail} unique patients with ED chief complaint; sampling all of them.\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "df_cc_sample = df_cc_one.sample(n=n_take, random_state=RANDOM_SEED)\n",
    "\n",
    "# Save the sample\n",
    "out_path_cc_sample = out_dir / f\"mimic_hypercap_EXT_EDcc_sample{n_take}_bq_abg_vbg_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(out_path_cc_sample, engine=\"openpyxl\") as xw:\n",
    "    df_cc_sample.to_excel(xw, sheet_name=\"cohort_cc_sample\", index=False)\n",
    "    try:\n",
    "        qc.to_excel(xw, sheet_name=\"qc_abg_vbg\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"Saved:\", out_path_cc_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e098c6",
   "metadata": {},
   "source": [
    "# ED-stay cohort expansion (timing, severity, comorbidity, outcomes)\n",
    "\n",
    "**Rationale:** Build a one-row-per-ED-stay analytic extract with time-anchored gas phenotypes, key comorbidities, and outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b296e",
   "metadata": {},
   "source": [
    "## Phase 0 — Inventory & missing-field registry\n",
    "\n",
    "**Rationale:** Detect which fields already exist and only add missing fields to avoid redundant extraction or join explosions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d50acefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:51.880769Z",
     "iopub.status.busy": "2026-02-04T23:26:51.880560Z",
     "iopub.status.idle": "2026-02-04T23:26:51.885816Z",
     "shell.execute_reply": "2026-02-04T23:26:51.885612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current admission-level df: (40151, 89)\n",
      "Current columns count: 89\n",
      "ED stay unique count: ED_KEY not in columns\n",
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/current_columns.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Identify current cohort dataframe (admission-level)\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"Expected admission-level df to exist before inventory step.\")\n",
    "\n",
    "ED_KEY = \"ed_stay_id\"  # target key for ED-level cohort\n",
    "\n",
    "print(\"Current admission-level df:\", df.shape)\n",
    "print(\"Current columns count:\", len(df.columns))\n",
    "if ED_KEY in df.columns:\n",
    "    print(\"ED stay unique count:\", int(df[ED_KEY].nunique()))\n",
    "else:\n",
    "    print(\"ED stay unique count: ED_KEY not in columns\")\n",
    "\n",
    "# Persist columns snapshot\n",
    "cols_out = WORK_DIR / \"current_columns.json\"\n",
    "cols_out.write_text(json.dumps(sorted(df.columns), indent=2))\n",
    "print(\"Wrote:\", cols_out)\n",
    "\n",
    "\n",
    "\n",
    "# Persist ED-stay columns snapshot (if ed_df exists)\n",
    "if \"ed_df\" in globals():\n",
    "    ed_cols_out = WORK_DIR / \"ed_columns.json\"\n",
    "    ed_cols_out.write_text(json.dumps(sorted(ed_df.columns), indent=2))\n",
    "    print(\"Wrote:\", ed_cols_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fff412f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:51.887040Z",
     "iopub.status.busy": "2026-02-04T23:26:51.886920Z",
     "iopub.status.idle": "2026-02-04T23:26:51.892255Z",
     "shell.execute_reply": "2026-02-04T23:26:51.892025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing fields total: 53\n",
      "- ed_edstays: ['ed_stay_id', 'ed_intime', 'ed_outtime', 'ed_intime_first', 'arrival_transport', 'disposition', 'ed_gender', 'ed_race']\n",
      "- admissions: ['hospital_expire_flag', 'language', 'marital_status', 'hosp_race']\n",
      "- icu: ['icu_stay_id', 'icu_intime_first', 'icu_outtime_last', 'icu_los_total', 'n_icu_stays', 'first_careunit', 'last_careunit']\n",
      "- labs_gas: ['first_gas_time', 'first_pco2', 'first_ph', 'first_hco3', 'first_lactate', 'max_pco2_0_6h', 'min_ph_0_6h', 'max_pco2_0_24h', 'min_ph_0_24h', 'flag_abg_hypercapnia', 'flag_vbg_hypercapnia', 'flag_any_gas_hypercapnia', 'gas_source_unknown_rate', 'dt_first_imv_hours', 'dt_first_niv_hours']\n",
      "- omr: ['bmi_closest_pre_ed', 'height_closest_pre_ed', 'weight_closest_pre_ed']\n",
      "- dx_flags: ['flag_copd', 'flag_osa_ohs', 'flag_chf', 'flag_neuromuscular', 'flag_opioid_substance', 'flag_pneumonia']\n",
      "- timing: ['dt_first_qualifying_gas_hours', 'presenting_hypercapnia', 'late_hypercapnia', 'dt_first_imv_hours', 'dt_first_niv_hours', 'ph_band', 'hco3_band', 'lactate_band']\n",
      "- derived: ['hospital_los_hours', 'in_hospital_death']\n"
     ]
    }
   ],
   "source": [
    "# Target field registry\n",
    "TARGET_RAW_FIELDS = {\n",
    "    \"ed_edstays\": [\n",
    "        \"ed_stay_id\",\"subject_id\",\"hadm_id\",\"ed_intime\",\"ed_outtime\",\"ed_intime_first\",\n",
    "        \"arrival_transport\",\"disposition\",\"ed_gender\",\"ed_race\",\n",
    "    ],\n",
    "    \"ed_triage\": [\n",
    "        \"ed_triage_temp\",\"ed_triage_hr\",\"ed_triage_rr\",\"ed_triage_o2sat\",\n",
    "        \"ed_triage_sbp\",\"ed_triage_dbp\",\"ed_triage_pain\",\"ed_triage_acuity\",\"ed_triage_cc\",\n",
    "    ],\n",
    "    \"ed_vitals_first\": [\n",
    "        \"ed_first_vitals_time\",\"ed_first_temp\",\"ed_first_hr\",\"ed_first_rr\",\n",
    "        \"ed_first_o2sat\",\"ed_first_sbp\",\"ed_first_dbp\",\"ed_first_rhythm\",\"ed_first_pain\",\n",
    "    ],\n",
    "    \"admissions\": [\n",
    "        \"admittime\",\"dischtime\",\"deathtime\",\"hospital_expire_flag\",\n",
    "        \"admission_type\",\"admission_location\",\"discharge_location\",\n",
    "        \"insurance\",\"language\",\"marital_status\",\"hosp_race\",\n",
    "    ],\n",
    "    \"icu\": [\n",
    "        \"icu_stay_id\",\"icu_intime_first\",\"icu_outtime_last\",\"icu_los_total\",\"n_icu_stays\",\n",
    "        \"first_careunit\",\"last_careunit\",\n",
    "    ],\n",
    "    \"labs_gas\": [\n",
    "        \"first_gas_time\",\"first_pco2\",\"first_ph\",\"first_hco3\",\"first_lactate\",\n",
    "        \"max_pco2_0_6h\",\"min_ph_0_6h\",\"max_pco2_0_24h\",\"min_ph_0_24h\",\n",
    "        \"flag_abg_hypercapnia\",\"flag_vbg_hypercapnia\",\"flag_any_gas_hypercapnia\",\n",
    "        \"gas_source_unknown_rate\",\n",
    "        \"dt_first_imv_hours\",\"dt_first_niv_hours\",\n",
    "    ],\n",
    "    \"omr\": [\n",
    "        \"bmi_closest_pre_ed\",\"height_closest_pre_ed\",\"weight_closest_pre_ed\",\n",
    "    ],\n",
    "    \"dx_flags\": [\n",
    "        \"flag_copd\",\"flag_osa_ohs\",\"flag_chf\",\"flag_neuromuscular\",\n",
    "        \"flag_opioid_substance\",\"flag_pneumonia\",\n",
    "    ],\n",
    "    \"timing\": [\n",
    "        \"dt_first_qualifying_gas_hours\",\"presenting_hypercapnia\",\"late_hypercapnia\",\n",
    "        \"dt_first_imv_hours\",\"dt_first_niv_hours\",\"abg_before_imv\",\"vbg_before_imv\",\n",
    "        \"ph_band\",\"hco3_band\",\"lactate_band\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "TARGET_DERIVED_FIELDS = [\n",
    "    \"hospital_los_hours\",\"in_hospital_death\",\n",
    "]\n",
    "\n",
    "TARGET_FIELDS = sorted({c for v in TARGET_RAW_FIELDS.values() for c in v} | set(TARGET_DERIVED_FIELDS))\n",
    "\n",
    "# Grouped missing report\n",
    "missing_by_group = {}\n",
    "for group, cols in TARGET_RAW_FIELDS.items():\n",
    "    missing_by_group[group] = [c for c in cols if c not in df.columns]\n",
    "\n",
    "missing_derived = [c for c in TARGET_DERIVED_FIELDS if c not in df.columns]\n",
    "missing_by_group[\"derived\"] = missing_derived\n",
    "\n",
    "missing_flat = [c for cols in missing_by_group.values() for c in cols]\n",
    "print(\"Missing fields total:\", len(missing_flat))\n",
    "for group, cols in missing_by_group.items():\n",
    "    if cols:\n",
    "        print(f\"- {group}: {cols}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d4c97",
   "metadata": {},
   "source": [
    "## Phase 1 — ED encounter spine and ED enrichment (one row per ED stay)\n",
    "\n",
    "**Rationale:** Create a dedicated ED-stay-level cohort with ED-specific attributes to avoid mixing admission- and ED-level grains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11b2122f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:51.893646Z",
     "iopub.status.busy": "2026-02-04T23:26:51.893558Z",
     "iopub.status.idle": "2026-02-04T23:26:56.986544Z",
     "shell.execute_reply": "2026-02-04T23:26:56.986007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED spine rows: 17449 unique ed_stay_id: 17449\n"
     ]
    }
   ],
   "source": [
    "# ED stay spine (rename stay_id to ed_stay_id)\n",
    "\n",
    "SQL[\"ed_spine_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  s.stay_id AS ed_stay_id,\n",
    "  s.subject_id,\n",
    "  s.hadm_id,\n",
    "  s.intime AS ed_intime,\n",
    "  s.outtime AS ed_outtime,\n",
    "  s.arrival_transport,\n",
    "  s.disposition,\n",
    "  s.gender AS ed_gender,\n",
    "  s.race   AS ed_race\n",
    "FROM `{PHYS}.{ED}.edstays` s\n",
    "JOIN hadms h ON h.hadm_id = s.hadm_id\n",
    "\"\"\"\n",
    "\n",
    "ed_spine = run_sql_bq(sql(\"ed_spine_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"ED spine rows:\", len(ed_spine), \"unique ed_stay_id:\", ed_spine[\"ed_stay_id\"].nunique())\n",
    "\n",
    "# ensure uniqueness\n",
    "if ed_spine[\"ed_stay_id\"].nunique() != len(ed_spine):\n",
    "    raise ValueError(\"ed_stay_id not unique in ED spine\")\n",
    "\n",
    "# First ED presentation time per admission\n",
    "ed_intime_first = (\n",
    "    ed_spine.groupby(\"hadm_id\", as_index=False)[\"ed_intime\"]\n",
    "    .min()\n",
    "    .rename(columns={\"ed_intime\": \"ed_intime_first\"})\n",
    ")\n",
    "\n",
    "# Start ED-level df\n",
    "ed_df = ed_spine.copy()\n",
    "ed_df = ed_df.merge(ed_intime_first, on=\"hadm_id\", how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f8c7170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:26:56.988305Z",
     "iopub.status.busy": "2026-02-04T23:26:56.988173Z",
     "iopub.status.idle": "2026-02-04T23:27:08.853873Z",
     "shell.execute_reply": "2026-02-04T23:27:08.853235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED triage rows: 17424\n",
      "ED first vitals rows: 16746\n",
      "ed_triage cols: ['hadm_id', 'ed_triage_temp', 'ed_triage_hr', 'ed_triage_rr', 'ed_triage_o2sat', 'ed_triage_sbp', 'ed_triage_dbp', 'ed_triage_pain', 'ed_triage_acuity', 'ed_triage_cc']\n",
      "ed_first cols: ['hadm_id', 'ed_first_vitals_time', 'ed_first_temp', 'ed_first_hr', 'ed_first_rr', 'ed_first_o2sat', 'ed_first_sbp', 'ed_first_dbp', 'ed_first_rhythm', 'ed_first_pain']\n",
      "ed_df cols: ['ed_stay_id', 'subject_id', 'hadm_id', 'ed_intime', 'ed_outtime', 'arrival_transport', 'disposition', 'ed_gender', 'ed_race', 'ed_intime_first']\n"
     ]
    }
   ],
   "source": [
    "# ED triage and first ED vitals (reuse existing logic if present; otherwise join)\n",
    "\n",
    "def _needs_cols(df, cols):\n",
    "    return (df is None) or any(c not in df.columns for c in cols)\n",
    "\n",
    "# Use existing ed_triage / ed_first if already in memory from earlier cells\n",
    "try:\n",
    "    _ = ed_triage\n",
    "except NameError:\n",
    "    ed_triage = None\n",
    "\n",
    "try:\n",
    "    _ = ed_first\n",
    "except NameError:\n",
    "    ed_first = None\n",
    "\n",
    "# Force re-query if required keys are missing\n",
    "if _needs_cols(locals().get('ed_triage', None), ['ed_stay_id', 'hadm_id']):\n",
    "    ed_triage = None\n",
    "if _needs_cols(locals().get('ed_first', None), ['ed_stay_id']):\n",
    "    ed_first = None\n",
    "\n",
    "# If missing, re-run ED triage / first vitals queries with ed_stay_id output\n",
    "if ed_triage is None:\n",
    "    ed_triage_sql = f\"\"\"\n",
    "    WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "    SELECT\n",
    "      s.stay_id AS ed_stay_id,\n",
    "      s.hadm_id,\n",
    "      s.intime,\n",
    "      t.temperature    AS ed_triage_temp,\n",
    "      t.heartrate      AS ed_triage_hr,\n",
    "      t.resprate       AS ed_triage_rr,\n",
    "      t.o2sat          AS ed_triage_o2sat,\n",
    "      t.sbp            AS ed_triage_sbp,\n",
    "      t.dbp            AS ed_triage_dbp,\n",
    "      t.pain           AS ed_triage_pain,\n",
    "      t.acuity         AS ed_triage_acuity,\n",
    "      t.chiefcomplaint AS ed_triage_cc\n",
    "    FROM `{PHYS}.{ED}.edstays` s\n",
    "    JOIN hadms h ON h.hadm_id = s.hadm_id\n",
    "    LEFT JOIN `{PHYS}.{ED}.triage` t\n",
    "      ON t.stay_id = s.stay_id\n",
    "    \"\"\"\n",
    "    ed_triage = run_sql_bq(sql(\"ed_triage_sql\"), {'hadms': hadm_list})\n",
    "    print('ED triage rows:', len(ed_triage))\n",
    "\n",
    "if ed_first is None:\n",
    "    ed_first_vitals_sql = f\"\"\"\n",
    "    WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "    edmap AS (\n",
    "      SELECT stay_id, hadm_id\n",
    "      FROM `{PHYS}.{ED}.edstays`\n",
    "      WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "    ),\n",
    "    vs AS (\n",
    "      SELECT stay_id, charttime, temperature, heartrate, resprate, o2sat, sbp, dbp, rhythm, pain\n",
    "      FROM `{PHYS}.{ED}.vitalsign`\n",
    "    ),\n",
    "    first_vs AS (\n",
    "      SELECT\n",
    "        v.stay_id,\n",
    "        (ARRAY_AGG(STRUCT(v.charttime, v.temperature, v.heartrate, v.resprate, v.o2sat, v.sbp, v.dbp, v.rhythm, v.pain)\n",
    "                   ORDER BY v.charttime LIMIT 1))[OFFSET(0)] AS pick\n",
    "      FROM vs v\n",
    "      JOIN edmap m USING (stay_id)\n",
    "      GROUP BY v.stay_id\n",
    "    )\n",
    "    SELECT\n",
    "      f.stay_id AS ed_stay_id,\n",
    "      pick.charttime AS ed_first_vitals_time,\n",
    "      pick.temperature AS ed_first_temp,\n",
    "      pick.heartrate AS ed_first_hr,\n",
    "      pick.resprate AS ed_first_rr,\n",
    "      pick.o2sat AS ed_first_o2sat,\n",
    "      pick.sbp AS ed_first_sbp,\n",
    "      pick.dbp AS ed_first_dbp,\n",
    "      pick.rhythm AS ed_first_rhythm,\n",
    "      pick.pain AS ed_first_pain\n",
    "    FROM first_vs f\n",
    "    \"\"\"\n",
    "    ed_first = run_sql_bq(sql(\"ed_first_vitals_sql\"), {'hadms': hadm_list})\n",
    "    print('ED first vitals rows:', len(ed_first))\n",
    "\n",
    "# Debug columns before merge\n",
    "print('ed_triage cols:', list(ed_triage.columns))\n",
    "print('ed_first cols:', list(ed_first.columns))\n",
    "print('ed_df cols:', list(ed_df.columns))\n",
    "\n",
    "if 'ed_stay_id' not in ed_df.columns:\n",
    "    raise KeyError('ed_df missing ed_stay_id; ensure ED spine cell ran.')\n",
    "\n",
    "# Merge ED triage + vitals onto ed_df with available keys\n",
    "merge_keys_triage = [k for k in [\"ed_stay_id\", \"hadm_id\"] if k in ed_df.columns and k in ed_triage.columns]\n",
    "if not merge_keys_triage:\n",
    "    raise KeyError(\"No common keys between ed_df and ed_triage\")\n",
    "ed_df = ed_df.merge(ed_triage, on=merge_keys_triage, how=\"left\")\n",
    "merge_keys_first = [k for k in [\"ed_stay_id\", \"hadm_id\"] if k in ed_df.columns and k in ed_first.columns]\n",
    "if not merge_keys_first:\n",
    "    raise KeyError(\"No common keys between ed_df and ed_first\")\n",
    "ed_df = ed_df.merge(ed_first, on=merge_keys_first, how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112697d",
   "metadata": {},
   "source": [
    "## Phase 2 — Hospital admission context and outcomes\n",
    "\n",
    "**Rationale:** Add admission-level outcomes and demographics for downstream stratification and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76aad284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:27:08.857597Z",
     "iopub.status.busy": "2026-02-04T23:27:08.857440Z",
     "iopub.status.idle": "2026-02-04T23:27:13.330352Z",
     "shell.execute_reply": "2026-02-04T23:27:13.330017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions rows: 40151\n",
      "Admissions discordance (expire_flag vs deathtime): 3\n"
     ]
    }
   ],
   "source": [
    "# Admissions fields\n",
    "SQL[\"admit_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  a.hadm_id,\n",
    "  a.admittime,\n",
    "  a.dischtime,\n",
    "  a.deathtime,\n",
    "  a.hospital_expire_flag,\n",
    "  a.admission_type,\n",
    "  a.admission_location,\n",
    "  a.discharge_location,\n",
    "  a.insurance,\n",
    "  a.language,\n",
    "  a.marital_status,\n",
    "  a.race AS hosp_race\n",
    "FROM `{PHYS}.{HOSP}.admissions` a\n",
    "JOIN hadms h USING (hadm_id)\n",
    "\"\"\"\n",
    "\n",
    "admit = run_sql_bq(sql(\"admit_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"Admissions rows:\", len(admit))\n",
    "\n",
    "ed_df = ed_df.merge(admit, on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "# Merge ventilation flags/times (hadm-level)\n",
    "if \"vent_combined\" in globals():\n",
    "    ed_df = ed_df.merge(vent_combined, on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "# Derived outcomes\n",
    "ed_df[\"hospital_los_hours\"] = (ed_df[\"dischtime\"] - ed_df[\"admittime\"]).dt.total_seconds() / 3600.0\n",
    "ed_df[\"in_hospital_death\"] = ((ed_df[\"hospital_expire_flag\"] == 1) | ed_df[\"deathtime\"].notna()).astype(\"int64\")\n",
    "\n",
    "# Concordance check\n",
    "discord = (\n",
    "    ((ed_df[\"hospital_expire_flag\"] == 1) & ed_df[\"deathtime\"].isna()) |\n",
    "    ((ed_df[\"hospital_expire_flag\"] == 0) & ed_df[\"deathtime\"].notna())\n",
    ")\n",
    "print(\"Admissions discordance (expire_flag vs deathtime):\", int(discord.sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904f650",
   "metadata": {},
   "source": [
    "## Phase 3 — ICU timing and LOS\n",
    "\n",
    "**Rationale:** Capture ICU exposure, timing, and total LOS for severity stratification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5174a456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:27:13.334513Z",
     "iopub.status.busy": "2026-02-04T23:27:13.334362Z",
     "iopub.status.idle": "2026-02-04T23:27:18.018212Z",
     "shell.execute_reply": "2026-02-04T23:27:18.017835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU stay rows: 31393\n"
     ]
    }
   ],
   "source": [
    "# ICU stays (aggregate per hadm)\n",
    "SQL[\"icu_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  i.hadm_id,\n",
    "  i.stay_id AS icu_stay_id,\n",
    "  i.intime,\n",
    "  i.outtime,\n",
    "  i.los,\n",
    "  i.first_careunit,\n",
    "  i.last_careunit\n",
    "FROM `{PHYS}.{ICU}.icustays` i\n",
    "JOIN hadms h USING (hadm_id)\n",
    "\"\"\"\n",
    "\n",
    "icu = run_sql_bq(sql(\"icu_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"ICU stay rows:\", len(icu))\n",
    "\n",
    "if len(icu) > 0:\n",
    "    icu_agg = (\n",
    "        icu.sort_values([\"hadm_id\", \"intime\"]).groupby(\"hadm_id\", as_index=False)\n",
    "        .agg(\n",
    "            icu_intime_first=(\"intime\", \"min\"),\n",
    "            icu_outtime_last=(\"outtime\", \"max\"),\n",
    "            icu_los_total=(\"los\", \"sum\"),\n",
    "            n_icu_stays=(\"icu_stay_id\", \"nunique\"),\n",
    "            first_careunit=(\"first_careunit\", \"first\"),\n",
    "            last_careunit=(\"last_careunit\", \"last\"),\n",
    "        )\n",
    "    )\n",
    "    ed_df = ed_df.merge(icu_agg, on=\"hadm_id\", how=\"left\")\n",
    "else:\n",
    "    print(\"No ICU stays found for cohort.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7764f3",
   "metadata": {},
   "source": [
    "## Phase 4 — ED longitudinal vitals (0–6h)\n",
    "\n",
    "**Rationale:** Summarize early ED vitals for severity phenotyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d01b4d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:27:18.026299Z",
     "iopub.status.busy": "2026-02-04T23:27:18.026180Z",
     "iopub.status.idle": "2026-02-04T23:27:23.726647Z",
     "shell.execute_reply": "2026-02-04T23:27:23.726282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED vitals long rows: 120310\n",
      "Warning: heartrate out of range count: 1\n",
      "Warning: resprate out of range count: 3\n",
      "Warning: o2sat out of range count: 2\n"
     ]
    }
   ],
   "source": [
    "# ED vitals long + aggregates (0-6h)\n",
    "\n",
    "SQL[\"ed_vitals_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "edmap AS (\n",
    "  SELECT stay_id AS ed_stay_id, hadm_id, intime AS ed_intime\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    ")\n",
    "SELECT\n",
    "  v.stay_id AS ed_stay_id,\n",
    "  m.hadm_id,\n",
    "  m.ed_intime,\n",
    "  v.charttime,\n",
    "  v.temperature,\n",
    "  v.heartrate,\n",
    "  v.resprate,\n",
    "  v.o2sat,\n",
    "  v.sbp,\n",
    "  v.dbp,\n",
    "  v.rhythm,\n",
    "  v.pain\n",
    "FROM `{PHYS}.{ED}.vitalsign` v\n",
    "JOIN edmap m ON m.ed_stay_id = v.stay_id\n",
    "\"\"\"\n",
    "\n",
    "ed_vitals_long = run_sql_bq(sql(\"ed_vitals_sql\"), {\"hadms\": hadm_list})\n",
    "print(\"ED vitals long rows:\", len(ed_vitals_long))\n",
    "\n",
    "# Window filter: 0–6h from ED intime\n",
    "ed_vitals_long[\"dt_hours\"] = (ed_vitals_long[\"charttime\"] - ed_vitals_long[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "in_6h = ed_vitals_long[\"dt_hours\"].between(0, 6, inclusive=\"both\")\n",
    "\n",
    "agg = (\n",
    "    ed_vitals_long.loc[in_6h]\n",
    "    .groupby(\"ed_stay_id\", as_index=False)\n",
    "    .agg(\n",
    "        max_heartrate_0_6h=(\"heartrate\", \"max\"),\n",
    "        max_resprate_0_6h=(\"resprate\", \"max\"),\n",
    "        min_o2sat_0_6h=(\"o2sat\", \"min\"),\n",
    "        min_sbp_0_6h=(\"sbp\", \"min\"),\n",
    "        n_vitals_0_6h=(\"charttime\", \"count\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "ed_df = ed_df.merge(agg, on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "# Range warnings (do not drop)\n",
    "range_checks = {\n",
    "    \"heartrate\": (0, 300),\n",
    "    \"resprate\": (0, 80),\n",
    "    \"o2sat\": (0, 100),\n",
    "    \"sbp\": (0, 300),\n",
    "}\n",
    "for col, (lo, hi) in range_checks.items():\n",
    "    bad = ed_vitals_long[col].notna() & (~ed_vitals_long[col].between(lo, hi))\n",
    "    if bad.any():\n",
    "        print(f\"Warning: {col} out of range count:\", int(bad.sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91c8d5",
   "metadata": {},
   "source": [
    "## Phase 5 — Robust lab discovery + gas panels\n",
    "\n",
    "**Rationale:** Capture blood gas and key chemistry labs with label-robust item discovery and unit normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a485417b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:27:23.729175Z",
     "iopub.status.busy": "2026-02-04T23:27:23.729069Z",
     "iopub.status.idle": "2026-02-04T23:30:17.596218Z",
     "shell.execute_reply": "2026-02-04T23:30:17.595061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/lab_item_map.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Discover itemids from d_labitems\n",
    "SQL[\"labitems_sql\"] = f\"\"\"\n",
    "SELECT itemid, label, fluid, category\n",
    "FROM `{PHYS}.{HOSP}.d_labitems`\n",
    "\"\"\"\n",
    "\n",
    "labitems = run_sql_bq(sql(\"labitems_sql\"))\n",
    "\n",
    "patterns = {\n",
    "    \"gas_pco2\": re.compile(r\"\\bp\\s*co2\\b|pco2|pco₂\", re.I),\n",
    "    \"gas_ph\": re.compile(r\"\\bph\\b\", re.I),\n",
    "    \"gas_hco3\": re.compile(r\"hco3|bicarbonate\", re.I),\n",
    "    \"gas_lactate\": re.compile(r\"lactate\", re.I),\n",
    "    \"gas_specimen\": re.compile(r\"specimen|source|type\", re.I),\n",
    "    \"chem_creatinine\": re.compile(r\"creatinine\", re.I),\n",
    "    \"chem_sodium\": re.compile(r\"\\bsodium\\b\", re.I),\n",
    "    \"chem_chloride\": re.compile(r\"\\bchloride\\b\", re.I),\n",
    "    \"chem_total_co2\": re.compile(r\"carbon dioxide|total co2|\\bco2\\b\", re.I),\n",
    "    \"cbc_hemoglobin\": re.compile(r\"hemoglobin\", re.I),\n",
    "}\n",
    "\n",
    "# category filters\n",
    "cat_gas = re.compile(r\"blood\\s*gas|blood gas|arterial|venous\", re.I)\n",
    "cat_chem = re.compile(r\"chemistry|chem|blood\", re.I)\n",
    "cat_cbc = re.compile(r\"hematology|cbc\", re.I)\n",
    "\n",
    "matches = {}\n",
    "for name, pat in patterns.items():\n",
    "    dfm = labitems.copy()\n",
    "    dfm = dfm[dfm[\"label\"].str.contains(pat, na=False)]\n",
    "    if name.startswith(\"gas_\"):\n",
    "        dfm = dfm[dfm[\"category\"].str.contains(cat_gas, na=False)]\n",
    "    elif name.startswith(\"chem_\"):\n",
    "        dfm = dfm[dfm[\"category\"].str.contains(cat_chem, na=False)]\n",
    "    elif name.startswith(\"cbc_\"):\n",
    "        dfm = dfm[dfm[\"category\"].str.contains(cat_cbc, na=False)]\n",
    "    matches[name] = dfm[[\"itemid\",\"label\",\"category\"]]\n",
    "\n",
    "# Build lab_item_map with counts in cohort\n",
    "itemids_all = sorted({int(i) for dfm in matches.values() for i in dfm[\"itemid\"].tolist()})\n",
    "\n",
    "SQL[\"counts_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT itemid, COUNT(*) AS n\n",
    "FROM `{PHYS}.{HOSP}.labevents`\n",
    "WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "  AND itemid IN UNNEST(@itemids)\n",
    "GROUP BY itemid\n",
    "\"\"\"\n",
    "\n",
    "counts = run_sql_bq(sql(\"counts_sql\"), {\"hadms\": hadm_list, \"itemids\": itemids_all}) if itemids_all else pd.DataFrame(columns=[\"itemid\",\"n\"])\n",
    "\n",
    "lab_item_map = {}\n",
    "for name, dfm in matches.items():\n",
    "    tmp = dfm.merge(counts, on=\"itemid\", how=\"left\").fillna({\"n\":0})\n",
    "    lab_item_map[name] = {\n",
    "        \"pattern\": patterns[name].pattern,\n",
    "        \"items\": tmp.sort_values(\"n\", ascending=False).to_dict(orient=\"records\"),\n",
    "    }\n",
    "\n",
    "lab_item_map_path = WORK_DIR / \"lab_item_map.json\"\n",
    "lab_item_map_path.write_text(json.dumps(lab_item_map, indent=2))\n",
    "print(\"Wrote:\", lab_item_map_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3fa3fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:30:17.603714Z",
     "iopub.status.busy": "2026-02-04T23:30:17.603572Z",
     "iopub.status.idle": "2026-02-04T23:39:52.368218Z",
     "shell.execute_reply": "2026-02-04T23:39:52.365943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labs long rows: 277691\n",
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/lab_unit_audit.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract labevents within ED windows\n",
    "\n",
    "# assemble itemid lists\n",
    "itemid_sets = {k: [int(x[\"itemid\"]) for x in v[\"items\"]] for k, v in lab_item_map.items()}\n",
    "# flatten\n",
    "all_itemids = sorted({i for v in itemid_sets.values() for i in v})\n",
    "\n",
    "SQL[\"labs_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "eds AS (\n",
    "  SELECT stay_id AS ed_stay_id, hadm_id, intime AS ed_intime\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    ")\n",
    "SELECT\n",
    "  e.ed_stay_id,\n",
    "  l.subject_id,\n",
    "  l.hadm_id,\n",
    "  l.itemid,\n",
    "  l.charttime,\n",
    "  l.specimen_id,\n",
    "  l.valuenum,\n",
    "  l.valueuom\n",
    "FROM `{PHYS}.{HOSP}.labevents` l\n",
    "JOIN eds e ON e.hadm_id = l.hadm_id\n",
    "WHERE l.itemid IN UNNEST(@itemids)\n",
    "  AND l.charttime BETWEEN e.ed_intime AND TIMESTAMP_ADD(e.ed_intime, INTERVAL 24 HOUR)\n",
    "\"\"\"\n",
    "\n",
    "labs_long = run_sql_bq(sql(\"labs_sql\"), {\"hadms\": hadm_list, \"itemids\": all_itemids})\n",
    "print(\"Labs long rows:\", len(labs_long))\n",
    "\n",
    "# Unit audit for pCO2\n",
    "pco2_ids = itemid_sets.get(\"gas_pco2\", [])\n",
    "unit_audit = (\n",
    "    labs_long.loc[labs_long[\"itemid\"].isin(pco2_ids)]\n",
    "    .groupby(\"valueuom\", dropna=False)\n",
    "    .size().reset_index(name=\"n\")\n",
    ")\n",
    "unit_audit_path = WORK_DIR / \"lab_unit_audit.csv\"\n",
    "unit_audit.to_csv(unit_audit_path, index=False)\n",
    "print(\"Wrote:\", unit_audit_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90790b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:39:52.378926Z",
     "iopub.status.busy": "2026-02-04T23:39:52.378800Z",
     "iopub.status.idle": "2026-02-04T23:39:52.670223Z",
     "shell.execute_reply": "2026-02-04T23:39:52.669876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reconstruct gas panels by specimen_id within ED stay\n",
    "\n",
    "pco2_ids = set(itemid_sets.get(\"gas_pco2\", []))\n",
    "ph_ids = set(itemid_sets.get(\"gas_ph\", []))\n",
    "hco3_ids = set(itemid_sets.get(\"gas_hco3\", []))\n",
    "lact_ids = set(itemid_sets.get(\"gas_lactate\", []))\n",
    "\n",
    "labs = labs_long.copy()\n",
    "\n",
    "# Convert pCO2 kPa to mmHg when needed\n",
    "is_kpa = labs[\"valueuom\"].astype(str).str.lower().str.contains(\"kpa\", na=False)\n",
    "mask_pco2 = labs[\"itemid\"].isin(pco2_ids)\n",
    "if mask_pco2.any() and is_kpa.any():\n",
    "    labs.loc[mask_pco2 & is_kpa, \"valuenum\"] = labs.loc[mask_pco2 & is_kpa, \"valuenum\"] * 7.50062\n",
    "    labs.loc[mask_pco2 & is_kpa, \"valueuom\"] = \"mmHg\"\n",
    "\n",
    "# panel by specimen_id\n",
    "panel = (\n",
    "    labs.groupby([\"ed_stay_id\",\"specimen_id\"], as_index=False)\n",
    "    .agg(panel_time=(\"charttime\",\"min\"))\n",
    ")\n",
    "\n",
    "# attach analytes\n",
    "\n",
    "def pick_analyte(df, ids, name):\n",
    "    tmp = df.loc[df[\"itemid\"].isin(ids), [\"ed_stay_id\",\"specimen_id\",\"valuenum\"]]\n",
    "    tmp = tmp.rename(columns={\"valuenum\": name})\n",
    "    return tmp.groupby([\"ed_stay_id\",\"specimen_id\"], as_index=False).first()\n",
    "\n",
    "if pco2_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, pco2_ids, \"pco2\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "if ph_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, ph_ids, \"ph\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "if hco3_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, hco3_ids, \"hco3\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "if lact_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, lact_ids, \"lactate\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "\n",
    "# First panel per ED stay\n",
    "first_panel = (\n",
    "    panel.sort_values([\"ed_stay_id\",\"panel_time\"]).groupby(\"ed_stay_id\", as_index=False).first()\n",
    ")\n",
    "\n",
    "# 0–6h and 0–24h extrema\n",
    "panel = panel.merge(ed_df[[\"ed_stay_id\",\"ed_intime\"]], on=\"ed_stay_id\", how=\"left\")\n",
    "panel[\"dt_hours\"] = (panel[\"panel_time\"] - panel[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Ensure expected panel columns exist even if analyte is absent\n",
    "for col in [\"pco2\", \"ph\", \"hco3\", \"lactate\"]:\n",
    "    if col not in panel.columns:\n",
    "        panel[col] = pd.NA\n",
    "\n",
    "p06 = panel.loc[panel[\"dt_hours\"].between(0,6, inclusive=\"both\")]\n",
    "p24 = panel.loc[panel[\"dt_hours\"].between(0,24, inclusive=\"both\")]\n",
    "\n",
    "agg06 = p06.groupby(\"ed_stay_id\", as_index=False).agg(max_pco2_0_6h=(\"pco2\",\"max\"), min_ph_0_6h=(\"ph\",\"min\"))\n",
    "agg24 = p24.groupby(\"ed_stay_id\", as_index=False).agg(max_pco2_0_24h=(\"pco2\",\"max\"), min_ph_0_24h=(\"ph\",\"min\"))\n",
    "\n",
    "ed_df = ed_df.merge(first_panel[[\"ed_stay_id\",\"panel_time\",\"pco2\",\"ph\",\"hco3\",\"lactate\"]].rename(\n",
    "    columns={\"panel_time\":\"first_gas_time\",\"pco2\":\"first_pco2\",\"ph\":\"first_ph\",\"hco3\":\"first_hco3\",\"lactate\":\"first_lactate\"}\n",
    "), on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "ed_df = ed_df.merge(agg06, on=\"ed_stay_id\", how=\"left\")\n",
    "ed_df = ed_df.merge(agg24, on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8759509b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:39:52.671865Z",
     "iopub.status.busy": "2026-02-04T23:39:52.671753Z",
     "iopub.status.idle": "2026-02-04T23:39:52.740376Z",
     "shell.execute_reply": "2026-02-04T23:39:52.740109Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/n84t7b8171lf64smq4ddvw1m0000gn/T/ipykernel_95316/2163351449.py:57: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  panel[\"source\"] = panel[\"source\"].fillna(panel[\"source_pco2\"])\n"
     ]
    }
   ],
   "source": [
    "# ABG vs VBG classification (specimen- and label-based inference)\n",
    "\n",
    "# Use label heuristics from d_labitems if available (arterial/venous hints)\n",
    "labitems_map = (\n",
    "    labitems.set_index(\"itemid\")[[\"label\", \"fluid\"]]\n",
    "    .fillna(\"\")\n",
    "    .to_dict(\"index\")\n",
    ")\n",
    "\n",
    "def _infer_source_text(text: str) -> str | None:\n",
    "    if re.search(r\"(arterial|abg|a[- ]?line|\\bart\\b)\", text):\n",
    "        return \"arterial\"\n",
    "    if re.search(r\"(venous|vbg|central|mixed|\\bven\\b)\", text):\n",
    "        return \"venous\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def infer_source_item(itemid):\n",
    "    meta = labitems_map.get(itemid, {})\n",
    "    text = f\"{meta.get('label','')} {meta.get('fluid','')}\".lower()\n",
    "    return _infer_source_text(text)\n",
    "\n",
    "# Infer source per specimen_id using ANY item label within the specimen\n",
    "spec_source = None\n",
    "if \"specimen_id\" in labs.columns and labs[\"specimen_id\"].notna().any():\n",
    "    spec_items = labs.loc[labs[\"specimen_id\"].notna(), [\"ed_stay_id\", \"specimen_id\", \"itemid\"]].drop_duplicates()\n",
    "    spec_items[\"source_hint\"] = spec_items[\"itemid\"].map(infer_source_item)\n",
    "\n",
    "    def _resolve_source(s):\n",
    "        s = s.dropna()\n",
    "        if (s == \"arterial\").any():\n",
    "            return \"arterial\"\n",
    "        if (s == \"venous\").any():\n",
    "            return \"venous\"\n",
    "        return \"unknown\"\n",
    "\n",
    "    spec_source = (\n",
    "        spec_items.groupby([\"ed_stay_id\", \"specimen_id\"], as_index=False)[\"source_hint\"]\n",
    "        .apply(_resolve_source)\n",
    "        .rename(columns={\"source_hint\": \"source\"})\n",
    "    )\n",
    "\n",
    "if spec_source is not None:\n",
    "    panel = panel.merge(spec_source, on=[\"ed_stay_id\", \"specimen_id\"], how=\"left\")\n",
    "\n",
    "# Fallback: assign source based on pco2 item label\n",
    "if pco2_ids:\n",
    "    pco2_itemid = (\n",
    "        labs.loc[labs[\"itemid\"].isin(pco2_ids), [\"ed_stay_id\", \"specimen_id\", \"itemid\"]]\n",
    "        .groupby([\"ed_stay_id\", \"specimen_id\"], as_index=False)[\"itemid\"].first()\n",
    "    )\n",
    "    pco2_itemid[\"source_pco2\"] = pco2_itemid[\"itemid\"].map(infer_source_item)\n",
    "    panel = panel.merge(pco2_itemid[[\"ed_stay_id\", \"specimen_id\", \"source_pco2\"]], on=[\"ed_stay_id\", \"specimen_id\"], how=\"left\")\n",
    "\n",
    "    if \"source\" in panel.columns:\n",
    "        panel[\"source\"] = panel[\"source\"].where(panel[\"source\"] != \"unknown\", pd.NA)\n",
    "        panel[\"source\"] = panel[\"source\"].fillna(panel[\"source_pco2\"])\n",
    "    else:\n",
    "        panel[\"source\"] = panel[\"source_pco2\"]\n",
    "    panel = panel.drop(columns=[\"source_pco2\"])\n",
    "else:\n",
    "    if \"source\" not in panel.columns:\n",
    "        panel[\"source\"] = \"unknown\"\n",
    "\n",
    "panel[\"source\"] = panel[\"source\"].fillna(\"unknown\")\n",
    "\n",
    "# flags\n",
    "panel[\"flag_abg_hypercapnia\"] = ((panel[\"source\"]==\"arterial\") & (panel[\"pco2\"]>=45)).astype(int)\n",
    "panel[\"flag_vbg_hypercapnia\"] = ((panel[\"source\"]==\"venous\") & (panel[\"pco2\"]>=50)).astype(int)\n",
    "panel[\"flag_any_gas_hypercapnia\"] = ((panel[\"pco2\"]>=45)).astype(int)\n",
    "\n",
    "# per-stay unknown source rate\n",
    "if len(panel) > 0:\n",
    "    unk_rate = (\n",
    "        panel.assign(_unk=(panel[\"source\"].fillna(\"unknown\") == \"unknown\"))\n",
    "             .groupby(\"ed_stay_id\", as_index=False)[\"_unk\"].mean()\n",
    "             .rename(columns={\"_unk\": \"gas_source_unknown_rate\"})\n",
    "    )\n",
    "else:\n",
    "    unk_rate = panel[[\"ed_stay_id\"]].drop_duplicates()\n",
    "    unk_rate[\"gas_source_unknown_rate\"] = 1.0\n",
    "\n",
    "# collapse to ED stay flags\n",
    "flags = panel.groupby(\"ed_stay_id\", as_index=False).agg(\n",
    "    flag_abg_hypercapnia=(\"flag_abg_hypercapnia\",\"max\"),\n",
    "    flag_vbg_hypercapnia=(\"flag_vbg_hypercapnia\",\"max\"),\n",
    "    flag_any_gas_hypercapnia=(\"flag_any_gas_hypercapnia\",\"max\"),\n",
    ")\n",
    "\n",
    "ed_df = ed_df.merge(flags, on=\"ed_stay_id\", how=\"left\")\n",
    "ed_df = ed_df.merge(unk_rate, on=\"ed_stay_id\", how=\"left\")\n",
    "ed_df[\"gas_source_unknown_rate\"] = ed_df[\"gas_source_unknown_rate\"].fillna(1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b49df4",
   "metadata": {},
   "source": [
    "## Phase 5C — ICU POC blood gases (chartevents, optional)\n",
    "\n",
    "**Rationale:** Capture ICU point-of-care gases if central lab labevents miss early measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1799ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:39:52.742831Z",
     "iopub.status.busy": "2026-02-04T23:39:52.742674Z",
     "iopub.status.idle": "2026-02-04T23:39:54.907726Z",
     "shell.execute_reply": "2026-02-04T23:39:54.907268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU POC candidate itemids: 6\n"
     ]
    }
   ],
   "source": [
    "# Discover ICU POC itemids from d_items\n",
    "\n",
    "SQL[\"ditems_sql\"] = f\"\"\"\n",
    "SELECT itemid, label, category\n",
    "FROM `{PHYS}.{ICU}.d_items`\n",
    "\"\"\"\n",
    "\n",
    "ditems = run_sql_bq(sql(\"ditems_sql\"))\n",
    "\n",
    "icu_patterns = {\n",
    "    \"pco2\": re.compile(r\"\bp\\s*co2\b|pco2|pco₂\", re.I),\n",
    "    \"ph\": re.compile(r\"\bph\b\", re.I),\n",
    "    \"hco3\": re.compile(r\"hco3|bicarbonate\", re.I),\n",
    "    \"lactate\": re.compile(r\"lactate\", re.I),\n",
    "    \"specimen\": re.compile(r\"specimen|source|type\", re.I),\n",
    "}\n",
    "\n",
    "icu_cat = re.compile(r\"blood\\s*gas|blood gas|resp|arterial|venous\", re.I)\n",
    "\n",
    "icu_matches = {}\n",
    "for name, pat in icu_patterns.items():\n",
    "    dfm = ditems[ditems[\"label\"].str.contains(pat, na=False)]\n",
    "    dfm = dfm[dfm[\"category\"].str.contains(icu_cat, na=False)]\n",
    "    icu_matches[name] = dfm[[\"itemid\",\"label\",\"category\"]]\n",
    "\n",
    "icu_itemids = sorted({int(i) for dfm in icu_matches.values() for i in dfm[\"itemid\"].tolist()})\n",
    "print(\"ICU POC candidate itemids:\", len(icu_itemids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa3c01a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:39:54.910843Z",
     "iopub.status.busy": "2026-02-04T23:39:54.910663Z",
     "iopub.status.idle": "2026-02-04T23:40:02.468179Z",
     "shell.execute_reply": "2026-02-04T23:40:02.467810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU POC long rows: 45400\n",
      "ICU POC incremental hypercapnia cases (ED stays): 0\n"
     ]
    }
   ],
   "source": [
    "# Extract ICU chartevents within ED 0–24h window for cohort ICU stays\n",
    "\n",
    "if len(icu_itemids) == 0:\n",
    "    icu_poc_long = pd.DataFrame()\n",
    "    print(\"No ICU POC itemids found.\")\n",
    "else:\n",
    "    # ensure icu stay ids available\n",
    "    if 'icu' not in globals():\n",
    "        raise NameError(\"ICU stays table 'icu' not found; run ICU phase first.\")\n",
    "\n",
    "    icu_stays = icu[[\"icu_stay_id\",\"hadm_id\",\"intime\"]].copy()\n",
    "    icu_stays = icu_stays.dropna(subset=[\"icu_stay_id\"])\n",
    "\n",
    "    icu_poc_sql = f\"\"\"\n",
    "    WITH icu_stays AS (\n",
    "      SELECT stay_id AS icu_stay_id, hadm_id\n",
    "      FROM `{PHYS}.{ICU}.icustays`\n",
    "      WHERE stay_id IN UNNEST(@icu_stay_ids)\n",
    "    ),\n",
    "    eds AS (\n",
    "      SELECT stay_id AS ed_stay_id, hadm_id, intime AS ed_intime\n",
    "      FROM `{PHYS}.{ED}.edstays`\n",
    "      WHERE hadm_id IN (SELECT hadm_id FROM icu_stays)\n",
    "    )\n",
    "    SELECT\n",
    "      s.icu_stay_id,\n",
    "      e.ed_stay_id,\n",
    "      e.hadm_id,\n",
    "      ce.charttime,\n",
    "      ce.itemid,\n",
    "      ce.valuenum,\n",
    "      ce.valueuom\n",
    "    FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "    JOIN icu_stays s ON s.icu_stay_id = ce.stay_id\n",
    "    JOIN eds e ON e.hadm_id = s.hadm_id\n",
    "    WHERE ce.itemid IN UNNEST(@itemids)\n",
    "      AND ce.charttime BETWEEN e.ed_intime AND TIMESTAMP_ADD(e.ed_intime, INTERVAL 24 HOUR)\n",
    "    \"\"\"\n",
    "\n",
    "    icu_poc_long = run_sql_bq(icu_poc_sql, {\"icu_stay_ids\": icu_stays[\"icu_stay_id\"].astype(int).tolist(), \"itemids\": icu_itemids})\n",
    "    print(\"ICU POC long rows:\", len(icu_poc_long))\n",
    "\n",
    "# Build panels by 5-minute bins per ICU stay\n",
    "if len(icu_poc_long) > 0:\n",
    "    icu_poc_long[\"time_bin\"] = icu_poc_long[\"charttime\"].dt.floor(\"5min\")\n",
    "\n",
    "    def pick_from_ids(df, ids, name):\n",
    "        tmp = df.loc[df[\"itemid\"].isin(ids), [\"icu_stay_id\",\"time_bin\",\"valuenum\"]]\n",
    "        tmp = tmp.rename(columns={\"valuenum\": name})\n",
    "        return tmp.groupby([\"icu_stay_id\",\"time_bin\"], as_index=False).first()\n",
    "\n",
    "    pco2_ids = set(icu_matches.get(\"pco2\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "    ph_ids = set(icu_matches.get(\"ph\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "    hco3_ids = set(icu_matches.get(\"hco3\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "    lact_ids = set(icu_matches.get(\"lactate\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "\n",
    "    panel_poc = (\n",
    "        icu_poc_long.groupby([\"icu_stay_id\",\"time_bin\"], as_index=False)\n",
    "        .agg(panel_time=(\"charttime\",\"min\"))\n",
    "    )\n",
    "    if pco2_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, pco2_ids, \"pco2\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "    if ph_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, ph_ids, \"ph\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "    if hco3_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, hco3_ids, \"hco3\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "    if lact_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, lact_ids, \"lactate\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "\n",
    "    # map to ED stay via hadm_id\n",
    "    panel_poc = panel_poc.merge(icu[[\"icu_stay_id\",\"hadm_id\"]], on=\"icu_stay_id\", how=\"left\")\n",
    "    panel_poc = panel_poc.merge(ed_df[[\"ed_stay_id\",\"hadm_id\",\"ed_intime\"]], on=\"hadm_id\", how=\"left\")\n",
    "    panel_poc[\"dt_hours\"] = (panel_poc[\"panel_time\"] - panel_poc[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "else:\n",
    "    panel_poc = pd.DataFrame()\n",
    "\n",
    "# Ensure expected panel_poc columns exist even if analyte is absent\n",
    "for col in [\"pco2\", \"ph\", \"hco3\", \"lactate\"]:\n",
    "    if col not in panel_poc.columns:\n",
    "        panel_poc[col] = pd.NA\n",
    "\n",
    "poc_flags = pd.DataFrame(columns=[\"ed_stay_id\", \"flag_any_gas_hypercapnia_poc\"])\n",
    "if len(panel_poc) > 0:\n",
    "    p24_poc = panel_poc.loc[panel_poc[\"dt_hours\"].between(0,24, inclusive=\"both\")].copy()\n",
    "    p24_poc.loc[:, \"flag_any_gas_hypercapnia_poc\"] = (p24_poc[\"pco2\"] >= 45).astype(\"Int64\")\n",
    "\n",
    "    poc_flags = p24_poc.groupby(\"ed_stay_id\", as_index=False).agg(\n",
    "        flag_any_gas_hypercapnia_poc=(\"flag_any_gas_hypercapnia_poc\",\"max\")\n",
    "    )\n",
    "\n",
    "# Avoid duplicate column on re-run\n",
    "if \"flag_any_gas_hypercapnia_poc\" in ed_df.columns:\n",
    "    ed_df = ed_df.drop(columns=[\"flag_any_gas_hypercapnia_poc\"])\n",
    "\n",
    "if len(poc_flags) > 0:\n",
    "    ed_df = ed_df.merge(poc_flags, on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "# incremental yield\n",
    "base = ed_df.get(\"flag_any_gas_hypercapnia\", pd.Series(0, index=ed_df.index)).fillna(0).astype(int)\n",
    "poc = ed_df.get(\"flag_any_gas_hypercapnia_poc\", pd.Series(0, index=ed_df.index)).fillna(0).astype(int)\n",
    "inc = ((base == 0) & (poc == 1)).sum()\n",
    "print(\"ICU POC incremental hypercapnia cases (ED stays):\", int(inc))\n",
    "\n",
    "# optional export\n",
    "if len(panel_poc) > 0:\n",
    "    panel_poc.to_parquet(DATA_DIR / \"gas_panels_poc.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c0913",
   "metadata": {},
   "source": [
    "## Phase 6 — BMI/anthropometrics (OMR)\n",
    "\n",
    "**Rationale:** Add BMI/height/weight closest to ED presentation when available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c07cecc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:40:02.473698Z",
     "iopub.status.busy": "2026-02-04T23:40:02.473511Z",
     "iopub.status.idle": "2026-02-04T23:40:06.412942Z",
     "shell.execute_reply": "2026-02-04T23:40:06.411940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMR rows: 46494\n"
     ]
    }
   ],
   "source": [
    "# OMR BMI/height/weight\n",
    "\n",
    "try:\n",
    "    omr_sql = f\"\"\"\n",
    "    SELECT subject_id, chartdate, result_name, result_value\n",
    "    FROM `{PHYS}.{HOSP}.omr`\n",
    "    WHERE LOWER(result_name) IN ('bmi','height','weight')\n",
    "    \"\"\"\n",
    "    omr = run_sql_bq(omr_sql)\n",
    "    print(\"OMR rows:\", len(omr))\n",
    "\n",
    "    if len(omr) == 0:\n",
    "        print(\"OMR query returned 0 rows; BMI/height/weight will remain missing.\")\n",
    "    else:\n",
    "        omr[\"result_name\"] = omr[\"result_name\"].str.lower()\n",
    "        omr[\"result_value_num\"] = (\n",
    "            omr[\"result_value\"].astype(str)\n",
    "            .str.extract(r\"(-?\\d+(?:\\.\\d+)?)\", expand=False)\n",
    "        )\n",
    "        omr[\"result_value_num\"] = pd.to_numeric(omr[\"result_value_num\"], errors=\"coerce\")\n",
    "\n",
    "        omr_pivot = (\n",
    "            omr.pivot_table(\n",
    "                index=[\"subject_id\",\"chartdate\"],\n",
    "                columns=\"result_name\",\n",
    "                values=\"result_value_num\",\n",
    "                aggfunc=\"first\",\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # attach closest pre-ED (within 365 days)\n",
    "        ed_dates = ed_df[[\"ed_stay_id\",\"subject_id\",\"ed_intime\"]].copy()\n",
    "        ed_dates[\"ed_date\"] = ed_dates[\"ed_intime\"].dt.date\n",
    "        omr_pivot[\"chartdate\"] = pd.to_datetime(omr_pivot[\"chartdate\"]).dt.date\n",
    "\n",
    "        merged = ed_dates.merge(omr_pivot, on=\"subject_id\", how=\"left\")\n",
    "        merged[\"days_before\"] = (pd.to_datetime(merged[\"ed_date\"]) - pd.to_datetime(merged[\"chartdate\"])).dt.days\n",
    "        merged = merged.loc[(merged[\"days_before\"] >= 0) & (merged[\"days_before\"] <= 365)]\n",
    "\n",
    "        closest = (\n",
    "            merged.sort_values([\"ed_stay_id\",\"days_before\"]).groupby(\"ed_stay_id\", as_index=False).first()\n",
    "            .rename(columns={\n",
    "                \"bmi\":\"bmi_closest_pre_ed\",\n",
    "                \"height\":\"height_closest_pre_ed\",\n",
    "                \"weight\":\"weight_closest_pre_ed\",\n",
    "            })\n",
    "        )\n",
    "\n",
    "        ed_df = ed_df.merge(\n",
    "            closest[[\"ed_stay_id\",\"bmi_closest_pre_ed\",\"height_closest_pre_ed\",\"weight_closest_pre_ed\"]],\n",
    "            on=\"ed_stay_id\", how=\"left\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(\"OMR not available or failed:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5247cb",
   "metadata": {},
   "source": [
    "## Phase 7 — ICD comorbidity flags\n",
    "\n",
    "**Rationale:** Derive comorbidity indicators from index admission ICD codes for stratified analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f462dbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:40:06.415658Z",
     "iopub.status.busy": "2026-02-04T23:40:06.415521Z",
     "iopub.status.idle": "2026-02-04T23:43:59.363420Z",
     "shell.execute_reply": "2026-02-04T23:43:59.362320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_copd 2760\n",
      "flag_osa_ohs 1891\n",
      "flag_chf 4685\n",
      "flag_neuromuscular 106\n",
      "flag_opioid_substance 830\n",
      "flag_pneumonia 2878\n"
     ]
    }
   ],
   "source": [
    "# ICD code pulls for comorbidity flags (hospital + ED; combined OR)\n",
    "# NOTE: Use prefix filters to reduce CPU and avoid regex-heavy scans.\n",
    "\n",
    "FLAGS = [\n",
    "    \"flag_copd\",\"flag_osa_ohs\",\"flag_chf\",\"flag_neuromuscular\",\n",
    "    \"flag_opioid_substance\",\"flag_pneumonia\",\n",
    "]\n",
    "\n",
    "SQL[\"icd_flags_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "icd AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")) AS code_norm\n",
    "  FROM `{PHYS}.{HOSP}.diagnoses_icd`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "    AND (\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J43\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J44\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"G473\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"E662\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"I50\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"G12\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"G70\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"G71\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"F11\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"T40\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"F13\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J12\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J13\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J14\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J15\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J16\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J17\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(icd_code, \\\".\\\", \\\"\\\")), \\\"J18\\\")\n",
    "    )\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"J43\\\") OR STARTS_WITH(code_norm, \\\"J44\\\"), 1, 0)) AS flag_copd,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"G473\\\") OR STARTS_WITH(code_norm, \\\"E662\\\"), 1, 0)) AS flag_osa_ohs,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"I50\\\"), 1, 0)) AS flag_chf,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"G12\\\") OR STARTS_WITH(code_norm, \\\"G70\\\") OR STARTS_WITH(code_norm, \\\"G71\\\"), 1, 0)) AS flag_neuromuscular,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"F11\\\") OR STARTS_WITH(code_norm, \\\"T40\\\") OR STARTS_WITH(code_norm, \\\"F13\\\"), 1, 0)) AS flag_opioid_substance,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"J12\\\") OR STARTS_WITH(code_norm, \\\"J13\\\") OR STARTS_WITH(code_norm, \\\"J14\\\") OR STARTS_WITH(code_norm, \\\"J15\\\") OR STARTS_WITH(code_norm, \\\"J16\\\") OR STARTS_WITH(code_norm, \\\"J17\\\") OR STARTS_WITH(code_norm, \\\"J18\\\"), 1, 0)) AS flag_pneumonia\n",
    "FROM icd\n",
    "GROUP BY hadm_id\n",
    "\"\"\"\n",
    "\n",
    "SQL[\"ed_icd_flags_sql\"] = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "ed_dx AS (\n",
    "  SELECT\n",
    "    s.hadm_id,\n",
    "    UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")) AS code_norm\n",
    "  FROM `{PHYS}.{ED}.diagnosis` d\n",
    "  JOIN `{PHYS}.{ED}.edstays` s\n",
    "    ON s.stay_id = d.stay_id\n",
    "  WHERE s.hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "    AND (\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J43\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J44\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"G473\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"E662\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"I50\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"G12\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"G70\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"G71\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"F11\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"T40\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"F13\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J12\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J13\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J14\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J15\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J16\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J17\\\") OR\n",
    "      STARTS_WITH(UPPER(REPLACE(d.icd_code, \\\".\\\", \\\"\\\")), \\\"J18\\\")\n",
    "    )\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"J43\\\") OR STARTS_WITH(code_norm, \\\"J44\\\"), 1, 0)) AS flag_copd,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"G473\\\") OR STARTS_WITH(code_norm, \\\"E662\\\"), 1, 0)) AS flag_osa_ohs,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"I50\\\"), 1, 0)) AS flag_chf,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"G12\\\") OR STARTS_WITH(code_norm, \\\"G70\\\") OR STARTS_WITH(code_norm, \\\"G71\\\"), 1, 0)) AS flag_neuromuscular,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"F11\\\") OR STARTS_WITH(code_norm, \\\"T40\\\") OR STARTS_WITH(code_norm, \\\"F13\\\"), 1, 0)) AS flag_opioid_substance,\n",
    "  MAX(IF(STARTS_WITH(code_norm, \\\"J12\\\") OR STARTS_WITH(code_norm, \\\"J13\\\") OR STARTS_WITH(code_norm, \\\"J14\\\") OR STARTS_WITH(code_norm, \\\"J15\\\") OR STARTS_WITH(code_norm, \\\"J16\\\") OR STARTS_WITH(code_norm, \\\"J17\\\") OR STARTS_WITH(code_norm, \\\"J18\\\"), 1, 0)) AS flag_pneumonia\n",
    "FROM ed_dx\n",
    "GROUP BY hadm_id\n",
    "\"\"\"\n",
    "\n",
    "flag_hosp = run_sql_bq(sql(\"icd_flags_sql\"), {\"hadms\": hadm_list})\n",
    "flag_ed = run_sql_bq(sql(\"ed_icd_flags_sql\"), {\"hadms\": hadm_list})\n",
    "\n",
    "flag_hosp = flag_hosp.rename(columns={k: f\"{k}_hosp\" for k in FLAGS})\n",
    "flag_ed = flag_ed.rename(columns={k: f\"{k}_ed\" for k in FLAGS})\n",
    "\n",
    "flag_df = flag_hosp.merge(flag_ed, on=\"hadm_id\", how=\"outer\")\n",
    "for k in FLAGS:\n",
    "    hosp_col = f\"{k}_hosp\"\n",
    "    ed_col = f\"{k}_ed\"\n",
    "    if hosp_col not in flag_df.columns:\n",
    "        flag_df[hosp_col] = 0\n",
    "    if ed_col not in flag_df.columns:\n",
    "        flag_df[ed_col] = 0\n",
    "    flag_df[k] = ((flag_df[hosp_col].fillna(0).astype(int) == 1) | (flag_df[ed_col].fillna(0).astype(int) == 1)).astype(int)\n",
    "\n",
    "# merge into admission-level and ED-stay-level frames (override if present)\n",
    "for _df_name in [\"df\", \"ed_df\"]:\n",
    "    if _df_name in globals():\n",
    "        _df = globals()[_df_name]\n",
    "        drop_cols = [c for c in flag_df.columns if c != \"hadm_id\" and c in _df.columns]\n",
    "        if drop_cols:\n",
    "            _df = _df.drop(columns=drop_cols)\n",
    "        _df = _df.merge(flag_df, on=\"hadm_id\", how=\"left\")\n",
    "        globals()[_df_name] = _df\n",
    "\n",
    "# prevalence (combined flags)\n",
    "for k in FLAGS:\n",
    "    if k in ed_df.columns:\n",
    "        print(k, int(ed_df[k].fillna(0).sum()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43905020",
   "metadata": {},
   "source": [
    "## Phase 8 — Timing phenotypes and derived bands\n",
    "\n",
    "**Rationale:** Compute time-anchored hypercapnia/acidemia phenotypes for ED presentation vs later course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebdc738d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:43:59.371937Z",
     "iopub.status.busy": "2026-02-04T23:43:59.371799Z",
     "iopub.status.idle": "2026-02-04T23:43:59.386174Z",
     "shell.execute_reply": "2026-02-04T23:43:59.385946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Timing phenotypes\n",
    "\n",
    "anchor = \"ed_intime_first\" if \"ed_intime_first\" in ed_df.columns else \"ed_intime\"\n",
    "\n",
    "ed_df[\"dt_first_qualifying_gas_hours\"] = (ed_df[\"first_gas_time\"] - ed_df[anchor]).dt.total_seconds() / 3600.0\n",
    "ed_df[\"presenting_hypercapnia\"] = (ed_df[\"dt_first_qualifying_gas_hours\"] <= 6).astype(\"Int64\")\n",
    "ed_df[\"late_hypercapnia\"] = (ed_df[\"dt_first_qualifying_gas_hours\"] > 6).astype(\"Int64\")\n",
    "\n",
    "# NIV/IMV timing relative to first ED presentation\n",
    "if \"first_imv_time\" in ed_df.columns:\n",
    "    ed_df[\"dt_first_imv_hours\"] = (ed_df[\"first_imv_time\"] - ed_df[anchor]).dt.total_seconds() / 3600.0\n",
    "if \"first_niv_time\" in ed_df.columns:\n",
    "    ed_df[\"dt_first_niv_hours\"] = (ed_df[\"first_niv_time\"] - ed_df[anchor]).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Bands\n",
    "bins_ph = [-1, 7.20, 7.30, 7.35, 99]\n",
    "labels_ph = [\"<7.20\",\"7.20–7.29\",\"7.30–7.34\",\"≥7.35\"]\n",
    "ed_df[\"ph_band\"] = pd.cut(ed_df[\"first_ph\"], bins=bins_ph, labels=labels_ph)\n",
    "\n",
    "bins_hco3 = [-1, 24, 30, 999]\n",
    "labels_hco3 = [\"<24\",\"24–29\",\"≥30\"]\n",
    "ed_df[\"hco3_band\"] = pd.cut(ed_df[\"first_hco3\"], bins=bins_hco3, labels=labels_hco3)\n",
    "\n",
    "bins_lac = [-1, 2, 4, 999]\n",
    "labels_lac = [\"<2\",\"2–4\",\">4\"]\n",
    "ed_df[\"lactate_band\"] = pd.cut(ed_df[\"first_lactate\"], bins=bins_lac, labels=labels_lac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d695d3",
   "metadata": {},
   "source": [
    "## QA / audits\n",
    "\n",
    "**Rationale:** Validate joins, missingness, lab completeness, and produce reproducibility artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cfa0fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:43:59.387477Z",
     "iopub.status.busy": "2026-02-04T23:43:59.387382Z",
     "iopub.status.idle": "2026-02-04T23:43:59.405041Z",
     "shell.execute_reply": "2026-02-04T23:43:59.404811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA: ed_stay_id unique OK\n",
      "QA: first_gas_time < ed_intime by >1h: 0\n",
      "QA range check (n out-of-range):\n",
      "          col  n_bad\n",
      "     first_ph      7\n",
      "   first_pco2      8\n",
      "first_lactate      0\n"
     ]
    }
   ],
   "source": [
    "# --- QA checks (lightweight, deterministic)\n",
    "STRICT_QA = False\n",
    "\n",
    "# 1) Key uniqueness\n",
    "if 'ed_df' in globals() and 'ed_stay_id' in ed_df.columns:\n",
    "    try:\n",
    "        assert_unique(ed_df, 'ed_stay_id', 'ed_df')\n",
    "        print('QA: ed_stay_id unique OK')\n",
    "    except Exception as e:\n",
    "        print('QA FAIL:', e)\n",
    "        if STRICT_QA:\n",
    "            raise\n",
    "\n",
    "# 2) Inclusion sanity: any_hypercap_icd==0 implies gas criteria met\n",
    "if 'ed_df' in globals() and 'any_hypercap_icd' in ed_df.columns:\n",
    "    gas_flag = ed_df.get('flag_any_gas_hypercapnia', pd.Series(0, index=ed_df.index)).fillna(0).astype(int)\n",
    "    icd_flag = ed_df['any_hypercap_icd'].fillna(0).astype(int)\n",
    "    viol = (icd_flag == 0) & (gas_flag == 0)\n",
    "    n_viol = int(viol.sum())\n",
    "    print('QA: ICD==0 & Gas==0 count:', n_viol)\n",
    "    if STRICT_QA and n_viol > 0:\n",
    "        raise AssertionError('Found rows without ICD and without gas criteria.')\n",
    "\n",
    "# 3) Temporal sanity: first_gas_time >= ed_intime (allow small negative drift)\n",
    "if 'ed_df' in globals() and 'first_gas_time' in ed_df.columns and 'ed_intime' in ed_df.columns:\n",
    "    dt = (pd.to_datetime(ed_df['first_gas_time']) - pd.to_datetime(ed_df['ed_intime'])).dt.total_seconds() / 3600\n",
    "    n_neg = int((dt < -1).sum())  # allow 1h clock drift\n",
    "    print('QA: first_gas_time < ed_intime by >1h:', n_neg)\n",
    "    if STRICT_QA and n_neg > 0:\n",
    "        raise AssertionError('first_gas_time before ed_intime by >1h')\n",
    "\n",
    "# 4) Range checks (report only)\n",
    "if 'ed_df' in globals():\n",
    "    ranges = {\n",
    "        'first_ph': (6.8, 7.8),\n",
    "        'first_pco2': (10, 200),\n",
    "        'first_lactate': (0, 30),\n",
    "        'creatinine': (0, 20),\n",
    "    }\n",
    "    rc = check_ranges(ed_df, ranges)\n",
    "    if not rc.empty:\n",
    "        print('QA range check (n out-of-range):')\n",
    "        print(rc.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fef44922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:43:59.406463Z",
     "iopub.status.busy": "2026-02-04T23:43:59.406373Z",
     "iopub.status.idle": "2026-02-04T23:43:59.446112Z",
     "shell.execute_reply": "2026-02-04T23:43:59.445802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    field  missing_n  missing_pct\n",
      "76  weight_closest_pre_ed      17449     1.000000\n",
      "4      bmi_closest_pre_ed      17449     1.000000\n",
      "54  height_closest_pre_ed      17449     1.000000\n",
      "53              hco3_band      16866     0.966588\n",
      "38             first_hco3      16866     0.966588\n",
      "16        ed_first_rhythm      16748     0.959826\n",
      "5               deathtime      15131     0.867156\n",
      "69          max_pco2_0_6h      13399     0.767895\n",
      "71            min_ph_0_6h      13278     0.760961\n",
      "10     dt_first_niv_hours      12743     0.730300\n",
      "49         flag_pneumonia       9526     0.545934\n",
      "44               flag_chf       9526     0.545934\n",
      "45              flag_copd       9526     0.545934\n",
      "46     flag_neuromuscular       9526     0.545934\n",
      "47  flag_opioid_substance       9526     0.545934\n",
      "48           flag_osa_ohs       9526     0.545934\n",
      "9      dt_first_imv_hours       7150     0.409766\n",
      "63           lactate_band       6141     0.351940\n",
      "39          first_lactate       6141     0.351940\n",
      "68         max_pco2_0_24h       6027     0.345407\n",
      "40             first_pco2       6027     0.345407\n",
      "60       icu_outtime_last       5888     0.337441\n",
      "59          icu_los_total       5888     0.337441\n",
      "58       icu_intime_first       5888     0.337441\n",
      "36         first_careunit       5888     0.337441\n",
      "65          last_careunit       5888     0.337441\n",
      "72            n_icu_stays       5888     0.337441\n",
      "70           min_ph_0_24h       5737     0.328787\n",
      "73                ph_band       5737     0.328787\n",
      "41               first_ph       5737     0.328787\n",
      "% any gas panel 0–6h: 41.5\n",
      "% any gas panel 0–24h: 96.4\n",
      "% source unknown (panel-level): 100.0\n",
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/qa_summary.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# T1 — uniqueness and join explosion guard\n",
    "if ed_df[\"ed_stay_id\"].nunique() != len(ed_df):\n",
    "    raise ValueError(\"ed_stay_id not unique after merges\")\n",
    "\n",
    "# T2 — missingness summary for new fields\n",
    "new_fields = [c for c in TARGET_FIELDS if c in ed_df.columns]\n",
    "miss = pd.DataFrame({\n",
    "    \"field\": new_fields,\n",
    "    \"missing_n\": [int(ed_df[c].isna().sum()) for c in new_fields],\n",
    "    \"missing_pct\": [float(ed_df[c].isna().mean()) for c in new_fields],\n",
    "})\n",
    "print(miss.sort_values(\"missing_pct\", ascending=False).head(30))\n",
    "\n",
    "# T3 — lab capture completeness\n",
    "pct_any_6h = float(p06[\"ed_stay_id\"].nunique() / max(ed_df[\"ed_stay_id\"].nunique(),1))\n",
    "pct_any_24h = float(p24[\"ed_stay_id\"].nunique() / max(ed_df[\"ed_stay_id\"].nunique(),1))\n",
    "print(\"% any gas panel 0–6h:\", round(pct_any_6h*100,1))\n",
    "print(\"% any gas panel 0–24h:\", round(pct_any_24h*100,1))\n",
    "\n",
    "# Use per-stay unknown rate if available\n",
    "if \"gas_source_unknown_rate\" in ed_df.columns:\n",
    "    source_unknown_rate = float(ed_df[\"gas_source_unknown_rate\"].mean())\n",
    "else:\n",
    "    source_unknown_rate = 1.0\n",
    "print(\"% source unknown (panel-level):\", round(source_unknown_rate*100,1))\n",
    "\n",
    "# T4 — QA summary artifact\n",
    "qa_summary = {\n",
    "    \"ed_rows\": int(len(ed_df)),\n",
    "    \"ed_unique\": int(ed_df[\"ed_stay_id\"].nunique()),\n",
    "    \"icu_link_rate\": float(ed_df[\"icu_intime_first\"].notna().mean()) if \"icu_intime_first\" in ed_df.columns else None,\n",
    "    \"pct_any_gas_0_6h\": pct_any_6h,\n",
    "    \"pct_any_gas_0_24h\": pct_any_24h,\n",
    "    \"source_unknown_rate\": source_unknown_rate,\n",
    "}\n",
    "qa_path = WORK_DIR / \"qa_summary.json\"\n",
    "qa_path.write_text(json.dumps(qa_summary, indent=2))\n",
    "print(\"Wrote:\", qa_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ea668",
   "metadata": {},
   "source": [
    "## Outputs (ED-stay cohort + long tables)\n",
    "\n",
    "**Rationale:** Persist ED-stay analytic datasets and supporting long tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9816b512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:43:59.447416Z",
     "iopub.status.busy": "2026-02-04T23:43:59.447323Z",
     "iopub.status.idle": "2026-02-04T23:44:01.414839Z",
     "shell.execute_reply": "2026-02-04T23:44:01.414529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/cohort_ed_stay.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save outputs\n",
    "cohort_path = DATA_DIR / \"cohort_ed_stay.parquet\"\n",
    "ed_df.to_parquet(cohort_path, index=False)\n",
    "print(\"Wrote:\", cohort_path)\n",
    "\n",
    "ed_vitals_long.to_parquet(DATA_DIR / \"ed_vitals_long.parquet\", index=False)\n",
    "labs_long.to_parquet(DATA_DIR / \"labs_long.parquet\", index=False)\n",
    "panel.to_parquet(DATA_DIR / \"gas_panels.parquet\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b8609ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:44:01.416745Z",
     "iopub.status.busy": "2026-02-04T23:44:01.416580Z",
     "iopub.status.idle": "2026-02-04T23:44:14.232827Z",
     "shell.execute_reply": "2026-02-04T23:44:14.232417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_EDstay_bq_gas_20260204_211114.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Also export to Excel (tabular dataset)\n",
    "from datetime import datetime\n",
    "\n",
    "out_dir = DATA_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "xlsx_path = out_dir / f\"mimic_hypercap_EXT_EDstay_bq_gas_{timestamp}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as xw:\n",
    "    ed_df.to_excel(xw, sheet_name=\"cohort_ed_stay\", index=False)\n",
    "    # Optional: include QA tables if present\n",
    "    try:\n",
    "        miss.to_excel(xw, sheet_name=\"missingness\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"Saved:\", xlsx_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "776739a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:44:14.255011Z",
     "iopub.status.busy": "2026-02-04T23:44:14.254878Z",
     "iopub.status.idle": "2026-02-04T23:45:06.749952Z",
     "shell.execute_reply": "2026-02-04T23:45:06.749090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_all_encounters_bq_20260204_211130.xlsx\n",
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_EDcc_only_edstay_bq_20260204_211130.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Final Excel outputs requested: all encounters + ED chief-complaint only\n",
    "from datetime import datetime\n",
    "\n",
    "out_dir = DATA_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 1) All encounters meeting inclusion criteria (admission-level), with ED linkage flags\n",
    "ed_link = (\n",
    "    ed_df.groupby(\"hadm_id\", as_index=False)\n",
    "         .agg(ed_stay_id_first=(\"ed_stay_id\", \"first\"), n_ed_stays=(\"ed_stay_id\", \"nunique\"))\n",
    ")\n",
    "all_encounters = df.merge(ed_link, on=\"hadm_id\", how=\"left\")\n",
    "all_encounters[\"has_ed_encounter\"] = all_encounters[\"n_ed_stays\"].fillna(0).astype(int).gt(0).astype(int)\n",
    "all_encounters[\"encounter_source\"] = all_encounters[\"has_ed_encounter\"].map({1: \"ED-linked\", 0: \"Inpatient-only\"})\n",
    "\n",
    "all_path = out_dir / f\"mimic_hypercap_EXT_all_encounters_bq_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(all_path, engine=\"openpyxl\") as xw:\n",
    "    all_encounters.to_excel(xw, sheet_name=\"all_encounters\", index=False)\n",
    "print(\"Saved:\", all_path)\n",
    "\n",
    "# 2) ED chief-complaint-only (ED-stay level)\n",
    "if \"ed_triage_cc\" not in ed_df.columns:\n",
    "    raise KeyError(\"Column 'ed_triage_cc' not found in ed_df. Ensure ED triage merge ran.\")\n",
    "\n",
    "mask_cc = ed_df[\"ed_triage_cc\"].notna() & (ed_df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "ed_cc_only = ed_df.loc[mask_cc].copy()\n",
    "\n",
    "cc_path = out_dir / f\"mimic_hypercap_EXT_EDcc_only_edstay_bq_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(cc_path, engine=\"openpyxl\") as xw:\n",
    "    ed_cc_only.to_excel(xw, sheet_name=\"ed_cc_only\", index=False)\n",
    "print(\"Saved:\", cc_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cbe3ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:45:06.753866Z",
     "iopub.status.busy": "2026-02-04T23:45:06.753638Z",
     "iopub.status.idle": "2026-02-04T23:45:29.497735Z",
     "shell.execute_reply": "2026-02-04T23:45:29.497178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/2026-02-04 MIMICIV all with CC.xlsx\n",
      "Base rows: 17424 | Added from ED-stay: 68\n",
      "Total columns: 157\n"
     ]
    }
   ],
   "source": [
    "# Final CC output (cohort-only; excludes NLP-derived columns)\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure cc-only frames exist\n",
    "if \"df_cc\" not in globals():\n",
    "    raise NameError(\"df_cc not found. Run the ED-CC-only export cell first.\")\n",
    "\n",
    "if \"ed_cc_only\" not in globals():\n",
    "    if \"ed_df\" not in globals():\n",
    "        raise NameError(\"ed_df not found. Run the ED-stay build cells first.\")\n",
    "    if \"ed_triage_cc\" not in ed_df.columns:\n",
    "        raise KeyError(\"ed_triage_cc missing in ed_df; cannot build ed_cc_only.\")\n",
    "    _mask_cc = ed_df[\"ed_triage_cc\"].notna() & (ed_df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "    ed_cc_only = ed_df.loc[_mask_cc].copy()\n",
    "\n",
    "# Add ED-stay columns (dedup to earliest ED stay per hadm_id)\n",
    "ed_tmp = ed_cc_only.copy()\n",
    "if \"ed_intime\" in ed_tmp.columns:\n",
    "    ed_tmp = ed_tmp.sort_values([\"hadm_id\", \"ed_intime\", \"ed_stay_id\"], na_position=\"last\")\n",
    "else:\n",
    "    ed_tmp = ed_tmp.sort_values([\"hadm_id\", \"ed_stay_id\"], na_position=\"last\")\n",
    "ed_first = ed_tmp.drop_duplicates(\"hadm_id\", keep=\"first\")\n",
    "\n",
    "add_ed_cols = [c for c in ed_first.columns if c not in df_cc.columns]\n",
    "\n",
    "final_cc = df_cc.merge(ed_first[[\"hadm_id\"] + add_ed_cols], on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "out_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "out_path = DATA_DIR / f\"{out_date} MIMICIV all with CC.xlsx\"\n",
    "final_cc.to_excel(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Base rows:\", len(df_cc), \"| Added from ED-stay:\", len(add_ed_cols))\n",
    "print(\"Total columns:\", len(final_cc.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8fd8556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T23:45:29.504290Z",
     "iopub.status.busy": "2026-02-04T23:45:29.504117Z",
     "iopub.status.idle": "2026-02-04T23:45:30.070847Z",
     "shell.execute_reply": "2026-02-04T23:45:30.070578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data dictionary: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/2026-02-04 MIMICIV all with CC_data_dictionary.xlsx\n",
      "Saved data dictionary: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/2026-02-04 MIMICIV all with CC_data_dictionary.csv\n",
      "Rows: 157\n"
     ]
    }
   ],
   "source": [
    "# Data dictionary (OSF-style) for final cohort output\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Choose target dataset for dictionary\n",
    "if \"final_cc\" in globals():\n",
    "    dd_target = final_cc\n",
    "elif \"df_cc\" in globals():\n",
    "    dd_target = df_cc\n",
    "elif \"df\" in globals():\n",
    "    dd_target = df\n",
    "else:\n",
    "    raise NameError(\"No cohort dataframe found for data dictionary (expected final_cc/df_cc/df).\")\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def _readable(name: str) -> str:\n",
    "    return name.replace(\"_\", \" \").strip().title()\n",
    "\n",
    "\n",
    "def _infer_units(col: str) -> str:\n",
    "    if col.endswith(\"_hours\"):\n",
    "        return \"hours\"\n",
    "    if col.endswith(\"_time\") or col.endswith(\"_intime\") or col.endswith(\"_outtime\") or col.endswith(\"_date\"):\n",
    "        return \"datetime\"\n",
    "    if col.startswith(\"flag_\") or col.endswith(\"_flag\") or col.endswith(\"_before_imv\"):\n",
    "        return \"binary (0/1)\"\n",
    "    if col.endswith(\"_paco2\") or col.endswith(\"_pco2\"):\n",
    "        return \"mmHg\"\n",
    "    if col.endswith(\"_ph\"):\n",
    "        return \"pH\"\n",
    "    if col.endswith(\"_lactate\"):\n",
    "        return \"mmol/L\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _allowed_values(series):\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return \"\"\n",
    "    if s.dtype.kind in \"biu\":\n",
    "        vals = sorted(map(int, s.unique()))\n",
    "        if len(vals) <= 15:\n",
    "            return \", \".join(map(str, vals))\n",
    "        return f\"{min(vals)}–{max(vals)}\"\n",
    "    if s.dtype.kind in \"f\":\n",
    "        return f\"{np.nanmin(s):.3g}–{np.nanmax(s):.3g}\"\n",
    "    # object/categorical\n",
    "    vals = sorted(map(str, s.unique()))\n",
    "    return \", \".join(vals[:15]) + (\" …\" if len(vals) > 15 else \"\")\n",
    "\n",
    "\n",
    "META = {\n",
    "    # IDs\n",
    "    \"subject_id\": {\n",
    "        \"label\": \"Subject identifier\",\n",
    "        \"definition\": \"Identifier for a unique patient in MIMIC-IV.\",\n",
    "        \"source\": \"mimiciv_hosp.patients\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"hadm_id\": {\n",
    "        \"label\": \"Hospital admission identifier\",\n",
    "        \"definition\": \"Identifier for a hospital admission.\",\n",
    "        \"source\": \"mimiciv_hosp.admissions\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"ed_stay_id\": {\n",
    "        \"label\": \"ED stay identifier\",\n",
    "        \"definition\": \"Identifier for an ED stay.\",\n",
    "        \"source\": \"mimiciv_ed.edstays\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"ed_intime\": {\n",
    "        \"label\": \"ED arrival time\",\n",
    "        \"definition\": \"ED arrival time for this ED stay.\",\n",
    "        \"source\": \"mimiciv_ed.edstays\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "        \"units\": \"datetime\",\n",
    "    },\n",
    "    \"ed_outtime\": {\n",
    "        \"label\": \"ED departure time\",\n",
    "        \"definition\": \"ED departure time for this ED stay.\",\n",
    "        \"source\": \"mimiciv_ed.edstays\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "        \"units\": \"datetime\",\n",
    "    },\n",
    "    \"ed_intime_first\": {\n",
    "        \"label\": \"First ED arrival time (admission)\",\n",
    "        \"definition\": \"Earliest ED arrival time among ED stays linked to the admission.\",\n",
    "        \"source\": \"mimiciv_ed.edstays\",\n",
    "        \"derivation\": \"min(edstays.intime) per hadm_id\",\n",
    "        \"units\": \"datetime\",\n",
    "    },\n",
    "    # Demographics / triage\n",
    "    \"ed_gender\": {\n",
    "        \"label\": \"ED gender\",\n",
    "        \"definition\": \"Gender as recorded in ED stay table.\",\n",
    "        \"source\": \"mimiciv_ed.edstays\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"ed_race\": {\n",
    "        \"label\": \"ED race\",\n",
    "        \"definition\": \"Race as recorded in ED stay table.\",\n",
    "        \"source\": \"mimiciv_ed.edstays\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"hosp_race\": {\n",
    "        \"label\": \"Hospital race\",\n",
    "        \"definition\": \"Race as recorded in admissions table.\",\n",
    "        \"source\": \"mimiciv_hosp.admissions\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"ed_triage_cc\": {\n",
    "        \"label\": \"ED chief complaint\",\n",
    "        \"definition\": \"Chief complaint recorded at ED triage.\",\n",
    "        \"source\": \"mimiciv_ed.triage\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    \"ed_triage_acuity\": {\n",
    "        \"label\": \"ED triage acuity\",\n",
    "        \"definition\": \"Triage acuity level recorded at ED presentation.\",\n",
    "        \"source\": \"mimiciv_ed.triage\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "    },\n",
    "    # Outcomes\n",
    "    \"hospital_expire_flag\": {\n",
    "        \"label\": \"Hospital expire flag\",\n",
    "        \"definition\": \"Hospital mortality indicator from admissions table.\",\n",
    "        \"source\": \"mimiciv_hosp.admissions\",\n",
    "        \"derivation\": \"as recorded\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"in_hospital_death\": {\n",
    "        \"label\": \"In-hospital death\",\n",
    "        \"definition\": \"Indicator for in-hospital death during admission.\",\n",
    "        \"source\": \"mimiciv_hosp.admissions\",\n",
    "        \"derivation\": \"(hospital_expire_flag == 1) OR (deathtime not null)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    # Ventilation\n",
    "    \"imv_flag\": {\n",
    "        \"label\": \"IMV flag\",\n",
    "        \"definition\": \"Indicator of invasive mechanical ventilation during admission.\",\n",
    "        \"source\": \"ICD procedures + ICU chartevents\",\n",
    "        \"derivation\": \"max(IMV ICD flag, IMV chart flag)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"niv_flag\": {\n",
    "        \"label\": \"NIV flag\",\n",
    "        \"definition\": \"Indicator of noninvasive ventilation during admission.\",\n",
    "        \"source\": \"ICD procedures + ICU chartevents\",\n",
    "        \"derivation\": \"max(NIV ICD flag, NIV chart flag)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"first_imv_time\": {\n",
    "        \"label\": \"First IMV time\",\n",
    "        \"definition\": \"Earliest charted time of IMV in ICU chartevents (if present).\",\n",
    "        \"source\": \"mimiciv_icu.chartevents\",\n",
    "        \"derivation\": \"min charttime among IMV charted events\",\n",
    "        \"units\": \"datetime\",\n",
    "    },\n",
    "    \"first_niv_time\": {\n",
    "        \"label\": \"First NIV time\",\n",
    "        \"definition\": \"Earliest charted time of NIV in ICU chartevents (if present).\",\n",
    "        \"source\": \"mimiciv_icu.chartevents\",\n",
    "        \"derivation\": \"min charttime among NIV charted events\",\n",
    "        \"units\": \"datetime\",\n",
    "    },\n",
    "    \"dt_first_imv_hours\": {\n",
    "        \"label\": \"Hours to first IMV\",\n",
    "        \"definition\": \"Hours from first ED arrival to first IMV time.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"(first_imv_time - ed_intime_first) in hours\",\n",
    "        \"units\": \"hours\",\n",
    "    },\n",
    "    \"dt_first_niv_hours\": {\n",
    "        \"label\": \"Hours to first NIV\",\n",
    "        \"definition\": \"Hours from first ED arrival to first NIV time.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"(first_niv_time - ed_intime_first) in hours\",\n",
    "        \"units\": \"hours\",\n",
    "    },\n",
    "    \"abg_before_imv\": {\n",
    "        \"label\": \"ABG before IMV\",\n",
    "        \"definition\": \"Indicator that first ABG time precedes first IMV time.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"first_abg_time < first_imv_time\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"vbg_before_imv\": {\n",
    "        \"label\": \"VBG before IMV\",\n",
    "        \"definition\": \"Indicator that first VBG time precedes first IMV time.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"first_vbg_time < first_imv_time\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    # Gas/ABG/VBG\n",
    "    \"abg_hypercap_threshold\": {\n",
    "        \"label\": \"ABG hypercapnia threshold met\",\n",
    "        \"definition\": \"Indicator that any arterial pCO2 ≥ 45 mmHg in hosp/ICU pCO2 extraction.\",\n",
    "        \"source\": \"mimiciv_hosp.labevents + mimiciv_icu.chartevents\",\n",
    "        \"derivation\": \"max(arterial pCO2 ≥ 45) per hadm_id\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"vbg_hypercap_threshold\": {\n",
    "        \"label\": \"VBG hypercapnia threshold met\",\n",
    "        \"definition\": \"Indicator that any venous pCO2 ≥ 50 mmHg in hosp/ICU pCO2 extraction.\",\n",
    "        \"source\": \"mimiciv_hosp.labevents + mimiciv_icu.chartevents\",\n",
    "        \"derivation\": \"max(venous pCO2 ≥ 50) per hadm_id\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"first_gas_time\": {\n",
    "        \"label\": \"First gas panel time\",\n",
    "        \"definition\": \"Earliest gas panel time in the ED 0–24h window.\",\n",
    "        \"source\": \"mimiciv_hosp.labevents (gas panels)\",\n",
    "        \"derivation\": \"min panel_time within ED 0–24h window\",\n",
    "        \"units\": \"datetime\",\n",
    "    },\n",
    "    \"dt_first_qualifying_gas_hours\": {\n",
    "        \"label\": \"Hours to first gas panel\",\n",
    "        \"definition\": \"Hours from first ED arrival to first gas panel time.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"(first_gas_time - ed_intime_first) in hours\",\n",
    "        \"units\": \"hours\",\n",
    "    },\n",
    "    \"presenting_hypercapnia\": {\n",
    "        \"label\": \"Presenting (≤6h) gas timing\",\n",
    "        \"definition\": \"Indicator that first gas panel occurred within 6h of first ED arrival.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"dt_first_qualifying_gas_hours ≤ 6\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"late_hypercapnia\": {\n",
    "        \"label\": \"Late (>6h) gas timing\",\n",
    "        \"definition\": \"Indicator that first gas panel occurred >6h after first ED arrival.\",\n",
    "        \"source\": \"Derived\",\n",
    "        \"derivation\": \"dt_first_qualifying_gas_hours > 6\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"gas_source_unknown_rate\": {\n",
    "        \"label\": \"Gas source unknown rate\",\n",
    "        \"definition\": \"Proportion of gas panels with unknown arterial/venous source per ED stay.\",\n",
    "        \"source\": \"Derived from gas panel source inference\",\n",
    "        \"derivation\": \"mean(source == 'unknown') per ed_stay_id\",\n",
    "        \"units\": \"proportion\",\n",
    "    },\n",
    "    # Comorbidities\n",
    "    \"flag_copd\": {\n",
    "        \"label\": \"COPD/emphysema flag\",\n",
    "        \"definition\": \"Indicator for COPD/emphysema ICD codes in ED or hospital diagnoses.\",\n",
    "        \"source\": \"mimiciv_hosp.diagnoses_icd + mimiciv_ed.diagnosis\",\n",
    "        \"derivation\": \"ICD prefixes J43/J44 (ED OR hospital)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"flag_osa_ohs\": {\n",
    "        \"label\": \"OSA/OHS flag\",\n",
    "        \"definition\": \"Indicator for OSA/OHS ICD codes in ED or hospital diagnoses.\",\n",
    "        \"source\": \"mimiciv_hosp.diagnoses_icd + mimiciv_ed.diagnosis\",\n",
    "        \"derivation\": \"ICD prefixes G473/E662 (ED OR hospital)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"flag_chf\": {\n",
    "        \"label\": \"CHF flag\",\n",
    "        \"definition\": \"Indicator for CHF ICD codes in ED or hospital diagnoses.\",\n",
    "        \"source\": \"mimiciv_hosp.diagnoses_icd + mimiciv_ed.diagnosis\",\n",
    "        \"derivation\": \"ICD prefix I50 (ED OR hospital)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"flag_neuromuscular\": {\n",
    "        \"label\": \"Neuromuscular flag\",\n",
    "        \"definition\": \"Indicator for neuromuscular ICD codes in ED or hospital diagnoses.\",\n",
    "        \"source\": \"mimiciv_hosp.diagnoses_icd + mimiciv_ed.diagnosis\",\n",
    "        \"derivation\": \"ICD prefixes G12/G70/G71 (ED OR hospital)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"flag_opioid_substance\": {\n",
    "        \"label\": \"Opioid/substance flag\",\n",
    "        \"definition\": \"Indicator for opioid/substance ICD codes in ED or hospital diagnoses.\",\n",
    "        \"source\": \"mimiciv_hosp.diagnoses_icd + mimiciv_ed.diagnosis\",\n",
    "        \"derivation\": \"ICD prefixes F11/T40/F13 (ED OR hospital)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "    \"flag_pneumonia\": {\n",
    "        \"label\": \"Pneumonia flag\",\n",
    "        \"definition\": \"Indicator for pneumonia ICD codes in ED or hospital diagnoses.\",\n",
    "        \"source\": \"mimiciv_hosp.diagnoses_icd + mimiciv_ed.diagnosis\",\n",
    "        \"derivation\": \"ICD prefixes J12–J18 (ED OR hospital)\",\n",
    "        \"units\": \"binary (0/1)\",\n",
    "    },\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for col in dd_target.columns:\n",
    "    info = META.get(col, {})\n",
    "    series = dd_target[col]\n",
    "    rows.append({\n",
    "        \"variable\": col,\n",
    "        \"label\": info.get(\"label\", _readable(col)),\n",
    "        \"units\": info.get(\"units\", _infer_units(col)),\n",
    "        \"allowed_values\": info.get(\"allowed_values\", _allowed_values(series)),\n",
    "        \"definition\": info.get(\"definition\", \"UNCONFIRMED\"),\n",
    "        \"synonyms\": info.get(\"synonyms\", \"\"),\n",
    "        \"description\": info.get(\"description\", \"\"),\n",
    "        \"source\": info.get(\"source\", \"UNCONFIRMED\"),\n",
    "        \"derivation\": info.get(\"derivation\", \"UNCONFIRMED\"),\n",
    "        \"dtype\": str(series.dtype),\n",
    "        \"example_value\": series.dropna().iloc[0] if series.dropna().shape[0] else None,\n",
    "    })\n",
    "\n",
    "data_dict = pd.DataFrame(rows)\n",
    "\n",
    "out_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "out_xlsx = DATA_DIR / f\"{out_date} MIMICIV all with CC_data_dictionary.xlsx\"\n",
    "out_csv = DATA_DIR / f\"{out_date} MIMICIV all with CC_data_dictionary.csv\"\n",
    "\n",
    "data_dict.to_excel(out_xlsx, index=False)\n",
    "data_dict.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"Saved data dictionary:\", out_xlsx)\n",
    "print(\"Saved data dictionary:\", out_csv)\n",
    "print(\"Rows:\", len(data_dict))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hypercap-CC-NLP (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
