{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab24b37",
   "metadata": {},
   "source": [
    "\n",
    "# MIMIC‑IV Hypercapnia Cohort — **ICD ∪ Physiologic Thresholds** (BigQuery)\n",
    "\n",
    "TODO: \n",
    "\n",
    "[ ] want to add comorbidity data (any codes)\n",
    "\n",
    "[ ] want to add ED-rendered diagnoses\n",
    "\n",
    "[ ] want to see if we can pull info on potential causative diagnoses rendered when making this data-set\n",
    "\n",
    "\n",
    "**Goal:** Build an admissions‑level tabular dataset that **enrolls** any hospital admission (`hadm_id`) meeting **_any_** of:\n",
    "\n",
    "1. **ICD** codes for hypercapnic respiratory failure (legacy cohort).\n",
    "2. **Any arterial blood gas** (LAB or POC) with **PaCO₂ ≥ 45.0 mmHg** anywhere during the episode.\n",
    "3. **Any venous blood gas** (LAB or POC) with **PaCO₂ ≥ 50.0 mmHg** anywhere during the episode.\n",
    "\n",
    "Then, keep all downstream columns/logic from the current workflow:\n",
    "- Per‑code ICD indicators and an `any_hypercap_icd` flag.\n",
    "- Robust extraction of **first ABG** and **first VBG** (across LAB + POC) with standardized units (mmHg) and pairing logic.\n",
    "- Demographics/outcomes, NIH/OMB race & ethnicity, ED triage + first ED vitals, ICU meta (first stay + LOS), ventilation flags.\n",
    "- Sanity checks.\n",
    "\n",
    "> **Assumptions**\n",
    "> - You already configured BigQuery auth (`gcloud auth application-default login`) and `.env` variables as in the previous notebook.\n",
    "> - The PhysioNet hosting project is `physionet-data`.\n",
    "> - Datasets exist (e.g., `mimiciv_3_1_hosp`, `mimiciv_3_1_icu`, and an ED dataset such as `mimiciv_ed`). This notebook auto-detects the ED dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale:** Define a reproducible, admission-level cohort that captures hypercapnia using complementary diagnostic (ICD) and physiologic (blood gas) criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1731fe",
   "metadata": {},
   "source": [
    "# MIMIC‑IV on BigQuery\n",
    "\n",
    "## Environment Bootstrap & Smoke Test\n",
    "\n",
    "Purpose: make a clean, reproducible start on a new machine.\n",
    "\n",
    "Outcome: verify auth, project config, and dataset access; provide a reusable BigQuery runner for the build notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale:** Establish the BigQuery environment and dataset configuration so queries are consistent and reproducible across runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8408759",
   "metadata": {},
   "source": [
    "## 0. Prerequisites (one-time)\n",
    "\n",
    "**Accounts & access**\n",
    "- PhysioNet access to MIMIC-IV on BigQuery; in BigQuery Console star project `physionet-data`.\n",
    "- A Google Cloud **Project ID** with BigQuery API enabled (this is your **billing** project).\n",
    "\n",
    "**CLI & environment**\n",
    "- Google Cloud SDK (gcloud) installed and on PATH.\n",
    "- Python environment created with `uv` (see README) and Jupyter kernel selected.\n",
    "- A project-local **`.env`** with the variables below.\n",
    "\n",
    "**.env variables**\n",
    "```ini\n",
    "MIMIC_BACKEND=bigquery\n",
    "WORK_PROJECT=<your-billing-project-id>\n",
    "BQ_PHYSIONET_PROJECT=physionet-data\n",
    "BQ_DATASET_HOSP=mimiciv_3_1_hosp\n",
    "BQ_DATASET_ICU=mimiciv_3_1_icu\n",
    "BQ_DATASET_ED=mimiciv_ed\n",
    "WORK_DIR=/path/to/Hypercap-CC-NLP\n",
    "# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json\n",
    "```\n",
    "\n",
    "**Command line quickstart**\n",
    "```bash\n",
    "brew install --cask google-cloud-sdk\n",
    "gcloud init\n",
    "gcloud auth application-default login\n",
    "gcloud services enable bigquery.googleapis.com --project <your-billing-project-id>\n",
    "ls -l ~/.config/gcloud/application_default_credentials.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale:** Verify access and credentials up front to prevent silent failures later in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf7fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: mimic-hypercapnia\n",
      "PhysioNet host: physionet-data\n",
      "HOSP: mimiciv_3_1_hosp ICU: mimiciv_3_1_icu ED (pref): mimiciv_ed\n",
      "WORK_DIR: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP\n"
     ]
    }
   ],
   "source": [
    "# --- Imports & environment\n",
    "import os, re, json, math, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "WORK_DIR = Path(os.getenv(\"WORK_DIR\", Path.cwd())).expanduser().resolve()\n",
    "DATA_DIR = WORK_DIR / \"MIMIC tabular data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Backend selection (we use BigQuery)\n",
    "BACKEND = os.getenv(\"MIMIC_BACKEND\", \"bigquery\").strip().lower()\n",
    "assert BACKEND == \"bigquery\", \"This notebook is BigQuery-specific.\"\n",
    "\n",
    "WORK_PROJECT = os.getenv(\"WORK_PROJECT\", \"\").strip()  # your billing project\n",
    "PHYS = os.getenv(\"BQ_PHYSIONET_PROJECT\", \"physionet-data\").strip()  # hosting project (read-only)\n",
    "\n",
    "# Default to MIMIC-IV v3.1 datasets\n",
    "HOSP = os.getenv(\"BQ_DATASET_HOSP\", \"mimiciv_3_1_hosp\").strip()\n",
    "ICU  = os.getenv(\"BQ_DATASET_ICU\",  \"mimiciv_3_1_icu\").strip()\n",
    "ED   = os.getenv(\"BQ_DATASET_ED\",   \"\").strip()  # may be empty; we will auto-detect\n",
    "\n",
    "# BigQuery client\n",
    "client = bigquery.Client(project=WORK_PROJECT)\n",
    "\n",
    "print(\"Project:\", WORK_PROJECT)\n",
    "print(\"PhysioNet host:\", PHYS)\n",
    "print(\"HOSP:\", HOSP, \"ICU:\", ICU, \"ED (pref):\", ED)\n",
    "print(\"WORK_DIR:\", WORK_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a0b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ED dataset: mimiciv_ed\n"
     ]
    }
   ],
   "source": [
    "# --- Helper: run SQL with optional named parameters\n",
    "def run_sql_bq(sql: str, params: dict | None = None) -> pd.DataFrame:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    if params:\n",
    "        bq_params = []\n",
    "        for k, v in params.items():\n",
    "            if isinstance(v, (list, tuple, np.ndarray, pd.Series)):\n",
    "                # BigQuery ARRAY<INT64> if all ints; else ARRAY<STRING>\n",
    "                v_list = list(v)\n",
    "                if all(isinstance(x, (int, np.integer)) for x in v_list):\n",
    "                    bq_params.append(bigquery.ArrayQueryParameter(k, \"INT64\", list(map(int, v_list))))\n",
    "                else:\n",
    "                    bq_params.append(bigquery.ArrayQueryParameter(k, \"STRING\", list(map(str, v_list))))\n",
    "            else:\n",
    "                # scalar\n",
    "                if isinstance(v, (int, np.integer)):\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(k, \"INT64\", int(v)))\n",
    "                elif isinstance(v, float):\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(k, \"FLOAT64\", float(v)))\n",
    "                else:\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(k, \"STRING\", str(v)))\n",
    "        job_config.query_parameters = bq_params\n",
    "    job = client.query(sql, job_config=job_config)\n",
    "    try:\n",
    "        return job.result().to_dataframe(create_bqstorage_client=True)\n",
    "    except TypeError:\n",
    "        return job.result().to_dataframe()\n",
    "\n",
    "# --- Helper: test if a fully-qualified table exists and is accessible\n",
    "def table_exists(fqtn: str) -> bool:\n",
    "    try:\n",
    "        _ = run_sql_bq(f\"SELECT 1 FROM `{fqtn}` LIMIT 1\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# --- Auto-detect ED dataset if not set\n",
    "if not ED:\n",
    "    candidates = [\n",
    "        f\"{PHYS}.mimiciv_ed.edstays\",\n",
    "        f\"{PHYS}.mimiciv_3_1_ed.edstays\",\n",
    "    ]\n",
    "    for cand in candidates:\n",
    "        if table_exists(cand):\n",
    "            ED = cand.split(\".\")[1]  # dataset\n",
    "            break\n",
    "if not ED:\n",
    "    raise RuntimeError(\"No accessible ED dataset found. Request access to MIMIC-IV-ED in PhysioNet (BigQuery).\")\n",
    "\n",
    "print(\"Using ED dataset:\", ED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a51c8",
   "metadata": {},
   "source": [
    "## 1) ICD cohort flags (hypercapnic respiratory failure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8291e",
   "metadata": {},
   "source": [
    "**Rationale:** Capture diagnosis-based hypercapnia from ED and hospital discharge codes to define a broad, clinically recognized cohort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3507bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769717910.036206 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD cohort admissions: 4237\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9602",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9612",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9622",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9692",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_E662",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD9_27803",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_hosp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_ed",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "icd_source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c0dbe885-eec9-4257-a8c7-acf8c4ac8cb1",
       "rows": [
        [
         "0",
         "10890447",
         "28025587",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "HOSP"
        ],
        [
         "1",
         "10114694",
         "22418467",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "HOSP"
        ],
        [
         "2",
         "12248917",
         "26511066",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "HOSP"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>ICD10_J9602</th>\n",
       "      <th>ICD10_J9612</th>\n",
       "      <th>ICD10_J9622</th>\n",
       "      <th>ICD10_J9692</th>\n",
       "      <th>ICD10_E662</th>\n",
       "      <th>ICD9_27803</th>\n",
       "      <th>any_hypercap_icd</th>\n",
       "      <th>any_hypercap_icd_hosp</th>\n",
       "      <th>any_hypercap_icd_ed</th>\n",
       "      <th>icd_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10890447</td>\n",
       "      <td>28025587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10114694</td>\n",
       "      <td>22418467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12248917</td>\n",
       "      <td>26511066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  ICD10_J9602  ICD10_J9612  ICD10_J9622  ICD10_J9692  \\\n",
       "0    10890447  28025587            0            0            1            0   \n",
       "1    10114694  22418467            1            0            0            0   \n",
       "2    12248917  26511066            0            0            1            0   \n",
       "\n",
       "   ICD10_E662  ICD9_27803  any_hypercap_icd  any_hypercap_icd_hosp  \\\n",
       "0           1           0                 1                      1   \n",
       "1           0           0                 1                      1   \n",
       "2           1           0                 1                      1   \n",
       "\n",
       "   any_hypercap_icd_ed icd_source  \n",
       "0                    0       HOSP  \n",
       "1                    0       HOSP  \n",
       "2                    0       HOSP  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target ICD codes (dotless, uppercase)\n",
    "ICD10_CODES = ['J9602','J9612','J9622','J9692','E662']\n",
    "ICD9_CODES  = ['27803']\n",
    "\n",
    "cohort_icd_sql = f\"\"\"\n",
    "-- ICD-based cohort flags per admission\n",
    "WITH target_codes AS (\n",
    "  SELECT 'J9602' AS code, 10 AS ver UNION ALL\n",
    "  SELECT 'J9612', 10 UNION ALL\n",
    "  SELECT 'J9622', 10 UNION ALL\n",
    "  SELECT 'J9692', 10 UNION ALL\n",
    "  SELECT 'E662',  10 UNION ALL\n",
    "  SELECT '27803', 9\n",
    "),\n",
    "\n",
    "-- Hospital ICDs restricted to target codes\n",
    "hosp_dx AS (\n",
    "  SELECT\n",
    "    d.subject_id,\n",
    "    d.hadm_id,\n",
    "    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,\n",
    "    d.icd_version\n",
    "  FROM `{PHYS}.{HOSP}.diagnoses_icd` d\n",
    "  JOIN target_codes t\n",
    "    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))\n",
    "  WHERE d.hadm_id IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Hospital flags per admission\n",
    "hosp_flags AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,\n",
    "    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,\n",
    "    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803\n",
    "  FROM hosp_dx\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- ED ICDs restricted to target codes (map to hadm via edstays)\n",
    "ed_dx AS (\n",
    "  SELECT\n",
    "    s.subject_id,\n",
    "    s.hadm_id,\n",
    "    s.stay_id,\n",
    "    s.intime AS ed_intime,\n",
    "    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,\n",
    "    d.icd_version\n",
    "  FROM `{PHYS}.{ED}.diagnosis` d\n",
    "  JOIN `{PHYS}.{ED}.edstays` s\n",
    "    ON s.subject_id = d.subject_id AND s.stay_id = d.stay_id\n",
    "  JOIN target_codes t\n",
    "    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))\n",
    "  WHERE s.hadm_id IS NOT NULL\n",
    "),\n",
    "\n",
    "-- ED flags per ED stay (so we can both: OR flags across stays and also pick earliest stay_id)\n",
    "ed_flags_by_stay AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id, stay_id, MIN(ed_intime) AS ed_intime,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,\n",
    "    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,\n",
    "    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803\n",
    "  FROM ed_dx\n",
    "  GROUP BY subject_id, hadm_id, stay_id\n",
    "),\n",
    "\n",
    "-- OR the ED flags across all ED stays mapped to the same hadm\n",
    "ed_flags_or AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id,\n",
    "    MAX(ICD10_J9602) AS ICD10_J9602,\n",
    "    MAX(ICD10_J9612) AS ICD10_J9612,\n",
    "    MAX(ICD10_J9622) AS ICD10_J9622,\n",
    "    MAX(ICD10_J9692) AS ICD10_J9692,\n",
    "    MAX(ICD10_E662 ) AS ICD10_E662,\n",
    "    MAX(ICD9_27803) AS ICD9_27803\n",
    "  FROM ed_flags_by_stay\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- Earliest ED stay_id per hadm (NO UNNEST of aggregates; use [OFFSET(0)])\n",
    "ed_earliest AS (\n",
    "  SELECT\n",
    "    subject_id,\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(stay_id, ed_intime) ORDER BY ed_intime LIMIT 1))[OFFSET(0)].stay_id AS stay_id\n",
    "  FROM ed_flags_by_stay\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- Bring flags and earliest stay_id together\n",
    "ed_by_hadm AS (\n",
    "  SELECT\n",
    "    f.subject_id,\n",
    "    f.hadm_id,\n",
    "    e.stay_id,\n",
    "    f.ICD10_J9602,\n",
    "    f.ICD10_J9612,\n",
    "    f.ICD10_J9622,\n",
    "    f.ICD10_J9692,\n",
    "    f.ICD10_E662,\n",
    "    f.ICD9_27803\n",
    "  FROM ed_flags_or f\n",
    "  LEFT JOIN ed_earliest e\n",
    "    USING (subject_id, hadm_id)\n",
    "),\n",
    "\n",
    "-- Combine ED and hospital flags at the admission level\n",
    "combined AS (\n",
    "  SELECT\n",
    "    COALESCE(h.subject_id, e.subject_id) AS subject_id,\n",
    "    COALESCE(h.hadm_id,     e.hadm_id)   AS hadm_id,\n",
    "    GREATEST(IFNULL(h.ICD10_J9602,0), IFNULL(e.ICD10_J9602,0)) AS ICD10_J9602,\n",
    "    GREATEST(IFNULL(h.ICD10_J9612,0), IFNULL(e.ICD10_J9612,0)) AS ICD10_J9612,\n",
    "    GREATEST(IFNULL(h.ICD10_J9622,0), IFNULL(e.ICD10_J9622,0)) AS ICD10_J9622,\n",
    "    GREATEST(IFNULL(h.ICD10_J9692,0), IFNULL(e.ICD10_J9692,0)) AS ICD10_J9692,\n",
    "    GREATEST(IFNULL(h.ICD10_E662 ,0), IFNULL(e.ICD10_E662 ,0)) AS ICD10_E662,\n",
    "    GREATEST(IFNULL(h.ICD9_27803,0), IFNULL(e.ICD9_27803,0)) AS ICD9_27803,\n",
    "    IF((IFNULL(h.ICD10_J9602,0)+IFNULL(h.ICD10_J9612,0)+IFNULL(h.ICD10_J9622,0)+IFNULL(h.ICD10_J9692,0)+IFNULL(h.ICD10_E662,0)+IFNULL(h.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_hosp,\n",
    "    IF((IFNULL(e.ICD10_J9602,0)+IFNULL(e.ICD10_J9612,0)+IFNULL(e.ICD10_J9622,0)+IFNULL(e.ICD10_J9692,0)+IFNULL(e.ICD10_E662,0)+IFNULL(e.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_ed\n",
    "  FROM hosp_flags h\n",
    "  FULL OUTER JOIN ed_by_hadm e\n",
    "    ON h.hadm_id = e.hadm_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  subject_id, hadm_id,\n",
    "  ICD10_J9602, ICD10_J9612, ICD10_J9622, ICD10_J9692, ICD10_E662, ICD9_27803,\n",
    "  IF((ICD10_J9602+ICD10_J9612+ICD10_J9622+ICD10_J9692+ICD10_E662+ICD9_27803) > 0, 1, 0) AS any_hypercap_icd,\n",
    "  any_hypercap_icd_hosp,\n",
    "  any_hypercap_icd_ed,\n",
    "  CASE\n",
    "    WHEN any_hypercap_icd_hosp=1 AND any_hypercap_icd_ed=1 THEN 'ED+HOSP'\n",
    "    WHEN any_hypercap_icd_ed=1 THEN 'ED'\n",
    "    WHEN any_hypercap_icd_hosp=1 THEN 'HOSP'\n",
    "    ELSE 'NONE'\n",
    "  END AS icd_source\n",
    "FROM combined\n",
    "\"\"\"\n",
    "\n",
    "cohort_icd = run_sql_bq(cohort_icd_sql)\n",
    "print(\"ICD cohort admissions:\", len(cohort_icd))\n",
    "cohort_icd.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29e962",
   "metadata": {},
   "source": [
    "## 2) Blood gas inclusion thresholds — ANY PaCO₂ meeting cutoffs (LAB + POC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b779a",
   "metadata": {},
   "source": [
    "**Rationale:** Identify physiologic hypercapnia using ABG/VBG thresholds, independent of diagnostic coding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb134f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717912.129608 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions meeting thresholds: 91926\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "abg_hypercap_threshold",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "vbg_hypercap_threshold",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "be63060d-5249-431e-b80a-e6e412550707",
       "rows": [
        [
         "0",
         "28885585",
         "1",
         "0"
        ],
        [
         "1",
         "22760357",
         "1",
         "0"
        ],
        [
         "2",
         "21098537",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>abg_hypercap_threshold</th>\n",
       "      <th>vbg_hypercap_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28885585</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22760357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21098537</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  abg_hypercap_threshold  vbg_hypercap_threshold\n",
       "0  28885585                       1                       0\n",
       "1  22760357                       1                       0\n",
       "2  21098537                       1                       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_thresholds_sql = f\"\"\"\n",
    "/* ---- LAB (HOSP) pCO2 across entire dataset ---- */\n",
    "WITH hosp_cand AS (\n",
    "  SELECT\n",
    "    le.hadm_id, le.charttime, le.specimen_id,\n",
    "    CAST(le.valuenum AS FLOAT64) AS val,\n",
    "    LOWER(REPLACE(COALESCE(le.valueuom,''),' ','')) AS uom_nospace,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(COALESCE(di.fluid,'')) AS fl\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE le.valuenum IS NOT NULL\n",
    "    AND (\n",
    "      LOWER(COALESCE(di.category,'')) LIKE '%blood gas%' OR\n",
    "      LOWER(di.label) LIKE '%pco2%' OR\n",
    "      REGEXP_CONTAINS(LOWER(di.label), r'\\\\bpa?\\\\s*co(?:2|₂)\\\\b')\n",
    "    )\n",
    "    AND NOT REGEXP_CONTAINS(LOWER(di.label),\n",
    "        r'(et\\\\s*co2|end[- ]?tidal|t\\\\s*co2|tco2|total\\\\s*co2|hco3|bicar)')\n",
    "),\n",
    "hosp_spec AS (\n",
    "  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE le.specimen_id IS NOT NULL\n",
    "    AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')\n",
    "),\n",
    "hosp_pco2 AS (\n",
    "  SELECT\n",
    "    c.hadm_id, c.charttime,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\\\\bart\\\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'\n",
    "      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\\\\b(abg|art|arterial|a[- ]?line)\\\\b') THEN 'arterial'\n",
    "      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\\\\b(vbg|ven|venous|mixed|central)\\\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site,\n",
    "    CASE WHEN c.uom_nospace='kpa' THEN c.val*7.50062 ELSE c.val END AS pco2_mmHg\n",
    "  FROM hosp_cand c\n",
    "  LEFT JOIN hosp_spec s USING (specimen_id)\n",
    "),\n",
    "hosp_pco2_std AS (\n",
    "  SELECT hadm_id, site, charttime, pco2_mmHg\n",
    "  FROM hosp_pco2\n",
    "  WHERE site IN ('arterial','venous') AND pco2_mmHg BETWEEN 5 AND 200\n",
    "),\n",
    "\n",
    "/* ---- ICU (POC) pCO2 across entire dataset ---- */\n",
    "icu_raw AS (\n",
    "  SELECT\n",
    "    ie.hadm_id,\n",
    "    ce.stay_id,\n",
    "    ce.charttime,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(REPLACE(COALESCE(ce.valueuom,''),' ','')) AS uom_nospace,\n",
    "    LOWER(COALESCE(ce.value,'')) AS valstr,\n",
    "    COALESCE(\n",
    "      CAST(ce.valuenum AS FLOAT64),\n",
    "      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r'(-?\\\\d+(?:\\\\.\\\\d+)?)') AS FLOAT64)\n",
    "    ) AS val\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n",
    "  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n",
    "),\n",
    "icu_cand AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,\n",
    "    CASE\n",
    "      WHEN (\n",
    "            REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\\\s*co\\\\s*(?:2|₂)([^a-z]|$)')\n",
    "            OR uom_nospace IN ('mmhg','kpa')\n",
    "            OR REGEXP_CONTAINS(valstr, r'\\\\b(mm\\\\s*hg|kpa)\\\\b')\n",
    "           )\n",
    "           AND NOT REGEXP_CONTAINS(lbl,\n",
    "               r'(et\\\\s*co2|end[- ]?tidal|t\\\\s*co2|tco2|total\\\\s*co2|hco3|bicar|v\\\\s*co2|vco2|co2\\\\s*(prod|elimin|production|elimination))')\n",
    "      THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\\\b(abg|art|arterial|a[- ]?line)\\\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\\\b(vbg|ven|venous|mixed|central)\\\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM icu_raw\n",
    "  WHERE val IS NOT NULL\n",
    "    AND (\n",
    "      REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\\\s*co\\\\s*(?:2|₂)([^a-z]|$)')\n",
    "      OR uom_nospace IN ('mmhg','kpa')\n",
    "      OR REGEXP_CONTAINS(valstr, r'\\\\b(mm\\\\s*hg|kpa)\\\\b')\n",
    "    )\n",
    "    AND NOT REGEXP_CONTAINS(lbl,\n",
    "        r'(et\\\\s*co2|end[- ]?tidal|t\\\\s*co2|tco2|total\\\\s*co2|hco3|bicar|v\\\\s*co2|vco2|co2\\\\s*(prod|elimin|production|elimination))')\n",
    "),\n",
    "icu_co2_std AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    site,\n",
    "    charttime,\n",
    "    CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\\\\bkpa\\\\b') THEN val*7.50062 ELSE val END AS pco2_mmHg\n",
    "  FROM icu_cand\n",
    "  WHERE analyte='pco2' AND site IN ('arterial','venous') AND val BETWEEN 5 AND 200\n",
    "),\n",
    "\n",
    "/* ---- Combine and threshold per admission ---- */\n",
    "all_pco2 AS (\n",
    "  SELECT * FROM hosp_pco2_std\n",
    "  UNION ALL\n",
    "  SELECT * FROM icu_co2_std\n",
    "),\n",
    "thresh AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    MAX(IF(site='arterial' AND pco2_mmHg >= 45.0, 1, 0)) AS abg_hypercap_threshold,\n",
    "    MAX(IF(site='venous'   AND pco2_mmHg >= 50.0, 1, 0)) AS vbg_hypercap_threshold\n",
    "  FROM all_pco2\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "SELECT * FROM thresh\n",
    "\"\"\"\n",
    "\n",
    "co2_thresh = run_sql_bq(co2_thresholds_sql)\n",
    "print(\"Admissions meeting thresholds:\", len(co2_thresh))\n",
    "co2_thresh.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d0066",
   "metadata": {},
   "source": [
    "## 3) Cohort union (ICD ∪ thresholds) and `hadm_list` for downstream queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73cdc3",
   "metadata": {},
   "source": [
    "**Rationale:** Combine ICD and physiologic routes to maximize sensitivity, then define a stable hadm_id list for downstream joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db1a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD-only admissions        : 4237\n",
      "Threshold-only admissions  : 79916\n",
      "Both ICD and threshold     : 3555\n",
      "Total enrolled (union)     : 84153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84152"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outer-join because thresholds can identify hadm_id with no ICD codes and vice versa\n",
    "cohort_any = cohort_icd.merge(co2_thresh, how=\"outer\", on=\"hadm_id\")\n",
    "\n",
    "# Fill missing flags with 0 where appropriate\n",
    "icd_cols = [\"ICD10_J9602\",\"ICD10_J9612\",\"ICD10_J9622\",\"ICD10_J9692\",\"ICD10_E662\",\"ICD9_27803\",\"any_hypercap_icd\",\"any_hypercap_icd_hosp\",\"any_hypercap_icd_ed\"]\n",
    "for c in icd_cols:\n",
    "    if c in cohort_any.columns:\n",
    "        cohort_any[c] = cohort_any[c].fillna(0).astype(int)\n",
    "\n",
    "for c in [\"abg_hypercap_threshold\",\"vbg_hypercap_threshold\"]:\n",
    "    if c in cohort_any.columns:\n",
    "        cohort_any[c] = cohort_any[c].fillna(0).astype(int)\n",
    "\n",
    "# Final enrollment flag\n",
    "cohort_any[\"pco2_threshold_any\"] = ((cohort_any[\"abg_hypercap_threshold\"]==1) | (cohort_any[\"vbg_hypercap_threshold\"]==1)).astype(int)\n",
    "cohort_any[\"enrolled_any\"] = ((cohort_any[\"any_hypercap_icd\"]==1) | (cohort_any[\"pco2_threshold_any\"]==1)).astype(int)\n",
    "\n",
    "print(\"ICD-only admissions        :\", int((cohort_any[\"any_hypercap_icd\"]==1).sum()))\n",
    "print(\"Threshold-only admissions  :\", int(((cohort_any[\"pco2_threshold_any\"]==1) & (cohort_any[\"any_hypercap_icd\"]==0)).sum()))\n",
    "print(\"Both ICD and threshold     :\", int(((cohort_any[\"pco2_threshold_any\"]==1) & (cohort_any[\"any_hypercap_icd\"]==1)).sum()))\n",
    "print(\"Total enrolled (union)     :\", int((cohort_any[\"enrolled_any\"]==1).sum()))\n",
    "\n",
    "# New hadm list used for the rest of the notebook\n",
    "hadm_list = cohort_any.loc[cohort_any[\"enrolled_any\"]==1, \"hadm_id\"].dropna().astype(\"int64\").tolist()\n",
    "len(hadm_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe110d70",
   "metadata": {},
   "source": [
    "## 4) First ABG and First VBG (LAB + POC, standardized to mmHg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd25d61",
   "metadata": {},
   "source": [
    "**Rationale:** Extract earliest ABG/VBG measurements to characterize baseline physiology with standardized units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d61ad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717920.222943 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "lab_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "lab_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_ph_uom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lab_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_paco2_uom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lab_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "first_abg_src",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_abg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_abg_pco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_src",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "first_vbg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_pco2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "988d9079-737b-4b64-9a7f-1095fe102204",
       "rows": [
        [
         "0",
         "28025587",
         "7.27",
         "units",
         "82.0",
         "mmhg",
         "2149-08-24 09:03:00",
         "7.27",
         "units",
         "80.0",
         "mmhg",
         "2149-08-24 14:01:00",
         "7.27",
         null,
         "82.0",
         "mmhg",
         "2149-08-24 11:20:00",
         null,
         null,
         "36.0",
         "mmhg",
         "2149-08-24 14:01:00",
         "LAB",
         "2149-08-24 09:03:00",
         "7.27",
         "82.0",
         "LAB",
         "2149-08-24 14:01:00",
         "7.27",
         "80.0"
        ],
        [
         "1",
         "22418467",
         null,
         null,
         null,
         null,
         null,
         "7.32",
         "units",
         "55.0",
         "mmhg",
         "2163-03-28 04:24:00",
         null,
         null,
         null,
         null,
         null,
         "7.32",
         null,
         "44.0",
         "mmhg",
         "2163-03-28 04:24:00",
         null,
         null,
         null,
         null,
         "LAB",
         "2163-03-28 04:24:00",
         "7.32",
         "55.0"
        ],
        [
         "2",
         "26511066",
         "7.31",
         "units",
         "72.0",
         "mmhg",
         "2192-09-22 05:53:00",
         "7.24",
         "units",
         "84.0",
         "mmhg",
         "2192-09-21 20:48:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "LAB",
         "2192-09-22 05:53:00",
         "7.31",
         "72.0",
         "LAB",
         "2192-09-21 20:48:00",
         "7.24",
         "84.0"
        ]
       ],
       "shape": {
        "columns": 29,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>lab_abg_ph</th>\n",
       "      <th>lab_abg_ph_uom</th>\n",
       "      <th>lab_abg_paco2</th>\n",
       "      <th>lab_abg_paco2_uom</th>\n",
       "      <th>lab_abg_time</th>\n",
       "      <th>lab_vbg_ph</th>\n",
       "      <th>lab_vbg_ph_uom</th>\n",
       "      <th>lab_vbg_paco2</th>\n",
       "      <th>lab_vbg_paco2_uom</th>\n",
       "      <th>...</th>\n",
       "      <th>poc_vbg_paco2_uom</th>\n",
       "      <th>poc_vbg_time</th>\n",
       "      <th>first_abg_src</th>\n",
       "      <th>first_abg_time</th>\n",
       "      <th>first_abg_ph</th>\n",
       "      <th>first_abg_pco2</th>\n",
       "      <th>first_vbg_src</th>\n",
       "      <th>first_vbg_time</th>\n",
       "      <th>first_vbg_ph</th>\n",
       "      <th>first_vbg_pco2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28025587</td>\n",
       "      <td>7.27</td>\n",
       "      <td>units</td>\n",
       "      <td>82.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>2149-08-24 09:03:00</td>\n",
       "      <td>7.27</td>\n",
       "      <td>units</td>\n",
       "      <td>80.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>...</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>2149-08-24 14:01:00</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2149-08-24 09:03:00</td>\n",
       "      <td>7.27</td>\n",
       "      <td>82.0</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2149-08-24 14:01:00</td>\n",
       "      <td>7.27</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22418467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.32</td>\n",
       "      <td>units</td>\n",
       "      <td>55.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>...</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>2163-03-28 04:24:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2163-03-28 04:24:00</td>\n",
       "      <td>7.32</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26511066</td>\n",
       "      <td>7.31</td>\n",
       "      <td>units</td>\n",
       "      <td>72.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>2192-09-22 05:53:00</td>\n",
       "      <td>7.24</td>\n",
       "      <td>units</td>\n",
       "      <td>84.0</td>\n",
       "      <td>mmhg</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2192-09-22 05:53:00</td>\n",
       "      <td>7.31</td>\n",
       "      <td>72.0</td>\n",
       "      <td>LAB</td>\n",
       "      <td>2192-09-21 20:48:00</td>\n",
       "      <td>7.24</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  lab_abg_ph lab_abg_ph_uom  lab_abg_paco2 lab_abg_paco2_uom  \\\n",
       "0  28025587        7.27          units           82.0              mmhg   \n",
       "1  22418467         NaN           None            NaN              None   \n",
       "2  26511066        7.31          units           72.0              mmhg   \n",
       "\n",
       "         lab_abg_time  lab_vbg_ph lab_vbg_ph_uom  lab_vbg_paco2  \\\n",
       "0 2149-08-24 09:03:00        7.27          units           80.0   \n",
       "1                 NaT        7.32          units           55.0   \n",
       "2 2192-09-22 05:53:00        7.24          units           84.0   \n",
       "\n",
       "  lab_vbg_paco2_uom  ... poc_vbg_paco2_uom        poc_vbg_time first_abg_src  \\\n",
       "0              mmhg  ...              mmhg 2149-08-24 14:01:00           LAB   \n",
       "1              mmhg  ...              mmhg 2163-03-28 04:24:00          None   \n",
       "2              mmhg  ...              None                 NaT           LAB   \n",
       "\n",
       "       first_abg_time first_abg_ph first_abg_pco2  first_vbg_src  \\\n",
       "0 2149-08-24 09:03:00         7.27           82.0            LAB   \n",
       "1                 NaT          NaN            NaN            LAB   \n",
       "2 2192-09-22 05:53:00         7.31           72.0            LAB   \n",
       "\n",
       "       first_vbg_time  first_vbg_ph first_vbg_pco2  \n",
       "0 2149-08-24 14:01:00          7.27           80.0  \n",
       "1 2163-03-28 04:24:00          7.32           55.0  \n",
       "2 2192-09-21 20:48:00          7.24           84.0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"hadms\": hadm_list}\n",
    "\n",
    "bg_pairs_sql = rf\"\"\"\n",
    "WITH hadms AS (SELECT hadm_id FROM UNNEST(@hadms) AS hadm_id),\n",
    "\n",
    "/* ---------------- LAB (HOSP) ---------------- */\n",
    "hosp_cand AS (\n",
    "  SELECT\n",
    "    le.subject_id, le.hadm_id, le.charttime, le.specimen_id,\n",
    "    CAST(le.valuenum AS FLOAT64) AS val,\n",
    "    LOWER(COALESCE(le.valueuom,'')) AS uom,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(COALESCE(di.fluid,'')) AS fl,\n",
    "    LOWER(COALESCE(di.category,'')) AS cat\n",
    "  FROM `{PHYS}.{HOSP}.labevents`  le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  JOIN hadms h ON h.hadm_id = le.hadm_id\n",
    "  WHERE le.valuenum IS NOT NULL\n",
    "    AND (\n",
    "         LOWER(COALESCE(di.category,'')) LIKE '%blood gas%' OR\n",
    "         LOWER(di.label) LIKE '%pco2%' OR\n",
    "         REGEXP_CONTAINS(LOWER(di.label), r'\\bph\\b') OR\n",
    "         REGEXP_CONTAINS(LOWER(di.label), r'\\bpa?\\s*co(?:2|₂)\\b')\n",
    "        )\n",
    "    AND NOT REGEXP_CONTAINS(LOWER(di.label), r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar)')\n",
    "),\n",
    "hosp_spec AS (\n",
    "  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE le.specimen_id IS NOT NULL\n",
    "    AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')\n",
    "),\n",
    "hosp_class AS (\n",
    "  SELECT\n",
    "    c.hadm_id, c.charttime, c.specimen_id, c.val, c.uom, c.lbl, c.fl,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(c.lbl, r'\\b(?:blood\\s*)?ph\\b') THEN 'ph'\n",
    "      WHEN (c.lbl LIKE '%pco2%' OR REGEXP_CONTAINS(c.lbl, r'\\bpa?\\s*co(?:2|₂)\\b')) THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\\bart\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'\n",
    "      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\\b(abg|art|arterial|a[- ]?line)\\b') THEN 'arterial'\n",
    "      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\\b(vbg|ven|venous|mixed|central)\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM hosp_cand c\n",
    "  LEFT JOIN hosp_spec s USING (specimen_id)\n",
    "),\n",
    "hosp_pairs AS (\n",
    "  SELECT\n",
    "    hadm_id, specimen_id,\n",
    "    MIN(charttime) AS sample_time,\n",
    "    MAX(IF(analyte='ph',   val, NULL)) AS ph,\n",
    "    MAX(IF(analyte='pco2', val, NULL)) AS pco2_raw,\n",
    "    (ARRAY_AGG(IF(analyte='pco2', uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS pco2_uom,\n",
    "    (ARRAY_AGG(IF(analyte='ph',   uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS ph_uom,\n",
    "    (ARRAY_AGG(site IGNORE NULLS LIMIT 1))[OFFSET(0)] AS site\n",
    "  FROM hosp_class\n",
    "  GROUP BY hadm_id, specimen_id\n",
    "  HAVING (ph IS NOT NULL OR pco2_raw IS NOT NULL) AND site IN ('arterial','venous')\n",
    "),\n",
    "hosp_pairs_std AS (\n",
    "  SELECT\n",
    "    hadm_id, specimen_id, sample_time, site,\n",
    "    ph, ph_uom,\n",
    "    CASE WHEN pco2_uom = 'kpa' THEN pco2_raw * 7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    'mmhg' AS pco2_uom_norm\n",
    "  FROM hosp_pairs\n",
    "  WHERE (ph IS NULL OR (ph BETWEEN 6.3 AND 7.8))\n",
    "    AND (pco2_raw IS NULL OR (CASE WHEN pco2_uom='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200)\n",
    "),\n",
    "lab_abg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS lab_abg_ph,\n",
    "         ph_uom        AS lab_abg_ph_uom,\n",
    "         pco2_mmHg     AS lab_abg_paco2,\n",
    "         'mmhg'        AS lab_abg_paco2_uom,\n",
    "         sample_time   AS lab_abg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM hosp_pairs_std WHERE site='arterial') WHERE rn=1\n",
    "),\n",
    "lab_vbg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS lab_vbg_ph,\n",
    "         ph_uom        AS lab_vbg_ph_uom,\n",
    "         pco2_mmHg     AS lab_vbg_paco2,\n",
    "         'mmhg'        AS lab_vbg_paco2_uom,\n",
    "         sample_time   AS lab_vbg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM hosp_pairs_std WHERE site='venous') WHERE rn=1\n",
    "),\n",
    "\n",
    "/* ---------------- POC (ICU) ---------------- */\n",
    "icu_raw AS (\n",
    "  SELECT\n",
    "    ie.hadm_id, ce.stay_id, ce.charttime,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(REPLACE(COALESCE(ce.valueuom,''),' ','')) AS uom_nospace,\n",
    "    LOWER(COALESCE(ce.value,'')) AS valstr,\n",
    "    COALESCE(\n",
    "      CAST(ce.valuenum AS FLOAT64),\n",
    "      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r'(-?\\d+(?:\\.\\d+)?)') AS FLOAT64)\n",
    "    ) AS val\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n",
    "  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n",
    "  JOIN hadms h ON h.hadm_id = ie.hadm_id\n",
    "),\n",
    "icu_cand AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'(^|[^a-z])ph([^a-z]|$)') OR (val BETWEEN 6.3 AND 7.8) THEN 'ph'\n",
    "      WHEN (\n",
    "             REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)')\n",
    "             OR uom_nospace IN ('mmhg','kpa')\n",
    "             OR REGEXP_CONTAINS(valstr, r'\\b(mm\\s*hg|kpa)\\b')\n",
    "           )\n",
    "           AND NOT REGEXP_CONTAINS(lbl, r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))')\n",
    "      THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\b(abg|art|arterial|a[- ]?line)\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\b(vbg|ven|venous|mixed|central)\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM icu_raw\n",
    "  WHERE val IS NOT NULL\n",
    "    AND (\n",
    "      REGEXP_CONTAINS(lbl, r'(^|[^a-z])ph([^a-z]|$)') OR\n",
    "      REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)') OR\n",
    "      uom_nospace IN ('mmhg','kpa') OR\n",
    "      REGEXP_CONTAINS(valstr, r'\\b(mm\\s*hg|kpa)\\b')\n",
    "    )\n",
    "    AND NOT REGEXP_CONTAINS(lbl, r'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))')\n",
    "),\n",
    "icu_ph AS (\n",
    "  SELECT hadm_id, stay_id, charttime, val AS ph, site AS site_ph\n",
    "  FROM icu_cand WHERE analyte='ph'\n",
    "),\n",
    "icu_co2 AS (\n",
    "  SELECT hadm_id, stay_id, charttime, val AS pco2_raw, uom_nospace, valstr, site AS site_co2\n",
    "  FROM icu_cand WHERE analyte='pco2'\n",
    "),\n",
    "icu_pair_win AS (\n",
    "  SELECT\n",
    "    p.hadm_id, p.stay_id,\n",
    "    COALESCE(p.site_ph, c.site_co2) AS site,\n",
    "    p.charttime AS ph_time, c.charttime AS co2_time,\n",
    "    p.ph,\n",
    "    CASE\n",
    "      WHEN c.uom_nospace='kpa' OR REGEXP_CONTAINS(c.valstr, r'\\bkpa\\b') THEN 'kpa'\n",
    "      WHEN c.uom_nospace='mmhg' OR REGEXP_CONTAINS(c.valstr, r'mm\\s*hg') THEN 'mmhg'\n",
    "      ELSE c.uom_nospace\n",
    "    END AS pco2_uom_norm_raw,\n",
    "    c.pco2_raw,\n",
    "    ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, SECOND)) AS dt_sec\n",
    "  FROM icu_ph p\n",
    "  JOIN icu_co2 c\n",
    "    ON c.hadm_id = p.hadm_id\n",
    "   AND c.stay_id = p.stay_id\n",
    "   AND (COALESCE(p.site_ph, c.site_co2) IN ('arterial','venous'))\n",
    "   AND ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, MINUTE)) <= 10\n",
    "  QUALIFY ROW_NUMBER() OVER (\n",
    "    PARTITION BY p.hadm_id, p.stay_id, p.charttime\n",
    "    ORDER BY dt_sec\n",
    "  ) = 1\n",
    "),\n",
    "icu_pairs_std AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, site,\n",
    "    LEAST(ph_time, co2_time) AS sample_time,\n",
    "    ph,\n",
    "    CAST(NULL AS STRING) AS ph_uom,              -- POC pH is unitless/null\n",
    "    CASE WHEN pco2_uom_norm_raw='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    'mmhg' AS pco2_uom_norm\n",
    "  FROM icu_pair_win\n",
    "  WHERE (ph BETWEEN 6.3 AND 7.8 OR ph IS NULL)\n",
    "    AND (CASE WHEN pco2_uom_norm_raw='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200\n",
    "),\n",
    "icu_solo_pco2_std AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, site_co2 AS site,\n",
    "    charttime AS sample_time,\n",
    "    CAST(NULL AS FLOAT64) AS ph,\n",
    "    CAST(NULL AS STRING)  AS ph_uom,            -- no pH here\n",
    "    CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\\bkpa\\b') THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    'mmhg' AS pco2_uom_norm\n",
    "  FROM icu_co2\n",
    "  WHERE site_co2 IN ('arterial','venous')\n",
    "    AND pco2_raw BETWEEN 5 AND 200\n",
    "),\n",
    "icu_all AS (\n",
    "  SELECT * FROM icu_pairs_std\n",
    "  UNION ALL\n",
    "  SELECT * FROM icu_solo_pco2_std\n",
    "),\n",
    "\n",
    "poc_abg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS poc_abg_ph,\n",
    "         ph_uom        AS poc_abg_ph_uom,\n",
    "         pco2_mmHg     AS poc_abg_paco2,\n",
    "         'mmhg'        AS poc_abg_paco2_uom,\n",
    "         sample_time   AS poc_abg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM icu_all WHERE site='arterial') WHERE rn=1\n",
    "),\n",
    "poc_vbg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph            AS poc_vbg_ph,\n",
    "         ph_uom        AS poc_vbg_ph_uom,\n",
    "         pco2_mmHg     AS poc_vbg_paco2,\n",
    "         'mmhg'        AS poc_vbg_paco2_uom,\n",
    "         sample_time   AS poc_vbg_time\n",
    "  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "        FROM icu_all WHERE site='venous') WHERE rn=1\n",
    ")\n",
    "\n",
    "/* ---------------- Final one row per hadm ---------------- */\n",
    "SELECT\n",
    "  h.hadm_id,\n",
    "  -- LAB-ABG / LAB-VBG\n",
    "  la.lab_abg_ph, la.lab_abg_ph_uom, la.lab_abg_paco2, la.lab_abg_paco2_uom, la.lab_abg_time,\n",
    "  lv.lab_vbg_ph, lv.lab_vbg_ph_uom, lv.lab_vbg_paco2, lv.lab_vbg_paco2_uom, lv.lab_vbg_time,\n",
    "  -- POC-ABG / POC-VBG\n",
    "  pa.poc_abg_ph, pa.poc_abg_ph_uom, pa.poc_abg_paco2, pa.poc_abg_paco2_uom, pa.poc_abg_time,\n",
    "  pv.poc_vbg_ph, pv.poc_vbg_ph_uom, pv.poc_vbg_paco2, pv.poc_vbg_paco2_uom, pv.poc_vbg_time,\n",
    "  -- First ABG across LAB+POC\n",
    "  (SELECT AS STRUCT src, t, ph, pco2\n",
    "   FROM (SELECT 'LAB' AS src, la.lab_abg_time AS t, la.lab_abg_ph AS ph, la.lab_abg_paco2 AS pco2\n",
    "         UNION ALL\n",
    "         SELECT 'POC', pa.poc_abg_time, pa.poc_abg_ph, pa.poc_abg_paco2)\n",
    "   WHERE t IS NOT NULL\n",
    "   ORDER BY t LIMIT 1) AS first_abg,\n",
    "  -- First VBG across LAB+POC\n",
    "  (SELECT AS STRUCT src, t, ph, pco2\n",
    "   FROM (SELECT 'LAB' AS src, lv.lab_vbg_time AS t, lv.lab_vbg_ph AS ph, lv.lab_vbg_paco2 AS pco2\n",
    "         UNION ALL\n",
    "         SELECT 'POC', pv.poc_vbg_time, pv.poc_vbg_ph, pv.poc_vbg_paco2)\n",
    "   WHERE t IS NOT NULL\n",
    "   ORDER BY t LIMIT 1) AS first_vbg\n",
    "FROM hadms h\n",
    "LEFT JOIN lab_abg la USING (hadm_id)\n",
    "LEFT JOIN lab_vbg lv USING (hadm_id)\n",
    "LEFT JOIN poc_abg pa USING (hadm_id)\n",
    "LEFT JOIN poc_vbg pv USING (hadm_id)\n",
    "\"\"\"\n",
    "\n",
    "bg_pairs = run_sql_bq(bg_pairs_sql, params)\n",
    "\n",
    "# Flatten STRUCTs for first_abg and first_vbg\n",
    "for col in [\"first_abg\",\"first_vbg\"]:\n",
    "    if col in bg_pairs.columns:\n",
    "        bg_pairs[f\"{col}_src\"]  = bg_pairs[col].apply(lambda x: x.get(\"src\") if isinstance(x, dict) else None)\n",
    "        bg_pairs[f\"{col}_time\"] = bg_pairs[col].apply(lambda x: x.get(\"t\")   if isinstance(x, dict) else None)\n",
    "        bg_pairs[f\"{col}_ph\"]   = bg_pairs[col].apply(lambda x: x.get(\"ph\")  if isinstance(x, dict) else None)\n",
    "        bg_pairs[f\"{col}_pco2\"] = bg_pairs[col].apply(lambda x: x.get(\"pco2\")if isinstance(x, dict) else None)\n",
    "        bg_pairs = bg_pairs.drop(columns=[col])\n",
    "\n",
    "bg_pairs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eba414",
   "metadata": {},
   "source": [
    "## 5) Demographics & outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36c218",
   "metadata": {},
   "source": [
    "**Rationale:** Build baseline covariates used for descriptive statistics and potential confounding adjustment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f2d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717928.621076 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo rows: 84152\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "admittime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "dischtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "deathtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "admission_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "admission_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "discharge_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "insurance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hosp_los_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_in_hosp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age_at_admit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_30d",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "b82ecd28-ecd6-427f-9da6-b56f4335b40a",
       "rows": [
        [
         "0",
         "26713233",
         "10106244",
         "2147-05-09 10:34:00",
         "2147-05-12 13:43:00",
         null,
         "DIRECT EMER.",
         "PHYSICIAN REFERRAL",
         "HOME",
         "Private",
         "3.125",
         "0",
         "F",
         "63.0",
         "0"
        ],
        [
         "1",
         "23485217",
         "10584718",
         "2165-02-12 15:41:00",
         "2165-03-06 08:20:00",
         "2165-03-06 08:20:00",
         "EW EMER.",
         "TRANSFER FROM SKILLED NURSING FACILITY",
         "DIED",
         "Medicare",
         "21.708333333333332",
         "1",
         "M",
         "78.0",
         "1"
        ],
        [
         "2",
         "27004173",
         "10297948",
         "2135-08-23 18:46:00",
         "2135-09-08 15:50:00",
         null,
         "URGENT",
         "TRANSFER FROM HOSPITAL",
         "CHRONIC/LONG TERM ACUTE CARE",
         "Private",
         "15.875",
         "0",
         "F",
         "70.0",
         "0"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hosp_los_days</th>\n",
       "      <th>death_in_hosp</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_at_admit</th>\n",
       "      <th>death_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26713233</td>\n",
       "      <td>10106244</td>\n",
       "      <td>2147-05-09 10:34:00</td>\n",
       "      <td>2147-05-12 13:43:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DIRECT EMER.</td>\n",
       "      <td>PHYSICIAN REFERRAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23485217</td>\n",
       "      <td>10584718</td>\n",
       "      <td>2165-02-12 15:41:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>DIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>21.708333</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27004173</td>\n",
       "      <td>10297948</td>\n",
       "      <td>2135-08-23 18:46:00</td>\n",
       "      <td>2135-09-08 15:50:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>CHRONIC/LONG TERM ACUTE CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  subject_id           admittime           dischtime  \\\n",
       "0  26713233    10106244 2147-05-09 10:34:00 2147-05-12 13:43:00   \n",
       "1  23485217    10584718 2165-02-12 15:41:00 2165-03-06 08:20:00   \n",
       "2  27004173    10297948 2135-08-23 18:46:00 2135-09-08 15:50:00   \n",
       "\n",
       "            deathtime admission_type                      admission_location  \\\n",
       "0                 NaT   DIRECT EMER.                      PHYSICIAN REFERRAL   \n",
       "1 2165-03-06 08:20:00       EW EMER.  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "2                 NaT         URGENT                  TRANSFER FROM HOSPITAL   \n",
       "\n",
       "             discharge_location insurance  hosp_los_days  death_in_hosp  \\\n",
       "0                          HOME   Private       3.125000              0   \n",
       "1                          DIED  Medicare      21.708333              1   \n",
       "2  CHRONIC/LONG TERM ACUTE CARE   Private      15.875000              0   \n",
       "\n",
       "  gender  age_at_admit  death_30d  \n",
       "0      F          63.0          0  \n",
       "1      M          78.0          1  \n",
       "2      F          70.0          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "demo_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  a.hadm_id,\n",
    "  a.subject_id,\n",
    "  a.admittime,\n",
    "  a.dischtime,\n",
    "  a.deathtime,\n",
    "  a.admission_type,\n",
    "  a.admission_location,\n",
    "  a.discharge_location,\n",
    "  a.insurance,\n",
    "  -- LOS (days)\n",
    "  TIMESTAMP_DIFF(a.dischtime, a.admittime, HOUR) / 24.0 AS hosp_los_days,\n",
    "  -- in-hospital death\n",
    "  IF(a.deathtime IS NOT NULL, 1, 0) AS death_in_hosp,\n",
    "  -- demographics\n",
    "  p.gender,\n",
    "  SAFE_CAST(ROUND(p.anchor_age + (EXTRACT(YEAR FROM a.admittime) - p.anchor_year), 1) AS FLOAT64) AS age_at_admit,\n",
    "  -- 30-day all-cause mortality from admission\n",
    "  IF(p.dod IS NOT NULL AND DATE_DIFF(DATE(p.dod), DATE(a.admittime), DAY) BETWEEN 0 AND 30, 1, 0) AS death_30d\n",
    "FROM `{PHYS}.{HOSP}.admissions` a\n",
    "JOIN hadms h USING (hadm_id)\n",
    "JOIN `{PHYS}.{HOSP}.patients` p USING (subject_id)\n",
    "\"\"\"\n",
    "demo = run_sql_bq(demo_sql, {\"hadms\": hadm_list})\n",
    "print(\"Demo rows:\", len(demo))\n",
    "demo.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fee13e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe merge helpers loaded.\n"
     ]
    }
   ],
   "source": [
    "# ==== Drop-in: safe merge utilities (one cell, run once) ====\n",
    "import pandas as pd\n",
    "from typing import Iterable, Optional, Literal\n",
    "\n",
    "def _ensure_Int64(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce to pandas nullable Int64 (preserves NA).\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "def strip_subject_cols(fr: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove any subject_id-like columns from a frame (e.g., 'subject_id', 'Subject_ID').\"\"\"\n",
    "    return fr.drop(columns=[c for c in fr.columns if c.lower().startswith(\"subject_id\")],\n",
    "                   errors=\"ignore\")\n",
    "\n",
    "def safe_merge_on_hadm(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    *,\n",
    "    right_name: str,\n",
    "    take: Optional[Iterable[str]] = None,\n",
    "    order_by: Optional[Iterable[str]] = None,\n",
    "    check_subject: Literal[False, \"warn\", \"raise\"] = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Left-merge 'right' into 'left' on hadm_id, returning a copy of left with right's columns.\n",
    "    - Dedupes right on hadm_id (optionally using order_by to pick the first row).\n",
    "    - Optionally restricts right columns via `take`.\n",
    "    - Optionally audits subject_id agreement before dropping subject_id from right.\n",
    "    - Always strips subject_id-like columns from the right to prevent *_x/_y suffixes.\n",
    "    - Raises if any *_x/_y suffixes still appear (indicates overlapping names besides hadm_id).\n",
    "    \"\"\"\n",
    "    if \"hadm_id\" not in left.columns:\n",
    "        raise KeyError(f\"left frame lacks hadm_id before merging {right_name}\")\n",
    "    if \"hadm_id\" not in right.columns:\n",
    "        raise KeyError(f\"{right_name} lacks hadm_id\")\n",
    "\n",
    "    L = left.copy()\n",
    "    R = right.copy()\n",
    "\n",
    "    # Standardize dtypes of keys\n",
    "    L[\"hadm_id\"] = _ensure_Int64(L[\"hadm_id\"])\n",
    "    R[\"hadm_id\"] = _ensure_Int64(R[\"hadm_id\"])\n",
    "    if \"subject_id\" in L.columns:\n",
    "        L[\"subject_id\"] = _ensure_Int64(L[\"subject_id\"])\n",
    "    if \"subject_id\" in R.columns:\n",
    "        R[\"subject_id\"] = _ensure_Int64(R[\"subject_id\"])\n",
    "\n",
    "    # Dedupe RIGHT by hadm_id (optionally order_by first)\n",
    "    if order_by:\n",
    "        R = (R.sort_values(list(order_by))\n",
    "               .drop_duplicates(subset=[\"hadm_id\"], keep=\"first\"))\n",
    "    else:\n",
    "        R = R.drop_duplicates(subset=[\"hadm_id\"], keep=\"first\")\n",
    "\n",
    "    # Optional subject_id consistency audit (before stripping)\n",
    "    if check_subject and (\"subject_id\" in L.columns) and (\"subject_id\" in R.columns):\n",
    "        # Join only on hadm_id where both sides have subject_id\n",
    "        tmp = (L[[\"hadm_id\", \"subject_id\"]]\n",
    "                 .merge(R[[\"hadm_id\", \"subject_id\"]],\n",
    "                        on=\"hadm_id\", how=\"inner\", suffixes=(\"_L\",\"_R\")))\n",
    "        mism = (tmp[\"subject_id_L\"].notna() & tmp[\"subject_id_R\"].notna() &\n",
    "                (tmp[\"subject_id_L\"] != tmp[\"subject_id_R\"]))\n",
    "        n_mism = int(mism.sum())\n",
    "        if n_mism > 0:\n",
    "            sample_ids = tmp.loc[mism, \"hadm_id\"].head(10).tolist()\n",
    "            msg = (f\"[{right_name}] subject_id mismatch on {n_mism} hadm_id(s). \"\n",
    "                   f\"Examples: {sample_ids}\")\n",
    "            if check_subject == \"raise\":\n",
    "                raise ValueError(msg)\n",
    "            else:\n",
    "                print(\"WARNING:\", msg)\n",
    "\n",
    "    # Limit right columns (avoid accidental overlaps)\n",
    "    if take is not None:\n",
    "        keep = [\"hadm_id\"] + [c for c in take if c != \"hadm_id\"]\n",
    "        R = R[[c for c in keep if c in R.columns]]\n",
    "\n",
    "    # Always strip subject_id-like columns from right to prevent *_x/_y\n",
    "    R = strip_subject_cols(R)\n",
    "\n",
    "    # Final merge\n",
    "    out = L.merge(R, on=\"hadm_id\", how=\"left\", suffixes=(\"\", \"\"))\n",
    "\n",
    "    # Guard: no suffixes should be present\n",
    "    bad = [c for c in out.columns if c.endswith(\"_x\") or c.endswith(\"_y\")]\n",
    "    if bad:\n",
    "        raise RuntimeError(\n",
    "            f\"Merge with {right_name} produced suffixed columns {bad}. \"\n",
    "            \"You likely have overlapping column names other than hadm_id.\"\n",
    "        )\n",
    "    return out\n",
    "\n",
    "print(\"Safe merge helpers loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c42e42",
   "metadata": {},
   "source": [
    "## 6) NIH/OMB race & ethnicity (ED + Hospital)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02bf38",
   "metadata": {},
   "source": [
    "**Rationale:** Harmonize race/ethnicity across sources using NIH/OMB categories for consistent reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb57c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717937.262110 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race/Eth rows: 84152\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "race_hosp_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race_ed_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nih_race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nih_ethnicity",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4fb6ba4c-f03a-46f7-b897-b76fe3085a22",
       "rows": [
        [
         "0",
         "28025587",
         "black/african american",
         "black/african american",
         "Black or African American",
         "Not Hispanic or Latino"
        ],
        [
         "1",
         "22418467",
         "unknown",
         "unknown",
         "Unknown or Not Reported",
         "Unknown or Not Reported"
        ],
        [
         "2",
         "26511066",
         "hispanic/latino - guatemalan",
         "hispanic/latino - guatemalan",
         "Unknown or Not Reported",
         "Hispanic or Latino"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>race_hosp_raw</th>\n",
       "      <th>race_ed_raw</th>\n",
       "      <th>nih_race</th>\n",
       "      <th>nih_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28025587</td>\n",
       "      <td>black/african american</td>\n",
       "      <td>black/african american</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22418467</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Unknown or Not Reported</td>\n",
       "      <td>Unknown or Not Reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26511066</td>\n",
       "      <td>hispanic/latino - guatemalan</td>\n",
       "      <td>hispanic/latino - guatemalan</td>\n",
       "      <td>Unknown or Not Reported</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id                 race_hosp_raw                   race_ed_raw  \\\n",
       "0  28025587        black/african american        black/african american   \n",
       "1  22418467                       unknown                       unknown   \n",
       "2  26511066  hispanic/latino - guatemalan  hispanic/latino - guatemalan   \n",
       "\n",
       "                    nih_race            nih_ethnicity  \n",
       "0  Black or African American   Not Hispanic or Latino  \n",
       "1    Unknown or Not Reported  Unknown or Not Reported  \n",
       "2    Unknown or Not Reported       Hispanic or Latino  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_eth_sql = rf\"\"\"\n",
    "WITH hadms AS (\n",
    "  SELECT x AS hadm_id\n",
    "  FROM UNNEST(@hadms) AS x\n",
    "),\n",
    "\n",
    "-- Hospital admission \"race\" text\n",
    "hosp AS (\n",
    "  SELECT a.hadm_id, LOWER(TRIM(a.race)) AS race_hosp_raw\n",
    "  FROM `{PHYS}.{HOSP}.admissions` a\n",
    "  JOIN hadms hm USING (hadm_id)\n",
    "),\n",
    "\n",
    "-- Earliest ED stay leading to the admission; take its \"race\" text if present\n",
    "ed_first AS (\n",
    "  SELECT\n",
    "    e.hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(e.intime AS intime, LOWER(TRIM(e.race)) AS race_ed_raw)\n",
    "               ORDER BY e.intime ASC LIMIT 1))[OFFSET(0)] AS pick\n",
    "  FROM `{PHYS}.{ED}.edstays` e\n",
    "  JOIN hadms hm USING (hadm_id)\n",
    "  GROUP BY e.hadm_id\n",
    "),\n",
    "ed AS (\n",
    "  SELECT hadm_id, pick.race_ed_raw\n",
    "  FROM ed_first\n",
    "),\n",
    "\n",
    "-- Combine ED + Hospital for maximum coverage\n",
    "comb AS (\n",
    "  SELECT\n",
    "    hm.hadm_id,\n",
    "    ho.race_hosp_raw,\n",
    "    ed.race_ed_raw,\n",
    "    TRIM(REGEXP_REPLACE(CONCAT(COALESCE(ho.race_hosp_raw,''), ' ', COALESCE(ed.race_ed_raw,'')), r'\\s+', ' ')) AS race_text_any\n",
    "  FROM hadms hm\n",
    "  LEFT JOIN hosp ho USING (hadm_id)\n",
    "  LEFT JOIN ed   ed USING (hadm_id)\n",
    "),\n",
    "\n",
    "-- Tokenization to OMB families + Hispanic ethnicity\n",
    "tok AS (\n",
    "  SELECT\n",
    "    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,\n",
    "\n",
    "    -- Ethnicity (Hispanic)\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\b(hispanic|latinx|latino|latina)\\b') AS is_hisp,\n",
    "\n",
    "    -- Race families (use boundaries to reduce false positives)\n",
    "    REGEXP_CONTAINS(race_text_any, r'american\\s+indian|\\balaska\\b') AS is_aian,\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\basian\\b') AS is_asian,\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\b(black|african\\s+american)\\b') AS is_black,\n",
    "    REGEXP_CONTAINS(race_text_any, r'hawaiian|pacific\\s+islander') AS is_nhopi,\n",
    "    REGEXP_CONTAINS(race_text_any, r'\\bwhite\\b|caucasian') AS is_white,\n",
    "\n",
    "    -- Unknown/other indicators\n",
    "    REGEXP_CONTAINS(race_text_any, r'unknown|other|declined|unable|not\\s+reported|missing|null') AS is_unknown_any,\n",
    "\n",
    "    -- Multi-race hints\n",
    "    REGEXP_CONTAINS(race_text_any, r'(two|2)\\s+or\\s+more|multi|biracial|multiracial') AS is_multi_hint\n",
    "  FROM comb\n",
    "),\n",
    "\n",
    "-- Decide ethnicity per NIH\n",
    "ethn AS (\n",
    "  SELECT\n",
    "    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,\n",
    "    CASE\n",
    "      WHEN is_hisp THEN 'Hispanic or Latino'\n",
    "      WHEN (race_text_any IS NULL OR race_text_any = '' OR is_unknown_any) THEN 'Unknown or Not Reported'\n",
    "      ELSE 'Not Hispanic or Latino'\n",
    "    END AS nih_ethnicity,\n",
    "    (CAST(is_aian AS INT64) + CAST(is_asian AS INT64) + CAST(is_black AS INT64)\n",
    "     + CAST(is_nhopi AS INT64) + CAST(is_white AS INT64)) AS race_hits,\n",
    "    is_aian, is_asian, is_black, is_nhopi, is_white, is_multi_hint, is_unknown_any\n",
    "  FROM tok\n",
    "),\n",
    "\n",
    "-- Decide race per NIH/OMB (1997)\n",
    "race_assign AS (\n",
    "  SELECT\n",
    "    hadm_id, race_hosp_raw, race_ed_raw, race_text_any, nih_ethnicity,\n",
    "    CASE\n",
    "      WHEN race_hits >= 2 OR is_multi_hint THEN 'More than one race'\n",
    "      WHEN is_aian THEN 'American Indian or Alaska Native'\n",
    "      WHEN is_asian THEN 'Asian'\n",
    "      WHEN is_black THEN 'Black or African American'\n",
    "      WHEN is_nhopi THEN 'Native Hawaiian or Other Pacific Islander'\n",
    "      WHEN is_white THEN 'White'\n",
    "      WHEN is_unknown_any OR race_text_any IS NULL OR race_text_any = '' THEN 'Unknown or Not Reported'\n",
    "      ELSE 'Unknown or Not Reported'\n",
    "    END AS nih_race\n",
    "  FROM ethn\n",
    ")\n",
    "\n",
    "SELECT hadm_id, race_hosp_raw, race_ed_raw, nih_race, nih_ethnicity\n",
    "FROM race_assign\n",
    "\"\"\"\n",
    "race_eth = run_sql_bq(race_eth_sql, {\"hadms\": hadm_list})\n",
    "print(\"Race/Eth rows:\", len(race_eth))\n",
    "race_eth.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46324987",
   "metadata": {},
   "source": [
    "## 7) ED triage (linked to hadm) and first ED vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cbc23",
   "metadata": {},
   "source": [
    "**Rationale:** Capture ED presentation features (vitals and chief complaint) for symptom and severity analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36d4797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717944.653963 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED triage rows: 27460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717952.072851 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED first vitals rows: 25575\n"
     ]
    }
   ],
   "source": [
    "# ED triage\n",
    "ed_triage_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "edmap AS (\n",
    "  SELECT stay_id, hadm_id, intime\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "),\n",
    "tri AS (\n",
    "  SELECT stay_id, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint\n",
    "  FROM `{PHYS}.{ED}.triage`\n",
    "),\n",
    "tri_by_stay AS (\n",
    "  SELECT m.hadm_id, m.intime, t.*\n",
    "  FROM edmap m\n",
    "  JOIN tri t USING (stay_id)\n",
    "),\n",
    "tri_by_hadm AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(intime, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint)\n",
    "               ORDER BY intime LIMIT 1))[OFFSET(0)] AS pick\n",
    "  FROM tri_by_stay\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  pick.temperature    AS ed_triage_temp,\n",
    "  pick.heartrate      AS ed_triage_hr,\n",
    "  pick.resprate       AS ed_triage_rr,\n",
    "  pick.o2sat          AS ed_triage_o2sat,\n",
    "  pick.sbp            AS ed_triage_sbp,\n",
    "  pick.dbp            AS ed_triage_dbp,\n",
    "  pick.pain           AS ed_triage_pain,\n",
    "  pick.acuity         AS ed_triage_acuity,\n",
    "  pick.chiefcomplaint AS ed_triage_cc\n",
    "FROM tri_by_hadm\n",
    "\"\"\"\n",
    "ed_triage = run_sql_bq(ed_triage_sql, {\"hadms\": hadm_list})\n",
    "print(\"ED triage rows:\", len(ed_triage))\n",
    "\n",
    "# First ED vitals\n",
    "ed_first_vitals_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "edmap AS (\n",
    "  SELECT stay_id, hadm_id\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "),\n",
    "vs AS (\n",
    "  SELECT stay_id, charttime, temperature, heartrate, resprate, o2sat, sbp, dbp, rhythm, pain\n",
    "  FROM `{PHYS}.{ED}.vitalsign`\n",
    "),\n",
    "first_vs AS (\n",
    "  SELECT\n",
    "    m.hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(v.charttime, v.temperature, v.heartrate, v.resprate, v.o2sat, v.sbp, v.dbp, v.rhythm, v.pain)\n",
    "               ORDER BY v.charttime LIMIT 1))[OFFSET(0)] AS pick\n",
    "  FROM edmap m JOIN vs v USING (stay_id)\n",
    "  GROUP BY m.hadm_id\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  pick.charttime   AS ed_first_vitals_time,\n",
    "  pick.temperature AS ed_first_temp,\n",
    "  pick.heartrate   AS ed_first_hr,\n",
    "  pick.resprate    AS ed_first_rr,\n",
    "  pick.o2sat       AS ed_first_o2sat,\n",
    "  pick.sbp         AS ed_first_sbp,\n",
    "  pick.dbp         AS ed_first_dbp,\n",
    "  pick.rhythm      AS ed_first_rhythm,\n",
    "  pick.pain        AS ed_first_pain\n",
    "FROM first_vs\n",
    "\"\"\"\n",
    "ed_first = run_sql_bq(ed_first_vitals_sql, {\"hadms\": hadm_list})\n",
    "print(\"ED first vitals rows:\", len(ed_first))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097df55c",
   "metadata": {},
   "source": [
    "## 8) ICU meta (first ICU stay, LOS days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6f8d8",
   "metadata": {},
   "source": [
    "**Rationale:** Summarize ICU exposure and length of stay to contextualize disease severity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356b3163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717959.457330 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU meta rows: 58601\n"
     ]
    }
   ],
   "source": [
    "icu_meta_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "first_icu AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(STRUCT(stay_id, intime, outtime) ORDER BY intime LIMIT 1))[OFFSET(0)] AS s\n",
    "  FROM `{PHYS}.{ICU}.icustays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "SELECT\n",
    "  hadm_id,\n",
    "  s.stay_id AS first_icu_stay_id,\n",
    "  s.intime  AS icu_intime,\n",
    "  s.outtime AS icu_outtime,\n",
    "  TIMESTAMP_DIFF(s.outtime, s.intime, HOUR)/24.0 AS icu_los_days\n",
    "FROM first_icu\n",
    "\"\"\"\n",
    "icu_meta = run_sql_bq(icu_meta_sql, {\"hadms\": hadm_list})\n",
    "print(\"ICU meta rows:\", len(icu_meta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04241211",
   "metadata": {},
   "source": [
    "## 9) Ventilation flags (ICD procedures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8dc04",
   "metadata": {},
   "source": [
    "**Rationale:** Identify IMV/NIV exposure as clinically relevant respiratory support indicators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d411472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717967.254470 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vent rows: 84152\n"
     ]
    }
   ],
   "source": [
    "# Cheaper ventilation flags: yes/no for IMV and NIV (ICD-9/ICD-10), plus any_vent_flag\n",
    "vent_sql = f\"\"\"\n",
    "WITH hadms AS (\n",
    "  SELECT x AS hadm_id\n",
    "  FROM UNNEST(@hadms) AS x\n",
    "),\n",
    "\n",
    "-- Restrict to admissions of interest early to minimize CPU\n",
    "proc AS (\n",
    "  SELECT hadm_id, icd_version, icd_code\n",
    "  FROM `{PHYS}.{HOSP}.procedures_icd`\n",
    "  JOIN hadms USING (hadm_id)\n",
    "),\n",
    "\n",
    "-- ICU Invasive Mechanical Ventilation (IMV)\n",
    "-- ICD-10-PCS (usually stored without a dot)\n",
    "imv10 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 10\n",
    "    AND icd_code IN ('5A1935Z','5A1945Z','5A1955Z','0BH17EZ','0BH18EZ')\n",
    "),\n",
    "\n",
    "-- ICD-9-CM procedures (stored sometimes with dot, sometimes without)\n",
    "imv9 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 9\n",
    "    AND (\n",
    "          icd_code IN ('96.70','96.71','96.72','96.04')  -- dotted forms\n",
    "          OR REPLACE(icd_code, '.', '') IN ('9670','9671','9672','9604') -- dotless match\n",
    "        )\n",
    "),\n",
    "\n",
    "-- Noninvasive Ventilation (NIV)\n",
    "-- ICD-10-PCS (no dot)\n",
    "niv10 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 10\n",
    "    AND icd_code IN ('5A09357','5A09457','5A09557')\n",
    "),\n",
    "\n",
    "-- ICD-9-CM (with/without dot)\n",
    "niv9 AS (\n",
    "  SELECT DISTINCT hadm_id\n",
    "  FROM proc\n",
    "  WHERE icd_version = 9\n",
    "    AND (\n",
    "          icd_code IN ('93.90','93.91','93.99')            -- dotted\n",
    "          OR REPLACE(icd_code, '.', '') IN ('9390','9391','9399')  -- dotless\n",
    "        )\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  h.hadm_id,\n",
    "  IF(i10.hadm_id IS NOT NULL OR i9.hadm_id IS NOT NULL, 1, 0) AS imv_flag,\n",
    "  IF(n10.hadm_id IS NOT NULL OR n9.hadm_id IS NOT NULL, 1, 0) AS niv_flag,\n",
    "  -- any_vent = either IMV or NIV\n",
    "  IF(\n",
    "    (i10.hadm_id IS NOT NULL OR i9.hadm_id IS NOT NULL)\n",
    "    OR (n10.hadm_id IS NOT NULL OR n9.hadm_id IS NOT NULL),\n",
    "    1, 0\n",
    "  ) AS any_vent_flag\n",
    "FROM hadms h\n",
    "LEFT JOIN imv10 i10 ON h.hadm_id = i10.hadm_id\n",
    "LEFT JOIN imv9  i9  ON h.hadm_id = i9.hadm_id\n",
    "LEFT JOIN niv10 n10 ON h.hadm_id = n10.hadm_id\n",
    "LEFT JOIN niv9  n9  ON h.hadm_id = n9.hadm_id\n",
    "\"\"\"\n",
    "\n",
    "vent = run_sql_bq(vent_sql, {\"hadms\": hadm_list})\n",
    "print(\"Vent rows:\", len(vent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cd724",
   "metadata": {},
   "source": [
    "and from charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9834f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717974.884436 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "vent_chart_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "\n",
    "stays AS (\n",
    "  SELECT hadm_id, stay_id\n",
    "  FROM `{PHYS}.{ICU}.icustays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "),\n",
    "\n",
    "cand AS (\n",
    "  SELECT\n",
    "    s.hadm_id,\n",
    "    ce.stay_id,\n",
    "    ce.charttime,\n",
    "    LOWER(di.label) AS lbl,\n",
    "    LOWER(COALESCE(ce.value,'')) AS valstr\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`    di ON di.itemid = ce.itemid\n",
    "  JOIN stays s ON s.stay_id = ce.stay_id\n",
    "  WHERE\n",
    "    -- simple pruning: look at likely respiratory/vent rows\n",
    "    (\n",
    "      REGEXP_CONTAINS(LOWER(di.label), r'(vent|ventilator|mode|bipap|bi[- ]?pap|cpap|nippv|niv|mask|ett|endotracheal)')\n",
    "      OR REGEXP_CONTAINS(LOWER(ce.value), r'(bipap|bi[- ]?pap|cpap|nippv|niv|endotracheal|ett|ac/|simv|prvc|aprv|pcv|vcv|assist\\\\s*control)')\n",
    "    )\n",
    "),\n",
    "\n",
    "flags AS (\n",
    "  SELECT\n",
    "    hadm_id,\n",
    "    MAX( CASE\n",
    "            WHEN REGEXP_CONTAINS(lbl,   r'(non[- ]?invasive|niv|nippv|bipap|bi[- ]?pap|cpap)')\n",
    "              OR REGEXP_CONTAINS(valstr,r'(non[- ]?invasive|niv|nippv|bipap|bi[- ]?pap|cpap)')\n",
    "            THEN 1 ELSE 0\n",
    "        END ) AS niv_chart_flag,\n",
    "\n",
    "    MAX( CASE\n",
    "            WHEN REGEXP_CONTAINS(lbl,   r'(invasive ventilation|endotracheal|ett|mech(|anical)? vent|ventilator mode|ac/|simv|prvc|aprv|pcv|vcv|assist\\\\s*control)')\n",
    "              OR REGEXP_CONTAINS(valstr,r'(invasive ventilation|endotracheal|ett|ac/|simv|prvc|aprv|pcv|vcv|assist\\\\s*control)')\n",
    "            THEN 1 ELSE 0\n",
    "        END ) AS imv_chart_flag\n",
    "  FROM cand\n",
    "  GROUP BY hadm_id\n",
    ")\n",
    "\n",
    "SELECT hadm_id, niv_chart_flag, imv_chart_flag\n",
    "FROM flags\n",
    "\"\"\"\n",
    "vent_chart = run_sql_bq(vent_chart_sql, {\"hadms\": hadm_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c096d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After combining ICD + chart signals: \n",
      "IMV=1: 53082 \n",
      "NIV=1: 24241\n"
     ]
    }
   ],
   "source": [
    "# If your existing ICD-only result is called `vent`, rename for clarity:\n",
    "vent_proc = vent.copy()\n",
    "\n",
    "# Outer merge so we keep hadm_ids that appear in only one source\n",
    "vent_combined = vent_proc.merge(vent_chart, on=\"hadm_id\", how=\"outer\")\n",
    "\n",
    "# Fill missing with 0 before taking maxima\n",
    "for c in [\"imv_flag\",\"niv_flag\",\"any_vent_flag\",\"imv_chart_flag\",\"niv_chart_flag\"]:\n",
    "    if c in vent_combined.columns:\n",
    "        vent_combined[c] = vent_combined[c].fillna(0).astype(\"Int64\")\n",
    "\n",
    "# Final \"any-source\" flags\n",
    "vent_combined[\"imv_flag\"]       = vent_combined[[\"imv_flag\",\"imv_chart_flag\"]].max(axis=1).astype(\"Int64\")\n",
    "vent_combined[\"niv_flag\"]       = vent_combined[[\"niv_flag\",\"niv_chart_flag\"]].max(axis=1).astype(\"Int64\")\n",
    "vent_combined[\"any_vent_flag\"]  = vent_combined[[\"imv_flag\",\"niv_flag\"]].max(axis=1).astype(\"Int64\")\n",
    "\n",
    "vent_combined = vent_combined[[\"hadm_id\",\"imv_flag\",\"niv_flag\",\"any_vent_flag\"]]\n",
    "print(\"After combining ICD + chart signals:\",\n",
    "      \"\\nIMV=1:\", int((vent_combined[\"imv_flag\"]==1).sum()),\n",
    "      \"\\nNIV=1:\", int((vent_combined[\"niv_flag\"]==1).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81ddd8",
   "metadata": {},
   "source": [
    "## 10) Assemble final DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af830bbe",
   "metadata": {},
   "source": [
    "**Rationale:** Merge all derived features into a single analytic table keyed by hadm_id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43442b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final df rows: 84152 cols: 85\n",
      "Final df rows: 84152 cols: 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "admittime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "dischtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "deathtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "admission_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "admission_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "discharge_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "insurance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hosp_los_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_in_hosp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age_at_admit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "death_30d",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9602",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9612",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9622",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_J9692",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD10_E662",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICD9_27803",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_hosp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "any_hypercap_icd_ed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "icd_source",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "abg_hypercap_threshold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "vbg_hypercap_threshold",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pco2_threshold_any",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "enrolled_any",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lab_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "lab_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lab_vbg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "lab_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_abg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_abg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_ph_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_paco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "poc_vbg_paco2_uom",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "poc_vbg_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "first_abg_src",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "first_abg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_abg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_abg_pco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_src",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_vbg_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "first_vbg_ph",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_vbg_pco2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "race_hosp_raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race_ed_raw",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "nih_race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nih_ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ed_triage_temp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_hr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_rr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_o2sat",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_sbp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_dbp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_pain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_acuity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_triage_cc",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_vitals_time",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "ed_first_temp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_hr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_rr",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_o2sat",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_sbp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ed_first_dbp",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "ed_first_rhythm",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ed_first_pain",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "first_icu_stay_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "icu_intime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "icu_outtime",
         "rawType": "datetime64[us]",
         "type": "unknown"
        },
        {
         "name": "icu_los_days",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "imv_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "niv_flag",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "any_vent_flag",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "30b9655c-0dca-4f56-a380-0e8643c06a09",
       "rows": [
        [
         "0",
         "26713233",
         "10106244",
         "2147-05-09 10:34:00",
         "2147-05-12 13:43:00",
         null,
         "DIRECT EMER.",
         "PHYSICIAN REFERRAL",
         "HOME",
         "Private",
         "3.125",
         "0",
         "F",
         "63.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         "1",
         "0",
         "1",
         "1",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "114.0",
         "mmhg",
         "2147-05-09 11:33:00",
         null,
         null,
         null,
         null,
         null,
         "POC",
         "2147-05-09 11:33:00",
         null,
         "114.0",
         null,
         null,
         null,
         null,
         "white",
         null,
         "White",
         "Not Hispanic or Latino",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "34344296",
         "2147-05-09 10:35:46",
         "2147-05-11 23:45:18",
         "2.5416666666666665",
         "1",
         "0",
         "1"
        ],
        [
         "1",
         "23485217",
         "10584718",
         "2165-02-12 15:41:00",
         "2165-03-06 08:20:00",
         "2165-03-06 08:20:00",
         "EW EMER.",
         "TRANSFER FROM SKILLED NURSING FACILITY",
         "DIED",
         "Medicare",
         "21.708333333333332",
         "1",
         "M",
         "78.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         "1",
         "1",
         "1",
         "1",
         null,
         null,
         null,
         null,
         null,
         "7.26",
         "units",
         "50.0",
         "mmhg",
         "2165-02-27 13:43:00",
         null,
         null,
         "160.0",
         "mmhg",
         "2165-03-02 07:34:00",
         "7.22",
         null,
         "53.0",
         "mmhg",
         "2165-02-27 23:07:00",
         "POC",
         "2165-03-02 07:34:00",
         null,
         "160.0",
         "LAB",
         "2165-02-27 13:43:00",
         "7.26",
         "50.0",
         "white",
         null,
         "White",
         "Not Hispanic or Latino",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "36809832",
         "2165-02-27 21:41:10",
         "2165-03-06 11:09:58",
         "6.583333333333333",
         "1",
         "0",
         "1"
        ],
        [
         "2",
         "27004173",
         "10297948",
         "2135-08-23 18:46:00",
         "2135-09-08 15:50:00",
         null,
         "URGENT",
         "TRANSFER FROM HOSPITAL",
         "CHRONIC/LONG TERM ACUTE CARE",
         "Private",
         "15.875",
         "0",
         "F",
         "70.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         null,
         "1",
         "0",
         "1",
         "1",
         "7.4",
         "units",
         "42.0",
         "mmhg",
         "2135-08-27 13:33:00",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "LAB",
         "2135-08-27 13:33:00",
         "7.4",
         "42.0",
         null,
         null,
         null,
         null,
         "white",
         null,
         "White",
         "Not Hispanic or Latino",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 85,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>hosp_los_days</th>\n",
       "      <th>...</th>\n",
       "      <th>ed_first_dbp</th>\n",
       "      <th>ed_first_rhythm</th>\n",
       "      <th>ed_first_pain</th>\n",
       "      <th>first_icu_stay_id</th>\n",
       "      <th>icu_intime</th>\n",
       "      <th>icu_outtime</th>\n",
       "      <th>icu_los_days</th>\n",
       "      <th>imv_flag</th>\n",
       "      <th>niv_flag</th>\n",
       "      <th>any_vent_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26713233</td>\n",
       "      <td>10106244</td>\n",
       "      <td>2147-05-09 10:34:00</td>\n",
       "      <td>2147-05-12 13:43:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DIRECT EMER.</td>\n",
       "      <td>PHYSICIAN REFERRAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34344296</td>\n",
       "      <td>2147-05-09 10:35:46</td>\n",
       "      <td>2147-05-11 23:45:18</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23485217</td>\n",
       "      <td>10584718</td>\n",
       "      <td>2165-02-12 15:41:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>2165-03-06 08:20:00</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n",
       "      <td>DIED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>21.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36809832</td>\n",
       "      <td>2165-02-27 21:41:10</td>\n",
       "      <td>2165-03-06 11:09:58</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27004173</td>\n",
       "      <td>10297948</td>\n",
       "      <td>2135-08-23 18:46:00</td>\n",
       "      <td>2135-09-08 15:50:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>CHRONIC/LONG TERM ACUTE CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  subject_id           admittime           dischtime  \\\n",
       "0  26713233    10106244 2147-05-09 10:34:00 2147-05-12 13:43:00   \n",
       "1  23485217    10584718 2165-02-12 15:41:00 2165-03-06 08:20:00   \n",
       "2  27004173    10297948 2135-08-23 18:46:00 2135-09-08 15:50:00   \n",
       "\n",
       "            deathtime admission_type                      admission_location  \\\n",
       "0                 NaT   DIRECT EMER.                      PHYSICIAN REFERRAL   \n",
       "1 2165-03-06 08:20:00       EW EMER.  TRANSFER FROM SKILLED NURSING FACILITY   \n",
       "2                 NaT         URGENT                  TRANSFER FROM HOSPITAL   \n",
       "\n",
       "             discharge_location insurance  hosp_los_days  ...  ed_first_dbp  \\\n",
       "0                          HOME   Private       3.125000  ...          <NA>   \n",
       "1                          DIED  Medicare      21.708333  ...          <NA>   \n",
       "2  CHRONIC/LONG TERM ACUTE CARE   Private      15.875000  ...          <NA>   \n",
       "\n",
       "  ed_first_rhythm  ed_first_pain  first_icu_stay_id          icu_intime  \\\n",
       "0             NaN            NaN           34344296 2147-05-09 10:35:46   \n",
       "1             NaN            NaN           36809832 2165-02-27 21:41:10   \n",
       "2             NaN            NaN               <NA>                 NaT   \n",
       "\n",
       "          icu_outtime  icu_los_days  imv_flag  niv_flag  any_vent_flag  \n",
       "0 2147-05-11 23:45:18      2.541667         1         0              1  \n",
       "1 2165-03-06 11:09:58      6.583333         1         0              1  \n",
       "2                 NaT           NaN         0         0              0  \n",
       "\n",
       "[3 rows x 85 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Canonical base (carries authoritative subject_id)\n",
    "df = demo.copy()\n",
    "\n",
    "# Cohort flags / thresholds / labs / etc.\n",
    "df = safe_merge_on_hadm(df, cohort_any, right_name=\"cohort_any\", check_subject=\"warn\")\n",
    "df = safe_merge_on_hadm(df, bg_pairs,   right_name=\"bg_pairs\")\n",
    "df = safe_merge_on_hadm(df, race_eth,   right_name=\"race_eth\")\n",
    "df = safe_merge_on_hadm(df, ed_triage,  right_name=\"ed_triage\")\n",
    "df = safe_merge_on_hadm(df, ed_first,   right_name=\"ed_first\")\n",
    "df = safe_merge_on_hadm(df, icu_meta,   right_name=\"icu_meta\")\n",
    "df = safe_merge_on_hadm(df, vent_combined,       right_name=\"vent_combined\")\n",
    "\n",
    "print(\"Final df rows:\", len(df), \"cols:\", len(df.columns))\n",
    "\n",
    "# Safety checks\n",
    "assert \"subject_id\" in df.columns, \"subject_id missing from final df\"\n",
    "assert not any(c.endswith(\"_x\") or c.endswith(\"_y\") for c in df.columns), \"Found suffixed columns\"\n",
    "print(\"Final df rows:\", len(df), \"cols:\", len(df.columns))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "806f96a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769717985.489100 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1769717987.495431 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "scope",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "21e33455-3cca-4cfc-96cb-4bd7b9c1cd4a",
       "rows": [
        [
         "0",
         "Total ED encounters (edstays)",
         "425087",
         "All ED dataset"
        ],
        [
         "1",
         "ED encounters with hadm_id",
         "203016",
         "All ED dataset"
        ],
        [
         "2",
         "ED→ICU admissions (distinct hadm_id)",
         "31862",
         "All ED+ICU"
        ],
        [
         "3",
         "ED→ICU ED-stays (distinct stay_id)",
         "31916",
         "All ED+ICU"
        ],
        [
         "4",
         "Cohort admissions (union ICD ∪ thresholds)",
         "84153",
         "Cohort"
        ],
        [
         "5",
         "Cohort admissions after merges (df rows)",
         "84152",
         "Cohort"
        ],
        [
         "6",
         "Cohort with any ABG/VBG (LAB or POC)",
         "81755",
         "Cohort"
        ],
        [
         "7",
         "Cohort meeting hypercapnia thresholds",
         "83470",
         "Cohort"
        ],
        [
         "8",
         "Cohort meeting ICD code criteria",
         "4237",
         "Cohort"
        ],
        [
         "9",
         "Cohort with ED chief complaint present",
         "27459",
         "Cohort"
        ],
        [
         "10",
         "Cohort excluded for missing ED chief complaint",
         "56693",
         "Cohort"
        ],
        [
         "11",
         "Cohort ED→ICU (ED CC present + ICU stay)",
         "19434",
         "Cohort"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>count</th>\n",
       "      <th>scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total ED encounters (edstays)</td>\n",
       "      <td>425087</td>\n",
       "      <td>All ED dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ED encounters with hadm_id</td>\n",
       "      <td>203016</td>\n",
       "      <td>All ED dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ED→ICU admissions (distinct hadm_id)</td>\n",
       "      <td>31862</td>\n",
       "      <td>All ED+ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ED→ICU ED-stays (distinct stay_id)</td>\n",
       "      <td>31916</td>\n",
       "      <td>All ED+ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cohort admissions (union ICD ∪ thresholds)</td>\n",
       "      <td>84153</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cohort admissions after merges (df rows)</td>\n",
       "      <td>84152</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cohort with any ABG/VBG (LAB or POC)</td>\n",
       "      <td>81755</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cohort meeting hypercapnia thresholds</td>\n",
       "      <td>83470</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cohort meeting ICD code criteria</td>\n",
       "      <td>4237</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cohort with ED chief complaint present</td>\n",
       "      <td>27459</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cohort excluded for missing ED chief complaint</td>\n",
       "      <td>56693</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cohort ED→ICU (ED CC present + ICU stay)</td>\n",
       "      <td>19434</td>\n",
       "      <td>Cohort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              step   count           scope\n",
       "0                    Total ED encounters (edstays)  425087  All ED dataset\n",
       "1                       ED encounters with hadm_id  203016  All ED dataset\n",
       "2             ED→ICU admissions (distinct hadm_id)   31862      All ED+ICU\n",
       "3               ED→ICU ED-stays (distinct stay_id)   31916      All ED+ICU\n",
       "4       Cohort admissions (union ICD ∪ thresholds)   84153          Cohort\n",
       "5         Cohort admissions after merges (df rows)   84152          Cohort\n",
       "6             Cohort with any ABG/VBG (LAB or POC)   81755          Cohort\n",
       "7            Cohort meeting hypercapnia thresholds   83470          Cohort\n",
       "8                 Cohort meeting ICD code criteria    4237          Cohort\n",
       "9           Cohort with ED chief complaint present   27459          Cohort\n",
       "10  Cohort excluded for missing ED chief complaint   56693          Cohort\n",
       "11        Cohort ED→ICU (ED CC present + ICU stay)   19434          Cohort"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cohort flow counts (ED / ICU / blood gas / hypercapnia / CC) ---\n",
    "\n",
    "# 1) Dataset-level ED counts\n",
    "ed_counts_sql = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS total_ed_encounters,\n",
    "  COUNTIF(hadm_id IS NOT NULL) AS ed_encounters_with_hadm\n",
    "FROM `{PHYS}.{ED}.edstays`\n",
    "\"\"\"\n",
    "\n",
    "ed_to_icu_sql = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(DISTINCT e.hadm_id) AS ed_to_icu_hadm,\n",
    "  COUNT(DISTINCT e.stay_id) AS ed_to_icu_edstays\n",
    "FROM `{PHYS}.{ED}.edstays` e\n",
    "JOIN `{PHYS}.{ICU}.icustays` i USING (hadm_id)\n",
    "WHERE e.hadm_id IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    ed_counts = run_sql_bq(ed_counts_sql)\n",
    "    ed_to_icu = run_sql_bq(ed_to_icu_sql)\n",
    "except Exception as e:\n",
    "    print(\"Warning: ED/ICU counts query failed:\", e)\n",
    "    ed_counts = None\n",
    "    ed_to_icu = None\n",
    "\n",
    "# 2) Cohort-level counts (admission-level)\n",
    "cohort_union = int((cohort_any[\"enrolled_any\"] == 1).sum()) if \"cohort_any\" in globals() and \"enrolled_any\" in cohort_any.columns else len(hadm_list)\n",
    "cohort_df_n = len(df)\n",
    "\n",
    "# Any blood gas present (ABG/VBG, LAB/POC)\n",
    "co2_cols = [c for c in [\n",
    "    \"lab_abg_paco2\", \"lab_vbg_paco2\", \"poc_abg_paco2\", \"poc_vbg_paco2\"\n",
    "] if c in df.columns]\n",
    "any_bg = int(df[co2_cols].notna().any(axis=1).sum()) if co2_cols else None\n",
    "\n",
    "# Hypercapnia thresholds and ICD\n",
    "icd_count = int((df[\"any_hypercap_icd\"] == 1).sum()) if \"any_hypercap_icd\" in df.columns else None\n",
    "threshold_count = int((df[\"pco2_threshold_any\"] == 1).sum()) if \"pco2_threshold_any\" in df.columns else None\n",
    "\n",
    "# ED chief complaint missing / present (within cohort)\n",
    "if \"ed_triage_cc\" in df.columns:\n",
    "    mask_cc_present = df[\"ed_triage_cc\"].notna() & (df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "    cc_present = int(mask_cc_present.sum())\n",
    "    cc_missing = int((~mask_cc_present).sum())\n",
    "else:\n",
    "    cc_present = None\n",
    "    cc_missing = None\n",
    "\n",
    "# ED→ICU within cohort (admissions with ED triage data and ICU stay)\n",
    "if \"first_icu_stay_id\" in df.columns and \"ed_triage_cc\" in df.columns:\n",
    "    cohort_ed_to_icu = int((df[\"first_icu_stay_id\"].notna() & mask_cc_present).sum())\n",
    "else:\n",
    "    cohort_ed_to_icu = None\n",
    "\n",
    "rows = []\n",
    "if ed_counts is not None:\n",
    "    rows.append({\"step\": \"Total ED encounters (edstays)\", \"count\": int(ed_counts.loc[0, \"total_ed_encounters\"]), \"scope\": \"All ED dataset\"})\n",
    "    rows.append({\"step\": \"ED encounters with hadm_id\", \"count\": int(ed_counts.loc[0, \"ed_encounters_with_hadm\"]), \"scope\": \"All ED dataset\"})\n",
    "if ed_to_icu is not None:\n",
    "    rows.append({\"step\": \"ED→ICU admissions (distinct hadm_id)\", \"count\": int(ed_to_icu.loc[0, \"ed_to_icu_hadm\"]), \"scope\": \"All ED+ICU\"})\n",
    "    rows.append({\"step\": \"ED→ICU ED-stays (distinct stay_id)\", \"count\": int(ed_to_icu.loc[0, \"ed_to_icu_edstays\"]), \"scope\": \"All ED+ICU\"})\n",
    "\n",
    "rows.append({\"step\": \"Cohort admissions (union ICD ∪ thresholds)\", \"count\": cohort_union, \"scope\": \"Cohort\"})\n",
    "rows.append({\"step\": \"Cohort admissions after merges (df rows)\", \"count\": cohort_df_n, \"scope\": \"Cohort\"})\n",
    "if any_bg is not None:\n",
    "    rows.append({\"step\": \"Cohort with any ABG/VBG (LAB or POC)\", \"count\": any_bg, \"scope\": \"Cohort\"})\n",
    "if threshold_count is not None:\n",
    "    rows.append({\"step\": \"Cohort meeting hypercapnia thresholds\", \"count\": threshold_count, \"scope\": \"Cohort\"})\n",
    "if icd_count is not None:\n",
    "    rows.append({\"step\": \"Cohort meeting ICD code criteria\", \"count\": icd_count, \"scope\": \"Cohort\"})\n",
    "if cc_present is not None:\n",
    "    rows.append({\"step\": \"Cohort with ED chief complaint present\", \"count\": cc_present, \"scope\": \"Cohort\"})\n",
    "if cc_missing is not None:\n",
    "    rows.append({\"step\": \"Cohort excluded for missing ED chief complaint\", \"count\": cc_missing, \"scope\": \"Cohort\"})\n",
    "if cohort_ed_to_icu is not None:\n",
    "    rows.append({\"step\": \"Cohort ED→ICU (ED CC present + ICU stay)\", \"count\": cohort_ed_to_icu, \"scope\": \"Cohort\"})\n",
    "\n",
    "flow_counts = pd.DataFrame(rows)\n",
    "flow_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f3d240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABG/VBG overlap (among gas-positive):\n",
      "   group  count  pct_of_gas  pct_of_cohort\n",
      "ABG-only  42713        51.2           50.8\n",
      "VBG-only  21818        26.1           25.9\n",
      " ABG+VBG  18939        22.7           22.5\n",
      "ICD vs Gas overlap (cohort-level):\n",
      "   group  count  pct_of_cohort\n",
      " ICD+Gas   3555            4.2\n",
      "ICD-only    682            0.8\n",
      "Gas-only  79915           95.0\n",
      " Neither      0            0.0\n"
     ]
    }
   ],
   "source": [
    "# --- Ascertainment overlap counts (ABG/VBG/ICD) ---\n",
    "\n",
    "required = [\"abg_hypercap_threshold\", \"vbg_hypercap_threshold\", \"any_hypercap_icd\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns for overlap counts: {missing}\")\n",
    "\n",
    "abg = pd.to_numeric(df[\"abg_hypercap_threshold\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "vbg = pd.to_numeric(df[\"vbg_hypercap_threshold\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "gas_any = (\n",
    "    pd.to_numeric(df.get(\"pco2_threshold_any\", None), errors=\"coerce\")\n",
    "    if \"pco2_threshold_any\" in df.columns else (abg | vbg)\n",
    ")\n",
    "if hasattr(gas_any, \"fillna\"):\n",
    "    gas_any = gas_any.fillna(0).astype(int)\n",
    "else:\n",
    "    gas_any = gas_any.astype(int)\n",
    "\n",
    "icd = pd.to_numeric(df[\"any_hypercap_icd\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "total_n = len(df)\n",
    "ngas = int((gas_any == 1).sum())\n",
    "\n",
    "abg_vbg_overlap = pd.DataFrame([\n",
    "    {\"group\": \"ABG-only\", \"count\": int(((abg==1) & (vbg==0)).sum())},\n",
    "    {\"group\": \"VBG-only\", \"count\": int(((vbg==1) & (abg==0)).sum())},\n",
    "    {\"group\": \"ABG+VBG\", \"count\": int(((abg==1) & (vbg==1)).sum())},\n",
    "])\n",
    "if ngas > 0:\n",
    "    abg_vbg_overlap[\"pct_of_gas\"] = (abg_vbg_overlap[\"count\"] / ngas * 100).round(1)\n",
    "else:\n",
    "    abg_vbg_overlap[\"pct_of_gas\"] = 0.0\n",
    "abg_vbg_overlap[\"pct_of_cohort\"] = (abg_vbg_overlap[\"count\"] / max(total_n,1) * 100).round(1)\n",
    "\n",
    "icd_gas_overlap = pd.DataFrame([\n",
    "    {\"group\": \"ICD+Gas\", \"count\": int(((icd==1) & (gas_any==1)).sum())},\n",
    "    {\"group\": \"ICD-only\", \"count\": int(((icd==1) & (gas_any==0)).sum())},\n",
    "    {\"group\": \"Gas-only\", \"count\": int(((icd==0) & (gas_any==1)).sum())},\n",
    "    {\"group\": \"Neither\", \"count\": int(((icd==0) & (gas_any==0)).sum())},\n",
    "])\n",
    "icd_gas_overlap[\"pct_of_cohort\"] = (icd_gas_overlap[\"count\"] / max(total_n,1) * 100).round(1)\n",
    "\n",
    "print(\"ABG/VBG overlap (among gas-positive):\")\n",
    "print(abg_vbg_overlap.to_string(index=False))\n",
    "print(\"ICD vs Gas overlap (cohort-level):\")\n",
    "print(icd_gas_overlap.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb306488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness summary (key variables):\n",
      "Missingness summary (ED triage + first ED vitals):\n"
     ]
    }
   ],
   "source": [
    "# --- Missingness summary (chief complaint, race/ethnicity, ED triage/vitals) ---\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# Chief complaint missingness (ED triage CC)\n",
    "if \"ed_triage_cc\" in df.columns:\n",
    "    cc_present = df[\"ed_triage_cc\"].notna() & (df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "    summary_rows.append({\n",
    "        \"variable\": \"ed_triage_cc_present\",\n",
    "        \"missing_n\": int((~cc_present).sum()),\n",
    "        \"missing_pct\": float((~cc_present).mean())\n",
    "    })\n",
    "\n",
    "# Race/Ethnicity missingness (NIH categories + raw sources)\n",
    "unknown_tokens = {\n",
    "    \"unknown or not reported\",\n",
    "    \"unknown\",\n",
    "    \"not reported\",\n",
    "    \"missing\",\n",
    "    \"declined\",\n",
    "    \"unable\"\n",
    "}\n",
    "\n",
    "def _missing_rate(series):\n",
    "    if series is None:\n",
    "        return None, None\n",
    "    s = series.astype(str).str.strip()\n",
    "    is_missing = series.isna() | (s == \"\") | s.str.lower().isin(unknown_tokens)\n",
    "    return int(is_missing.sum()), float(is_missing.mean())\n",
    "\n",
    "for col in [\"nih_race\", \"nih_ethnicity\", \"race_hosp_raw\", \"race_ed_raw\"]:\n",
    "    if col in df.columns:\n",
    "        m_n, m_p = _missing_rate(df[col])\n",
    "        summary_rows.append({\n",
    "            \"variable\": col,\n",
    "            \"missing_n\": m_n,\n",
    "            \"missing_pct\": m_p\n",
    "        })\n",
    "\n",
    "missing_summary = pd.DataFrame(summary_rows)\n",
    "print(\"Missingness summary (key variables):\")\n",
    "missing_summary\n",
    "\n",
    "# ED triage + first ED vitals missingness\n",
    "triage_cols = [c for c in df.columns if c.startswith(\"ed_triage_\")]\n",
    "first_cols  = [c for c in df.columns if c.startswith(\"ed_first_\")]\n",
    "\n",
    "vital_cols = triage_cols + first_cols\n",
    "if vital_cols:\n",
    "    miss_tbl = (\n",
    "        pd.DataFrame({\"variable\": vital_cols})\n",
    "        .assign(\n",
    "            missing_n=lambda d: [int(df[c].isna().sum()) for c in d[\"variable\"]],\n",
    "            missing_pct=lambda d: [float(df[c].isna().mean()) for c in d[\"variable\"]]\n",
    "        )\n",
    "        .sort_values(\"missing_pct\", ascending=False)\n",
    "    )\n",
    "    print(\"Missingness summary (ED triage + first ED vitals):\")\n",
    "    miss_tbl\n",
    "else:\n",
    "    miss_tbl = pd.DataFrame(columns=[\"variable\", \"missing_n\", \"missing_pct\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e172e",
   "metadata": {},
   "source": [
    "## 11) Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761e99a",
   "metadata": {},
   "source": [
    "**Rationale:** Run QC checks to validate units, flags, and basic data integrity before export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39f00e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative ICU LOS rows: 0\n",
      "any_vent_flag mismatches vs (imv|niv): 0\n",
      "lab_abg_paco2_uom ['mmhg']\n",
      "lab_vbg_paco2_uom ['mmhg']\n",
      "poc_abg_paco2_uom ['mmhg']\n",
      "poc_vbg_paco2_uom ['mmhg']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pair",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "present_any",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "present_both",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "only_ph",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "only_pco2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ph_oob",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pco2_oob",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "14283f0f-b83f-42de-901e-e56213053dfc",
       "rows": [
        [
         "0",
         "LAB ABG",
         "56286",
         "55752",
         "522",
         "12",
         "0",
         "0"
        ],
        [
         "1",
         "LAB VBG",
         "43167",
         "35255",
         "7904",
         "8",
         "0",
         "0"
        ],
        [
         "2",
         "POC ABG",
         "46122",
         "20334",
         "0",
         "25788",
         "0",
         "0"
        ],
        [
         "3",
         "POC VBG",
         "36667",
         "16027",
         "0",
         "20640",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>present_any</th>\n",
       "      <th>present_both</th>\n",
       "      <th>only_ph</th>\n",
       "      <th>only_pco2</th>\n",
       "      <th>ph_oob</th>\n",
       "      <th>pco2_oob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAB ABG</td>\n",
       "      <td>56286</td>\n",
       "      <td>55752</td>\n",
       "      <td>522</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAB VBG</td>\n",
       "      <td>43167</td>\n",
       "      <td>35255</td>\n",
       "      <td>7904</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POC ABG</td>\n",
       "      <td>46122</td>\n",
       "      <td>20334</td>\n",
       "      <td>0</td>\n",
       "      <td>25788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POC VBG</td>\n",
       "      <td>36667</td>\n",
       "      <td>16027</td>\n",
       "      <td>0</td>\n",
       "      <td>20640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pair  present_any  present_both  only_ph  only_pco2  ph_oob  pco2_oob\n",
       "0  LAB ABG        56286         55752      522         12       0         0\n",
       "1  LAB VBG        43167         35255     7904          8       0         0\n",
       "2  POC ABG        46122         20334        0      25788       0         0\n",
       "3  POC VBG        36667         16027        0      20640       0         0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ICU LOS negative?\n",
    "if {\"icu_los_days\",\"first_icu_stay_id\"}.issubset(df.columns):\n",
    "    neg_los = int((df[\"icu_los_days\"] < 0).fillna(False).sum())\n",
    "    print(\"Negative ICU LOS rows:\", neg_los)\n",
    "\n",
    "# Vent flags consistency\n",
    "vent_cols = {\"imv_flag\",\"niv_flag\",\"any_vent_flag\"}\n",
    "if vent_cols.issubset(df.columns):\n",
    "    any_calc = ((df[\"imv_flag\"]==1) | (df[\"niv_flag\"]==1)).fillna(False).astype(int)\n",
    "    any_flag = pd.to_numeric(df[\"any_vent_flag\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    mism = int((any_calc != any_flag).sum())\n",
    "    print(\"any_vent_flag mismatches vs (imv|niv):\", mism)\n",
    "\n",
    "# UOMs: expect mmhg only\n",
    "uom_cols = [c for c in df.columns if c.endswith(\"_paco2_uom\")]\n",
    "for c in uom_cols:\n",
    "    vals = sorted(pd.Series(df[c]).dropna().astype(str).str.lower().str.strip().unique().tolist())\n",
    "    print(c, vals)\n",
    "\n",
    "# ABG/VBG coverage QC\n",
    "def qc_pair(df, ph_col, co2_col, label, ph_lo=6.3, ph_hi=7.8, co2_lo=5, co2_hi=200):\n",
    "    ph  = pd.to_numeric(df.get(ph_col), errors=\"coerce\")\n",
    "    co2 = pd.to_numeric(df.get(co2_col), errors=\"coerce\")\n",
    "    return {\n",
    "        \"pair\": label,\n",
    "        \"present_any\":  int(((ph.notna()) | (co2.notna())).sum()),\n",
    "        \"present_both\": int(((ph.notna()) & (co2.notna())).sum()),\n",
    "        \"only_ph\":      int(((ph.notna()) & (~co2.notna())).sum()),\n",
    "        \"only_pco2\":    int(((co2.notna()) & (~ph.notna())).sum()),\n",
    "        \"ph_oob\":       int((((ph  < ph_lo)  | (ph  > ph_hi))  & ph.notna()).sum()),\n",
    "        \"pco2_oob\":     int((((co2 < co2_lo) | (co2 > co2_hi)) & co2.notna()).sum()),\n",
    "    }\n",
    "\n",
    "qc = pd.DataFrame([\n",
    "    qc_pair(df, \"lab_abg_ph\",\"lab_abg_paco2\",\"LAB ABG\"),\n",
    "    qc_pair(df, \"lab_vbg_ph\",\"lab_vbg_paco2\",\"LAB VBG\"),\n",
    "    qc_pair(df, \"poc_abg_ph\",\"poc_abg_paco2\",\"POC ABG\"),\n",
    "    qc_pair(df, \"poc_vbg_ph\",\"poc_vbg_paco2\",\"POC VBG\"),\n",
    "])\n",
    "qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9634bf",
   "metadata": {},
   "source": [
    "## 12) Save to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5f147",
   "metadata": {},
   "source": [
    "**Rationale:** Persist cohort outputs for downstream annotation and NLP analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd24b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_bq_abg_vbg_20260129_131949.xlsx')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "out_path = DATA_DIR / f\"mimic_hypercap_EXT_bq_abg_vbg_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xw:\n",
    "    df.to_excel(xw, sheet_name=\"cohort\", index=False)\n",
    "    try:\n",
    "        qc.to_excel(xw, sheet_name=\"qc_abg_vbg\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28e47c",
   "metadata": {},
   "source": [
    "## Create Annotation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a607a4",
   "metadata": {},
   "source": [
    "**Rationale:** Create ED chief-complaint subsets and a reproducible sample for manual annotation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd4b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED-CC present rows: 27459 of 84152 (32.6% of cohort).\n",
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_EDcc_only_bq_abg_vbg_20260129_132116.xlsx\n",
      "Saved: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/MIMIC tabular data/mimic_hypercap_EXT_EDcc_sample160_bq_abg_vbg_20260129_132116.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---- Extra exports: (1) ED chief-complaint only; (2) random sample of 160 patients ----\n",
    "from datetime import datetime\n",
    "\n",
    "# Where to write\n",
    "out_dir = DATA_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 1) Filter to rows with a non-empty ED chief complaint\n",
    "if \"ed_triage_cc\" not in df.columns:\n",
    "    raise KeyError(\n",
    "        \"Column 'ed_triage_cc' not found in df. \"\n",
    "        \"Ensure the ED triage merge cell ran earlier.\"\n",
    "    )\n",
    "\n",
    "mask_cc = df[\"ed_triage_cc\"].notna() & (df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "df_cc = df.loc[mask_cc].copy()\n",
    "\n",
    "print(f\"ED-CC present rows: {len(df_cc)} of {len(df)} \"\n",
    "      f\"({(len(df_cc) / max(len(df),1)):.1%} of cohort).\")\n",
    "\n",
    "# Save ED-CC-only cohort\n",
    "out_path_cc = out_dir / f\"mimic_hypercap_EXT_EDcc_only_bq_abg_vbg_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(out_path_cc, engine=\"openpyxl\") as xw:\n",
    "    df_cc.to_excel(xw, sheet_name=\"cohort_cc_only\", index=False)\n",
    "    try:\n",
    "        qc.to_excel(xw, sheet_name=\"qc_abg_vbg\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"Saved:\", out_path_cc)\n",
    "\n",
    "# 2) Random sample of n = 160 patients (distinct subject_id), one row per patient\n",
    "if \"subject_id\" not in df_cc.columns:\n",
    "    raise KeyError(\"Column 'subject_id' missing; cannot sample by patient.\")\n",
    "\n",
    "# Make a one-row-per-patient frame by earliest admission\n",
    "if \"admittime\" in df_cc.columns:\n",
    "    df_cc_one = (\n",
    "        df_cc.sort_values([\"subject_id\", \"admittime\"])\n",
    "             .groupby(\"subject_id\", as_index=False)\n",
    "             .head(1)\n",
    "    )\n",
    "else:\n",
    "    # Fallback if admittime not present: choose the smallest hadm_id per patient\n",
    "    df_cc_one = (\n",
    "        df_cc.sort_values([\"subject_id\", \"hadm_id\"])\n",
    "             .groupby(\"subject_id\", as_index=False)\n",
    "             .head(1)\n",
    "    )\n",
    "\n",
    "N = 160\n",
    "n_avail = len(df_cc_one)\n",
    "n_take = min(N, n_avail)\n",
    "if n_avail < N:\n",
    "    print(f\"Warning: only {n_avail} unique patients with ED chief complaint; sampling all of them.\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "df_cc_sample = df_cc_one.sample(n=n_take, random_state=RANDOM_SEED)\n",
    "\n",
    "# Save the sample\n",
    "out_path_cc_sample = out_dir / f\"mimic_hypercap_EXT_EDcc_sample{n_take}_bq_abg_vbg_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(out_path_cc_sample, engine=\"openpyxl\") as xw:\n",
    "    df_cc_sample.to_excel(xw, sheet_name=\"cohort_cc_sample\", index=False)\n",
    "    try:\n",
    "        qc.to_excel(xw, sheet_name=\"qc_abg_vbg\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "print(\"Saved:\", out_path_cc_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e098c6",
   "metadata": {},
   "source": [
    "# ED-stay cohort expansion (timing, severity, comorbidity, outcomes)\n",
    "\n",
    "**Rationale:** Build a one-row-per-ED-stay analytic extract with time-anchored gas phenotypes, key comorbidities, and outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b296e",
   "metadata": {},
   "source": [
    "## Phase 0 — Inventory & missing-field registry\n",
    "\n",
    "**Rationale:** Detect which fields already exist and only add missing fields to avoid redundant extraction or join explosions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d50acefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current admission-level df: (84152, 85)\n",
      "Current columns count: 85\n",
      "ED stay unique count: ED_KEY not in columns\n",
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/current_columns.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Identify current cohort dataframe (admission-level)\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"Expected admission-level df to exist before inventory step.\")\n",
    "\n",
    "ED_KEY = \"ed_stay_id\"  # target key for ED-level cohort\n",
    "\n",
    "print(\"Current admission-level df:\", df.shape)\n",
    "print(\"Current columns count:\", len(df.columns))\n",
    "if ED_KEY in df.columns:\n",
    "    print(\"ED stay unique count:\", int(df[ED_KEY].nunique()))\n",
    "else:\n",
    "    print(\"ED stay unique count: ED_KEY not in columns\")\n",
    "\n",
    "# Persist columns snapshot\n",
    "cols_out = WORK_DIR / \"current_columns.json\"\n",
    "cols_out.write_text(json.dumps(sorted(df.columns), indent=2))\n",
    "print(\"Wrote:\", cols_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fff412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing fields total: 48\n",
      "- ed_edstays: ['ed_stay_id', 'ed_intime', 'ed_outtime', 'arrival_transport', 'disposition', 'ed_gender', 'ed_race']\n",
      "- admissions: ['hospital_expire_flag', 'language', 'marital_status', 'hosp_race']\n",
      "- icu: ['icu_stay_id', 'icu_intime_first', 'icu_outtime_last', 'icu_los_total', 'n_icu_stays', 'first_careunit', 'last_careunit']\n",
      "- labs_gas: ['first_gas_time', 'first_pco2', 'first_ph', 'first_hco3', 'first_lactate', 'max_pco2_0_6h', 'min_ph_0_6h', 'max_pco2_0_24h', 'min_ph_0_24h', 'flag_abg_hypercapnia', 'flag_vbg_hypercapnia', 'flag_any_gas_hypercapnia', 'gas_source_unknown_rate']\n",
      "- omr: ['bmi_closest_pre_ed', 'height_closest_pre_ed', 'weight_closest_pre_ed']\n",
      "- dx_flags: ['flag_copd', 'flag_osa_ohs', 'flag_chf', 'flag_neuromuscular', 'flag_opioid_substance', 'flag_pneumonia']\n",
      "- timing: ['dt_first_qualifying_gas_hours', 'presenting_hypercapnia', 'late_hypercapnia', 'ph_band', 'hco3_band', 'lactate_band']\n",
      "- derived: ['hospital_los_hours', 'in_hospital_death']\n"
     ]
    }
   ],
   "source": [
    "# Target field registry\n",
    "TARGET_RAW_FIELDS = {\n",
    "    \"ed_edstays\": [\n",
    "        \"ed_stay_id\",\"subject_id\",\"hadm_id\",\"ed_intime\",\"ed_outtime\",\n",
    "        \"arrival_transport\",\"disposition\",\"ed_gender\",\"ed_race\",\n",
    "    ],\n",
    "    \"ed_triage\": [\n",
    "        \"ed_triage_temp\",\"ed_triage_hr\",\"ed_triage_rr\",\"ed_triage_o2sat\",\n",
    "        \"ed_triage_sbp\",\"ed_triage_dbp\",\"ed_triage_pain\",\"ed_triage_acuity\",\"ed_triage_cc\",\n",
    "    ],\n",
    "    \"ed_vitals_first\": [\n",
    "        \"ed_first_vitals_time\",\"ed_first_temp\",\"ed_first_hr\",\"ed_first_rr\",\n",
    "        \"ed_first_o2sat\",\"ed_first_sbp\",\"ed_first_dbp\",\"ed_first_rhythm\",\"ed_first_pain\",\n",
    "    ],\n",
    "    \"admissions\": [\n",
    "        \"admittime\",\"dischtime\",\"deathtime\",\"hospital_expire_flag\",\n",
    "        \"admission_type\",\"admission_location\",\"discharge_location\",\n",
    "        \"insurance\",\"language\",\"marital_status\",\"hosp_race\",\n",
    "    ],\n",
    "    \"icu\": [\n",
    "        \"icu_stay_id\",\"icu_intime_first\",\"icu_outtime_last\",\"icu_los_total\",\"n_icu_stays\",\n",
    "        \"first_careunit\",\"last_careunit\",\n",
    "    ],\n",
    "    \"labs_gas\": [\n",
    "        \"first_gas_time\",\"first_pco2\",\"first_ph\",\"first_hco3\",\"first_lactate\",\n",
    "        \"max_pco2_0_6h\",\"min_ph_0_6h\",\"max_pco2_0_24h\",\"min_ph_0_24h\",\n",
    "        \"flag_abg_hypercapnia\",\"flag_vbg_hypercapnia\",\"flag_any_gas_hypercapnia\",\n",
    "        \"gas_source_unknown_rate\",\n",
    "    ],\n",
    "    \"omr\": [\n",
    "        \"bmi_closest_pre_ed\",\"height_closest_pre_ed\",\"weight_closest_pre_ed\",\n",
    "    ],\n",
    "    \"dx_flags\": [\n",
    "        \"flag_copd\",\"flag_osa_ohs\",\"flag_chf\",\"flag_neuromuscular\",\n",
    "        \"flag_opioid_substance\",\"flag_pneumonia\",\n",
    "    ],\n",
    "    \"timing\": [\n",
    "        \"dt_first_qualifying_gas_hours\",\"presenting_hypercapnia\",\"late_hypercapnia\",\n",
    "        \"ph_band\",\"hco3_band\",\"lactate_band\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "TARGET_DERIVED_FIELDS = [\n",
    "    \"hospital_los_hours\",\"in_hospital_death\",\n",
    "]\n",
    "\n",
    "TARGET_FIELDS = sorted({c for v in TARGET_RAW_FIELDS.values() for c in v} | set(TARGET_DERIVED_FIELDS))\n",
    "\n",
    "# Grouped missing report\n",
    "missing_by_group = {}\n",
    "for group, cols in TARGET_RAW_FIELDS.items():\n",
    "    missing_by_group[group] = [c for c in cols if c not in df.columns]\n",
    "\n",
    "missing_derived = [c for c in TARGET_DERIVED_FIELDS if c not in df.columns]\n",
    "missing_by_group[\"derived\"] = missing_derived\n",
    "\n",
    "missing_flat = [c for cols in missing_by_group.values() for c in cols]\n",
    "print(\"Missing fields total:\", len(missing_flat))\n",
    "for group, cols in missing_by_group.items():\n",
    "    if cols:\n",
    "        print(f\"- {group}: {cols}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d4c97",
   "metadata": {},
   "source": [
    "## Phase 1 — ED encounter spine and ED enrichment (one row per ED stay)\n",
    "\n",
    "**Rationale:** Create a dedicated ED-stay-level cohort with ED-specific attributes to avoid mixing admission- and ED-level grains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b2122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718115.427194 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED spine rows: 27507 unique ed_stay_id: 27507\n"
     ]
    }
   ],
   "source": [
    "# ED stay spine (rename stay_id to ed_stay_id)\n",
    "\n",
    "ed_spine_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  s.stay_id AS ed_stay_id,\n",
    "  s.subject_id,\n",
    "  s.hadm_id,\n",
    "  s.intime AS ed_intime,\n",
    "  s.outtime AS ed_outtime,\n",
    "  s.arrival_transport,\n",
    "  s.disposition,\n",
    "  s.gender AS ed_gender,\n",
    "  s.race   AS ed_race\n",
    "FROM `{PHYS}.{ED}.edstays` s\n",
    "JOIN hadms h ON h.hadm_id = s.hadm_id\n",
    "\"\"\"\n",
    "\n",
    "ed_spine = run_sql_bq(ed_spine_sql, {\"hadms\": hadm_list})\n",
    "print(\"ED spine rows:\", len(ed_spine), \"unique ed_stay_id:\", ed_spine[\"ed_stay_id\"].nunique())\n",
    "\n",
    "# ensure uniqueness\n",
    "if ed_spine[\"ed_stay_id\"].nunique() != len(ed_spine):\n",
    "    raise ValueError(\"ed_stay_id not unique in ED spine\")\n",
    "\n",
    "# Start ED-level df\n",
    "ed_df = ed_spine.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f8c7170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718123.496275 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED triage rows: 27507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718131.270023 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED first vitals rows: 25607\n",
      "ed_triage cols: ['ed_stay_id', 'hadm_id', 'intime', 'ed_triage_temp', 'ed_triage_hr', 'ed_triage_rr', 'ed_triage_o2sat', 'ed_triage_sbp', 'ed_triage_dbp', 'ed_triage_pain', 'ed_triage_acuity', 'ed_triage_cc']\n",
      "ed_first cols: ['ed_stay_id', 'ed_first_vitals_time', 'ed_first_temp', 'ed_first_hr', 'ed_first_rr', 'ed_first_o2sat', 'ed_first_sbp', 'ed_first_dbp', 'ed_first_rhythm', 'ed_first_pain']\n",
      "ed_df cols: ['ed_stay_id', 'subject_id', 'hadm_id', 'ed_intime', 'ed_outtime', 'arrival_transport', 'disposition', 'ed_gender', 'ed_race']\n"
     ]
    }
   ],
   "source": [
    "# ED triage and first ED vitals (reuse existing logic if present; otherwise join)\n",
    "\n",
    "def _needs_cols(df, cols):\n",
    "    return (df is None) or any(c not in df.columns for c in cols)\n",
    "\n",
    "# Use existing ed_triage / ed_first if already in memory from earlier cells\n",
    "try:\n",
    "    _ = ed_triage\n",
    "except NameError:\n",
    "    ed_triage = None\n",
    "\n",
    "try:\n",
    "    _ = ed_first\n",
    "except NameError:\n",
    "    ed_first = None\n",
    "\n",
    "# Force re-query if required keys are missing\n",
    "if _needs_cols(locals().get('ed_triage', None), ['ed_stay_id', 'hadm_id']):\n",
    "    ed_triage = None\n",
    "if _needs_cols(locals().get('ed_first', None), ['ed_stay_id']):\n",
    "    ed_first = None\n",
    "\n",
    "# If missing, re-run ED triage / first vitals queries with ed_stay_id output\n",
    "if ed_triage is None:\n",
    "    ed_triage_sql = f\"\"\"\n",
    "    WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "    SELECT\n",
    "      s.stay_id AS ed_stay_id,\n",
    "      s.hadm_id,\n",
    "      s.intime,\n",
    "      t.temperature    AS ed_triage_temp,\n",
    "      t.heartrate      AS ed_triage_hr,\n",
    "      t.resprate       AS ed_triage_rr,\n",
    "      t.o2sat          AS ed_triage_o2sat,\n",
    "      t.sbp            AS ed_triage_sbp,\n",
    "      t.dbp            AS ed_triage_dbp,\n",
    "      t.pain           AS ed_triage_pain,\n",
    "      t.acuity         AS ed_triage_acuity,\n",
    "      t.chiefcomplaint AS ed_triage_cc\n",
    "    FROM `{PHYS}.{ED}.edstays` s\n",
    "    JOIN hadms h ON h.hadm_id = s.hadm_id\n",
    "    LEFT JOIN `{PHYS}.{ED}.triage` t\n",
    "      ON t.stay_id = s.stay_id\n",
    "    \"\"\"\n",
    "    ed_triage = run_sql_bq(ed_triage_sql, {'hadms': hadm_list})\n",
    "    print('ED triage rows:', len(ed_triage))\n",
    "\n",
    "if ed_first is None:\n",
    "    ed_first_vitals_sql = f\"\"\"\n",
    "    WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "    edmap AS (\n",
    "      SELECT stay_id, hadm_id\n",
    "      FROM `{PHYS}.{ED}.edstays`\n",
    "      WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "    ),\n",
    "    vs AS (\n",
    "      SELECT stay_id, charttime, temperature, heartrate, resprate, o2sat, sbp, dbp, rhythm, pain\n",
    "      FROM `{PHYS}.{ED}.vitalsign`\n",
    "    ),\n",
    "    first_vs AS (\n",
    "      SELECT\n",
    "        v.stay_id,\n",
    "        (ARRAY_AGG(STRUCT(v.charttime, v.temperature, v.heartrate, v.resprate, v.o2sat, v.sbp, v.dbp, v.rhythm, v.pain)\n",
    "                   ORDER BY v.charttime LIMIT 1))[OFFSET(0)] AS pick\n",
    "      FROM vs v\n",
    "      JOIN edmap m USING (stay_id)\n",
    "      GROUP BY v.stay_id\n",
    "    )\n",
    "    SELECT\n",
    "      f.stay_id AS ed_stay_id,\n",
    "      pick.charttime AS ed_first_vitals_time,\n",
    "      pick.temperature AS ed_first_temp,\n",
    "      pick.heartrate AS ed_first_hr,\n",
    "      pick.resprate AS ed_first_rr,\n",
    "      pick.o2sat AS ed_first_o2sat,\n",
    "      pick.sbp AS ed_first_sbp,\n",
    "      pick.dbp AS ed_first_dbp,\n",
    "      pick.rhythm AS ed_first_rhythm,\n",
    "      pick.pain AS ed_first_pain\n",
    "    FROM first_vs f\n",
    "    \"\"\"\n",
    "    ed_first = run_sql_bq(ed_first_vitals_sql, {'hadms': hadm_list})\n",
    "    print('ED first vitals rows:', len(ed_first))\n",
    "\n",
    "# Debug columns before merge\n",
    "print('ed_triage cols:', list(ed_triage.columns))\n",
    "print('ed_first cols:', list(ed_first.columns))\n",
    "print('ed_df cols:', list(ed_df.columns))\n",
    "\n",
    "if 'ed_stay_id' not in ed_df.columns:\n",
    "    raise KeyError('ed_df missing ed_stay_id; ensure ED spine cell ran.')\n",
    "\n",
    "ed_df = ed_df.merge(ed_triage, on=['ed_stay_id', 'hadm_id'], how='left')\n",
    "ed_df = ed_df.merge(ed_first, on=['ed_stay_id'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112697d",
   "metadata": {},
   "source": [
    "## Phase 2 — Hospital admission context and outcomes\n",
    "\n",
    "**Rationale:** Add admission-level outcomes and demographics for downstream stratification and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76aad284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718138.645349 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions rows: 84152\n",
      "Admissions discordance (expire_flag vs deathtime): 4\n"
     ]
    }
   ],
   "source": [
    "# Admissions fields\n",
    "admit_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  a.hadm_id,\n",
    "  a.admittime,\n",
    "  a.dischtime,\n",
    "  a.deathtime,\n",
    "  a.hospital_expire_flag,\n",
    "  a.admission_type,\n",
    "  a.admission_location,\n",
    "  a.discharge_location,\n",
    "  a.insurance,\n",
    "  a.language,\n",
    "  a.marital_status,\n",
    "  a.race AS hosp_race\n",
    "FROM `{PHYS}.{HOSP}.admissions` a\n",
    "JOIN hadms h USING (hadm_id)\n",
    "\"\"\"\n",
    "\n",
    "admit = run_sql_bq(admit_sql, {\"hadms\": hadm_list})\n",
    "print(\"Admissions rows:\", len(admit))\n",
    "\n",
    "ed_df = ed_df.merge(admit, on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "# Derived outcomes\n",
    "ed_df[\"hospital_los_hours\"] = (ed_df[\"dischtime\"] - ed_df[\"admittime\"]).dt.total_seconds() / 3600.0\n",
    "ed_df[\"in_hospital_death\"] = ((ed_df[\"hospital_expire_flag\"] == 1) | ed_df[\"deathtime\"].notna()).astype(\"int64\")\n",
    "\n",
    "# Concordance check\n",
    "discord = (\n",
    "    ((ed_df[\"hospital_expire_flag\"] == 1) & ed_df[\"deathtime\"].isna()) |\n",
    "    ((ed_df[\"hospital_expire_flag\"] == 0) & ed_df[\"deathtime\"].notna())\n",
    ")\n",
    "print(\"Admissions discordance (expire_flag vs deathtime):\", int(discord.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904f650",
   "metadata": {},
   "source": [
    "## Phase 3 — ICU timing and LOS\n",
    "\n",
    "**Rationale:** Capture ICU exposure, timing, and total LOS for severity stratification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5174a456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718146.453966 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU stay rows: 67073\n"
     ]
    }
   ],
   "source": [
    "# ICU stays (aggregate per hadm)\n",
    "icu_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT\n",
    "  i.hadm_id,\n",
    "  i.stay_id AS icu_stay_id,\n",
    "  i.intime,\n",
    "  i.outtime,\n",
    "  i.los,\n",
    "  i.first_careunit,\n",
    "  i.last_careunit\n",
    "FROM `{PHYS}.{ICU}.icustays` i\n",
    "JOIN hadms h USING (hadm_id)\n",
    "\"\"\"\n",
    "\n",
    "icu = run_sql_bq(icu_sql, {\"hadms\": hadm_list})\n",
    "print(\"ICU stay rows:\", len(icu))\n",
    "\n",
    "if len(icu) > 0:\n",
    "    icu_agg = (\n",
    "        icu.sort_values([\"hadm_id\", \"intime\"]).groupby(\"hadm_id\", as_index=False)\n",
    "        .agg(\n",
    "            icu_intime_first=(\"intime\", \"min\"),\n",
    "            icu_outtime_last=(\"outtime\", \"max\"),\n",
    "            icu_los_total=(\"los\", \"sum\"),\n",
    "            n_icu_stays=(\"icu_stay_id\", \"nunique\"),\n",
    "            first_careunit=(\"first_careunit\", \"first\"),\n",
    "            last_careunit=(\"last_careunit\", \"last\"),\n",
    "        )\n",
    "    )\n",
    "    ed_df = ed_df.merge(icu_agg, on=\"hadm_id\", how=\"left\")\n",
    "else:\n",
    "    print(\"No ICU stays found for cohort.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7764f3",
   "metadata": {},
   "source": [
    "## Phase 4 — ED longitudinal vitals (0–6h)\n",
    "\n",
    "**Rationale:** Summarize early ED vitals for severity phenotyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d01b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718154.094782 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED vitals long rows: 171042\n",
      "Warning: heartrate out of range count: 1\n",
      "Warning: resprate out of range count: 4\n",
      "Warning: o2sat out of range count: 2\n"
     ]
    }
   ],
   "source": [
    "# ED vitals long + aggregates (0-6h)\n",
    "\n",
    "ed_vitals_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "edmap AS (\n",
    "  SELECT stay_id AS ed_stay_id, hadm_id, intime AS ed_intime\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    ")\n",
    "SELECT\n",
    "  v.stay_id AS ed_stay_id,\n",
    "  m.hadm_id,\n",
    "  m.ed_intime,\n",
    "  v.charttime,\n",
    "  v.temperature,\n",
    "  v.heartrate,\n",
    "  v.resprate,\n",
    "  v.o2sat,\n",
    "  v.sbp,\n",
    "  v.dbp,\n",
    "  v.rhythm,\n",
    "  v.pain\n",
    "FROM `{PHYS}.{ED}.vitalsign` v\n",
    "JOIN edmap m ON m.ed_stay_id = v.stay_id\n",
    "\"\"\"\n",
    "\n",
    "ed_vitals_long = run_sql_bq(ed_vitals_sql, {\"hadms\": hadm_list})\n",
    "print(\"ED vitals long rows:\", len(ed_vitals_long))\n",
    "\n",
    "# Window filter: 0–6h from ED intime\n",
    "ed_vitals_long[\"dt_hours\"] = (ed_vitals_long[\"charttime\"] - ed_vitals_long[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "in_6h = ed_vitals_long[\"dt_hours\"].between(0, 6, inclusive=\"both\")\n",
    "\n",
    "agg = (\n",
    "    ed_vitals_long.loc[in_6h]\n",
    "    .groupby(\"ed_stay_id\", as_index=False)\n",
    "    .agg(\n",
    "        max_heartrate_0_6h=(\"heartrate\", \"max\"),\n",
    "        max_resprate_0_6h=(\"resprate\", \"max\"),\n",
    "        min_o2sat_0_6h=(\"o2sat\", \"min\"),\n",
    "        min_sbp_0_6h=(\"sbp\", \"min\"),\n",
    "        n_vitals_0_6h=(\"charttime\", \"count\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "ed_df = ed_df.merge(agg, on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "# Range warnings (do not drop)\n",
    "range_checks = {\n",
    "    \"heartrate\": (0, 300),\n",
    "    \"resprate\": (0, 80),\n",
    "    \"o2sat\": (0, 100),\n",
    "    \"sbp\": (0, 300),\n",
    "}\n",
    "for col, (lo, hi) in range_checks.items():\n",
    "    bad = ed_vitals_long[col].notna() & (~ed_vitals_long[col].between(lo, hi))\n",
    "    if bad.any():\n",
    "        print(f\"Warning: {col} out of range count:\", int(bad.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91c8d5",
   "metadata": {},
   "source": [
    "## Phase 5 — Robust lab discovery + gas panels\n",
    "\n",
    "**Rationale:** Capture blood gas and key chemistry labs with label-robust item discovery and unit normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a485417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718158.274471 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1769718165.327062 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/lab_item_map.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Discover itemids from d_labitems\n",
    "labitems_sql = f\"\"\"\n",
    "SELECT itemid, label, fluid, category\n",
    "FROM `{PHYS}.{HOSP}.d_labitems`\n",
    "\"\"\"\n",
    "\n",
    "labitems = run_sql_bq(labitems_sql)\n",
    "\n",
    "patterns = {\n",
    "    \"gas_pco2\": re.compile(r\"\\bp\\s*co2\\b|pco2|pco₂\", re.I),\n",
    "    \"gas_ph\": re.compile(r\"\\bph\\b\", re.I),\n",
    "    \"gas_hco3\": re.compile(r\"hco3|bicarbonate\", re.I),\n",
    "    \"gas_lactate\": re.compile(r\"lactate\", re.I),\n",
    "    \"gas_specimen\": re.compile(r\"specimen|source|type\", re.I),\n",
    "    \"chem_creatinine\": re.compile(r\"creatinine\", re.I),\n",
    "    \"chem_sodium\": re.compile(r\"\\bsodium\\b\", re.I),\n",
    "    \"chem_chloride\": re.compile(r\"\\bchloride\\b\", re.I),\n",
    "    \"chem_total_co2\": re.compile(r\"carbon dioxide|total co2|\\bco2\\b\", re.I),\n",
    "    \"cbc_hemoglobin\": re.compile(r\"hemoglobin\", re.I),\n",
    "}\n",
    "\n",
    "# category filters\n",
    "cat_gas = re.compile(r\"blood\\s*gas|blood gas|arterial|venous\", re.I)\n",
    "cat_chem = re.compile(r\"chemistry|chem|blood\", re.I)\n",
    "cat_cbc = re.compile(r\"hematology|cbc\", re.I)\n",
    "\n",
    "matches = {}\n",
    "for name, pat in patterns.items():\n",
    "    dfm = labitems.copy()\n",
    "    dfm = dfm[dfm[\"label\"].str.contains(pat, na=False)]\n",
    "    if name.startswith(\"gas_\"):\n",
    "        dfm = dfm[dfm[\"category\"].str.contains(cat_gas, na=False)]\n",
    "    elif name.startswith(\"chem_\"):\n",
    "        dfm = dfm[dfm[\"category\"].str.contains(cat_chem, na=False)]\n",
    "    elif name.startswith(\"cbc_\"):\n",
    "        dfm = dfm[dfm[\"category\"].str.contains(cat_cbc, na=False)]\n",
    "    matches[name] = dfm[[\"itemid\",\"label\",\"category\"]]\n",
    "\n",
    "# Build lab_item_map with counts in cohort\n",
    "itemids_all = sorted({int(i) for dfm in matches.values() for i in dfm[\"itemid\"].tolist()})\n",
    "\n",
    "counts_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT itemid, COUNT(*) AS n\n",
    "FROM `{PHYS}.{HOSP}.labevents`\n",
    "WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "  AND itemid IN UNNEST(@itemids)\n",
    "GROUP BY itemid\n",
    "\"\"\"\n",
    "\n",
    "counts = run_sql_bq(counts_sql, {\"hadms\": hadm_list, \"itemids\": itemids_all}) if itemids_all else pd.DataFrame(columns=[\"itemid\",\"n\"])\n",
    "\n",
    "lab_item_map = {}\n",
    "for name, dfm in matches.items():\n",
    "    tmp = dfm.merge(counts, on=\"itemid\", how=\"left\").fillna({\"n\":0})\n",
    "    lab_item_map[name] = {\n",
    "        \"pattern\": patterns[name].pattern,\n",
    "        \"items\": tmp.sort_values(\"n\", ascending=False).to_dict(orient=\"records\"),\n",
    "    }\n",
    "\n",
    "lab_item_map_path = WORK_DIR / \"lab_item_map.json\"\n",
    "lab_item_map_path.write_text(json.dumps(lab_item_map, indent=2))\n",
    "print(\"Wrote:\", lab_item_map_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3fa3fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718172.658707 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labs long rows: 410765\n",
      "Wrote: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/lab_unit_audit.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract labevents within ED windows\n",
    "\n",
    "# assemble itemid lists\n",
    "itemid_sets = {k: [int(x[\"itemid\"]) for x in v[\"items\"]] for k, v in lab_item_map.items()}\n",
    "# flatten\n",
    "all_itemids = sorted({i for v in itemid_sets.values() for i in v})\n",
    "\n",
    "labs_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\n",
    "eds AS (\n",
    "  SELECT stay_id AS ed_stay_id, hadm_id, intime AS ed_intime\n",
    "  FROM `{PHYS}.{ED}.edstays`\n",
    "  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    ")\n",
    "SELECT\n",
    "  e.ed_stay_id,\n",
    "  l.subject_id,\n",
    "  l.hadm_id,\n",
    "  l.itemid,\n",
    "  l.charttime,\n",
    "  l.specimen_id,\n",
    "  l.valuenum,\n",
    "  l.valueuom\n",
    "FROM `{PHYS}.{HOSP}.labevents` l\n",
    "JOIN eds e ON e.hadm_id = l.hadm_id\n",
    "WHERE l.itemid IN UNNEST(@itemids)\n",
    "  AND l.charttime BETWEEN e.ed_intime AND TIMESTAMP_ADD(e.ed_intime, INTERVAL 24 HOUR)\n",
    "\"\"\"\n",
    "\n",
    "labs_long = run_sql_bq(labs_sql, {\"hadms\": hadm_list, \"itemids\": all_itemids})\n",
    "print(\"Labs long rows:\", len(labs_long))\n",
    "\n",
    "# Unit audit for pCO2\n",
    "pco2_ids = itemid_sets.get(\"gas_pco2\", [])\n",
    "unit_audit = (\n",
    "    labs_long.loc[labs_long[\"itemid\"].isin(pco2_ids)]\n",
    "    .groupby(\"valueuom\", dropna=False)\n",
    "    .size().reset_index(name=\"n\")\n",
    ")\n",
    "unit_audit_path = WORK_DIR / \"lab_unit_audit.csv\"\n",
    "unit_audit.to_csv(unit_audit_path, index=False)\n",
    "print(\"Wrote:\", unit_audit_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90790b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct gas panels by specimen_id within ED stay\n",
    "\n",
    "pco2_ids = set(itemid_sets.get(\"gas_pco2\", []))\n",
    "ph_ids = set(itemid_sets.get(\"gas_ph\", []))\n",
    "hco3_ids = set(itemid_sets.get(\"gas_hco3\", []))\n",
    "lact_ids = set(itemid_sets.get(\"gas_lactate\", []))\n",
    "\n",
    "labs = labs_long.copy()\n",
    "\n",
    "# Convert pCO2 kPa to mmHg when needed\n",
    "is_kpa = labs[\"valueuom\"].astype(str).str.lower().str.contains(\"kpa\", na=False)\n",
    "mask_pco2 = labs[\"itemid\"].isin(pco2_ids)\n",
    "if mask_pco2.any() and is_kpa.any():\n",
    "    labs.loc[mask_pco2 & is_kpa, \"valuenum\"] = labs.loc[mask_pco2 & is_kpa, \"valuenum\"] * 7.50062\n",
    "    labs.loc[mask_pco2 & is_kpa, \"valueuom\"] = \"mmHg\"\n",
    "\n",
    "# panel by specimen_id\n",
    "panel = (\n",
    "    labs.groupby([\"ed_stay_id\",\"specimen_id\"], as_index=False)\n",
    "    .agg(panel_time=(\"charttime\",\"min\"))\n",
    ")\n",
    "\n",
    "# attach analytes\n",
    "\n",
    "def pick_analyte(df, ids, name):\n",
    "    tmp = df.loc[df[\"itemid\"].isin(ids), [\"ed_stay_id\",\"specimen_id\",\"valuenum\"]]\n",
    "    tmp = tmp.rename(columns={\"valuenum\": name})\n",
    "    return tmp.groupby([\"ed_stay_id\",\"specimen_id\"], as_index=False).first()\n",
    "\n",
    "if pco2_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, pco2_ids, \"pco2\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "if ph_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, ph_ids, \"ph\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "if hco3_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, hco3_ids, \"hco3\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "if lact_ids:\n",
    "    panel = panel.merge(pick_analyte(labs, lact_ids, \"lactate\"), on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "\n",
    "# First panel per ED stay\n",
    "first_panel = (\n",
    "    panel.sort_values([\"ed_stay_id\",\"panel_time\"]).groupby(\"ed_stay_id\", as_index=False).first()\n",
    ")\n",
    "\n",
    "# 0–6h and 0–24h extrema\n",
    "panel = panel.merge(ed_df[[\"ed_stay_id\",\"ed_intime\"]], on=\"ed_stay_id\", how=\"left\")\n",
    "panel[\"dt_hours\"] = (panel[\"panel_time\"] - panel[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Ensure expected panel columns exist even if analyte is absent\n",
    "for col in [\"pco2\", \"ph\", \"hco3\", \"lactate\"]:\n",
    "    if col not in panel.columns:\n",
    "        panel[col] = pd.NA\n",
    "\n",
    "p06 = panel.loc[panel[\"dt_hours\"].between(0,6, inclusive=\"both\")]\n",
    "p24 = panel.loc[panel[\"dt_hours\"].between(0,24, inclusive=\"both\")]\n",
    "\n",
    "agg06 = p06.groupby(\"ed_stay_id\", as_index=False).agg(max_pco2_0_6h=(\"pco2\",\"max\"), min_ph_0_6h=(\"ph\",\"min\"))\n",
    "agg24 = p24.groupby(\"ed_stay_id\", as_index=False).agg(max_pco2_0_24h=(\"pco2\",\"max\"), min_ph_0_24h=(\"ph\",\"min\"))\n",
    "\n",
    "ed_df = ed_df.merge(first_panel[[\"ed_stay_id\",\"panel_time\",\"pco2\",\"ph\",\"hco3\",\"lactate\"]].rename(\n",
    "    columns={\"panel_time\":\"first_gas_time\",\"pco2\":\"first_pco2\",\"ph\":\"first_ph\",\"hco3\":\"first_hco3\",\"lactate\":\"first_lactate\"}\n",
    "), on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "ed_df = ed_df.merge(agg06, on=\"ed_stay_id\", how=\"left\")\n",
    "ed_df = ed_df.merge(agg24, on=\"ed_stay_id\", how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8759509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABG vs VBG classification (label-based fallback only; specimen source may be unavailable)\n",
    "\n",
    "# Use label heuristics from d_labitems if available (arterial/venous hints)\n",
    "labitems_map = labitems.set_index(\"itemid\")[\"label\"].to_dict()\n",
    "\n",
    "def infer_source(itemid):\n",
    "    label = str(labitems_map.get(itemid, \"\")).lower()\n",
    "    if re.search(r\"arterial|abg|a[- ]?line\", label):\n",
    "        return \"arterial\"\n",
    "    if re.search(r\"venous|vbg|central|mixed\", label):\n",
    "        return \"venous\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# assign source for panels based on pco2 item label (fallback)\n",
    "if pco2_ids:\n",
    "    pco2_itemid = labs.loc[labs[\"itemid\"].isin(pco2_ids)].groupby([\"ed_stay_id\",\"specimen_id\"], as_index=False)[\"itemid\"].first()\n",
    "    pco2_itemid[\"source\"] = pco2_itemid[\"itemid\"].map(infer_source)\n",
    "    panel = panel.merge(pco2_itemid[[\"ed_stay_id\",\"specimen_id\",\"source\"]], on=[\"ed_stay_id\",\"specimen_id\"], how=\"left\")\n",
    "else:\n",
    "    panel[\"source\"] = \"unknown\"\n",
    "\n",
    "# flags\n",
    "panel[\"flag_abg_hypercapnia\"] = ((panel[\"source\"]==\"arterial\") & (panel[\"pco2\"]>=45)).astype(int)\n",
    "panel[\"flag_vbg_hypercapnia\"] = ((panel[\"source\"]==\"venous\") & (panel[\"pco2\"]>=50)).astype(int)\n",
    "panel[\"flag_any_gas_hypercapnia\"] = ((panel[\"pco2\"]>=45)).astype(int)\n",
    "\n",
    "panel_source_unknown_rate = (panel[\"source\"].fillna(\"unknown\") == \"unknown\").mean() if len(panel)>0 else 1.0\n",
    "\n",
    "# collapse to ED stay flags\n",
    "flags = panel.groupby(\"ed_stay_id\", as_index=False).agg(\n",
    "    flag_abg_hypercapnia=(\"flag_abg_hypercapnia\",\"max\"),\n",
    "    flag_vbg_hypercapnia=(\"flag_vbg_hypercapnia\",\"max\"),\n",
    "    flag_any_gas_hypercapnia=(\"flag_any_gas_hypercapnia\",\"max\"),\n",
    ")\n",
    "\n",
    "ed_df = ed_df.merge(flags, on=\"ed_stay_id\", how=\"left\")\n",
    "ed_df[\"gas_source_unknown_rate\"] = panel_source_unknown_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b49df4",
   "metadata": {},
   "source": [
    "## Phase 5C — ICU POC blood gases (chartevents, optional)\n",
    "\n",
    "**Rationale:** Capture ICU point-of-care gases if central lab labevents miss early measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1799ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718175.971731 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU POC candidate itemids: 6\n"
     ]
    }
   ],
   "source": [
    "# Discover ICU POC itemids from d_items\n",
    "\n",
    "ditems_sql = f\"\"\"\n",
    "SELECT itemid, label, category\n",
    "FROM `{PHYS}.{ICU}.d_items`\n",
    "\"\"\"\n",
    "\n",
    "ditems = run_sql_bq(ditems_sql)\n",
    "\n",
    "icu_patterns = {\n",
    "    \"pco2\": re.compile(r\"\bp\\s*co2\b|pco2|pco₂\", re.I),\n",
    "    \"ph\": re.compile(r\"\bph\b\", re.I),\n",
    "    \"hco3\": re.compile(r\"hco3|bicarbonate\", re.I),\n",
    "    \"lactate\": re.compile(r\"lactate\", re.I),\n",
    "    \"specimen\": re.compile(r\"specimen|source|type\", re.I),\n",
    "}\n",
    "\n",
    "icu_cat = re.compile(r\"blood\\s*gas|blood gas|resp|arterial|venous\", re.I)\n",
    "\n",
    "icu_matches = {}\n",
    "for name, pat in icu_patterns.items():\n",
    "    dfm = ditems[ditems[\"label\"].str.contains(pat, na=False)]\n",
    "    dfm = dfm[dfm[\"category\"].str.contains(icu_cat, na=False)]\n",
    "    icu_matches[name] = dfm[[\"itemid\",\"label\",\"category\"]]\n",
    "\n",
    "icu_itemids = sorted({int(i) for dfm in icu_matches.values() for i in dfm[\"itemid\"].tolist()})\n",
    "print(\"ICU POC candidate itemids:\", len(icu_itemids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa3c01a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718183.199904 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICU POC long rows: 80096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/n84t7b8171lf64smq4ddvw1m0000gn/T/ipykernel_67343/2164793392.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p24_poc[\"flag_any_gas_hypercapnia_poc\"] = (p24_poc[\"pco2\"] >= 45).astype(int)\n",
      "/var/folders/vf/n84t7b8171lf64smq4ddvw1m0000gn/T/ipykernel_67343/2164793392.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p24_poc[\"flag_any_gas_hypercapnia_poc\"] = (p24_poc[\"pco2\"] >= 45).astype(int)\n",
      "/var/folders/vf/n84t7b8171lf64smq4ddvw1m0000gn/T/ipykernel_67343/2164793392.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p24_poc[\"flag_any_gas_hypercapnia_poc\"] = (p24_poc[\"pco2\"] >= 45).astype(int)\n",
      "/var/folders/vf/n84t7b8171lf64smq4ddvw1m0000gn/T/ipykernel_67343/2164793392.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p24_poc[\"flag_any_gas_hypercapnia_poc\"] = (p24_poc[\"pco2\"] >= 45).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Extract ICU chartevents within ED 0–24h window for cohort ICU stays\n",
    "\n",
    "if len(icu_itemids) == 0:\n",
    "    icu_poc_long = pd.DataFrame()\n",
    "    print(\"No ICU POC itemids found.\")\n",
    "else:\n",
    "    # ensure icu stay ids available\n",
    "    if 'icu' not in globals():\n",
    "        raise NameError(\"ICU stays table 'icu' not found; run ICU phase first.\")\n",
    "\n",
    "    icu_stays = icu[[\"icu_stay_id\",\"hadm_id\",\"intime\"]].copy()\n",
    "    icu_stays = icu_stays.dropna(subset=[\"icu_stay_id\"])\n",
    "\n",
    "    icu_poc_sql = f\"\"\"\n",
    "    WITH icu_stays AS (\n",
    "      SELECT stay_id AS icu_stay_id, hadm_id\n",
    "      FROM `{PHYS}.{ICU}.icustays`\n",
    "      WHERE stay_id IN UNNEST(@icu_stay_ids)\n",
    "    ),\n",
    "    eds AS (\n",
    "      SELECT stay_id AS ed_stay_id, hadm_id, intime AS ed_intime\n",
    "      FROM `{PHYS}.{ED}.edstays`\n",
    "      WHERE hadm_id IN (SELECT hadm_id FROM icu_stays)\n",
    "    )\n",
    "    SELECT\n",
    "      s.icu_stay_id,\n",
    "      e.ed_stay_id,\n",
    "      e.hadm_id,\n",
    "      ce.charttime,\n",
    "      ce.itemid,\n",
    "      ce.valuenum,\n",
    "      ce.valueuom\n",
    "    FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "    JOIN icu_stays s ON s.icu_stay_id = ce.stay_id\n",
    "    JOIN eds e ON e.hadm_id = s.hadm_id\n",
    "    WHERE ce.itemid IN UNNEST(@itemids)\n",
    "      AND ce.charttime BETWEEN e.ed_intime AND TIMESTAMP_ADD(e.ed_intime, INTERVAL 24 HOUR)\n",
    "    \"\"\"\n",
    "\n",
    "    icu_poc_long = run_sql_bq(icu_poc_sql, {\"icu_stay_ids\": icu_stays[\"icu_stay_id\"].astype(int).tolist(), \"itemids\": icu_itemids})\n",
    "    print(\"ICU POC long rows:\", len(icu_poc_long))\n",
    "\n",
    "# Build panels by 5-minute bins per ICU stay\n",
    "if len(icu_poc_long) > 0:\n",
    "    icu_poc_long[\"time_bin\"] = icu_poc_long[\"charttime\"].dt.floor(\"5min\")\n",
    "\n",
    "    def pick_from_ids(df, ids, name):\n",
    "        tmp = df.loc[df[\"itemid\"].isin(ids), [\"icu_stay_id\",\"time_bin\",\"valuenum\"]]\n",
    "        tmp = tmp.rename(columns={\"valuenum\": name})\n",
    "        return tmp.groupby([\"icu_stay_id\",\"time_bin\"], as_index=False).first()\n",
    "\n",
    "    pco2_ids = set(icu_matches.get(\"pco2\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "    ph_ids = set(icu_matches.get(\"ph\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "    hco3_ids = set(icu_matches.get(\"hco3\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "    lact_ids = set(icu_matches.get(\"lactate\", pd.DataFrame()).get(\"itemid\", []).tolist())\n",
    "\n",
    "    panel_poc = (\n",
    "        icu_poc_long.groupby([\"icu_stay_id\",\"time_bin\"], as_index=False)\n",
    "        .agg(panel_time=(\"charttime\",\"min\"))\n",
    "    )\n",
    "    if pco2_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, pco2_ids, \"pco2\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "    if ph_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, ph_ids, \"ph\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "    if hco3_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, hco3_ids, \"hco3\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "    if lact_ids:\n",
    "        panel_poc = panel_poc.merge(pick_from_ids(icu_poc_long, lact_ids, \"lactate\"), on=[\"icu_stay_id\",\"time_bin\"], how=\"left\")\n",
    "\n",
    "    # map to ED stay via hadm_id\n",
    "    panel_poc = panel_poc.merge(icu[[\"icu_stay_id\",\"hadm_id\"]], on=\"icu_stay_id\", how=\"left\")\n",
    "    panel_poc = panel_poc.merge(ed_df[[\"ed_stay_id\",\"hadm_id\",\"ed_intime\"]], on=\"hadm_id\", how=\"left\")\n",
    "    panel_poc[\"dt_hours\"] = (panel_poc[\"panel_time\"] - panel_poc[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Ensure expected panel_poc columns exist even if analyte is absent\n",
    "for col in [\"pco2\", \"ph\", \"hco3\", \"lactate\"]:\n",
    "    if col not in panel_poc.columns:\n",
    "        panel_poc[col] = pd.NA\n",
    "\n",
    "    p24_poc = panel_poc.loc[panel_poc[\"dt_hours\"].between(0,24, inclusive=\"both\")]\n",
    "\n",
    "    # derive flags (source unknown in POC)\n",
    "    p24_poc[\"flag_any_gas_hypercapnia_poc\"] = (p24_poc[\"pco2\"] >= 45).astype(int)\n",
    "\n",
    "    poc_flags = p24_poc.groupby(\"ed_stay_id\", as_index=False).agg(\n",
    "        flag_any_gas_hypercapnia_poc=(\"flag_any_gas_hypercapnia_poc\",\"max\")\n",
    "    )\n",
    "\n",
    "# Avoid duplicate column on re-run\n",
    "if \"flag_any_gas_hypercapnia_poc\" in ed_df.columns:\n",
    "    ed_df = ed_df.drop(columns=[\"flag_any_gas_hypercapnia_poc\"])\n",
    "\n",
    "    ed_df = ed_df.merge(poc_flags, on=\"ed_stay_id\", how=\"left\")\n",
    "\n",
    "    # incremental yield\n",
    "    base = ed_df.get(\"flag_any_gas_hypercapnia\", pd.Series(0, index=ed_df.index)).fillna(0).astype(int)\n",
    "    poc = ed_df.get(\"flag_any_gas_hypercapnia_poc\", pd.Series(0, index=ed_df.index)).fillna(0).astype(int)\n",
    "    inc = ((base == 0) & (poc == 1)).sum()\n",
    "    print(\"ICU POC incremental hypercapnia cases (ED stays):\", int(inc))\n",
    "\n",
    "    # optional export\n",
    "    panel_poc.to_parquet(WORK_DIR / \"gas_panels_poc.parquet\", index=False)\n",
    "else:\n",
    "    panel_poc = pd.DataFrame()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6 — BMI/anthropometrics (OMR)\n",
    "\n",
    "**Rationale:** Add BMI/height/weight closest to ED presentation when available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1769718188.693377 22204418 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMR rows: 46494\n"
     ]
    }
   ],
   "source": [
    "# OMR BMI/height/weight\n",
    "\n",
    "try:\n",
    "    omr_sql = f\"\"\"\n",
    "    SELECT subject_id, chartdate, result_name, result_value\n",
    "    FROM `{PHYS}.{HOSP}.omr`\n",
    "    WHERE LOWER(result_name) IN ('bmi','height','weight')\n",
    "    \"\"\"\n",
    "    omr = run_sql_bq(omr_sql)\n",
    "    print(\"OMR rows:\", len(omr))\n",
    "\n",
    "    omr[\"result_name\"] = omr[\"result_name\"].str.lower()\n",
    "    omr_pivot = (\n",
    "        omr.pivot_table(index=[\"subject_id\",\"chartdate\"], columns=\"result_name\", values=\"result_value\", aggfunc=\"first\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # attach closest pre-ED (within 365 days)\n",
    "    ed_dates = ed_df[[\"ed_stay_id\",\"subject_id\",\"ed_intime\"]].copy()\n",
    "    ed_dates[\"ed_date\"] = ed_dates[\"ed_intime\"].dt.date\n",
    "    omr_pivot[\"chartdate\"] = pd.to_datetime(omr_pivot[\"chartdate\"]).dt.date\n",
    "\n",
    "    merged = ed_dates.merge(omr_pivot, on=\"subject_id\", how=\"left\")\n",
    "    merged[\"days_before\"] = (pd.to_datetime(merged[\"ed_date\"]) - pd.to_datetime(merged[\"chartdate\"])).dt.days\n",
    "    merged = merged.loc[(merged[\"days_before\"] >= 0) & (merged[\"days_before\"] <= 365)]\n",
    "\n",
    "    closest = (\n",
    "        merged.sort_values([\"ed_stay_id\",\"days_before\"]).groupby(\"ed_stay_id\", as_index=False).first()\n",
    "        .rename(columns={\n",
    "            \"bmi\":\"bmi_closest_pre_ed\",\n",
    "            \"height\":\"height_closest_pre_ed\",\n",
    "            \"weight\":\"weight_closest_pre_ed\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    ed_df = ed_df.merge(closest[[\"ed_stay_id\",\"bmi_closest_pre_ed\",\"height_closest_pre_ed\",\"weight_closest_pre_ed\"]],\n",
    "                        on=\"ed_stay_id\", how=\"left\")\n",
    "except Exception as e:\n",
    "    print(\"OMR not available or failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7 — ICD comorbidity flags\n",
    "\n",
    "**Rationale:** Derive comorbidity indicators from index admission ICD codes for stratified analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD code pulls for comorbidity flags\n",
    "\n",
    "icd_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\n",
    "SELECT subject_id, hadm_id, icd_code, icd_version, seq_num\n",
    "FROM `{PHYS}.{HOSP}.diagnoses_icd`\n",
    "WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n",
    "\"\"\"\n",
    "\n",
    "icd = run_sql_bq(icd_sql, {\"hadms\": hadm_list})\n",
    "\n",
    "# normalize codes\n",
    "icd[\"code_norm\"] = icd[\"icd_code\"].str.upper().str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "# pattern-based flags (ICD-10 prefixes)\n",
    "patterns = {\n",
    "    \"flag_copd\": r\"^(J43|J44)\",\n",
    "    \"flag_osa_ohs\": r\"^(G473|E662)\",\n",
    "    \"flag_chf\": r\"^(I50)\",\n",
    "    \"flag_neuromuscular\": r\"^(G12|G70|G71)\",\n",
    "    \"flag_opioid_substance\": r\"^(F11|T40|F13)\",\n",
    "    \"flag_pneumonia\": r\"^(J12|J13|J14|J15|J16|J17|J18)\",\n",
    "}\n",
    "\n",
    "flags = {k: icd[\"code_norm\"].str.contains(v, na=False) for k, v in patterns.items()}\n",
    "flag_df = icd.assign(**flags).groupby(\"hadm_id\", as_index=False)[list(patterns.keys())].max()\n",
    "\n",
    "ed_df = ed_df.merge(flag_df, on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "# prevalence\n",
    "for k in patterns:\n",
    "    if k in ed_df.columns:\n",
    "        print(k, int(ed_df[k].fillna(0).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 8 — Timing phenotypes and derived bands\n",
    "\n",
    "**Rationale:** Compute time-anchored hypercapnia/acidemia phenotypes for ED presentation vs later course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing phenotypes\n",
    "\n",
    "ed_df[\"dt_first_qualifying_gas_hours\"] = (ed_df[\"first_gas_time\"] - ed_df[\"ed_intime\"]).dt.total_seconds() / 3600.0\n",
    "ed_df[\"presenting_hypercapnia\"] = (ed_df[\"dt_first_qualifying_gas_hours\"] <= 6).astype(\"Int64\")\n",
    "ed_df[\"late_hypercapnia\"] = (ed_df[\"dt_first_qualifying_gas_hours\"] > 6).astype(\"Int64\")\n",
    "\n",
    "# Bands\n",
    "bins_ph = [-1, 7.20, 7.30, 7.35, 99]\n",
    "labels_ph = [\"<7.20\",\"7.20–7.29\",\"7.30–7.34\",\"≥7.35\"]\n",
    "ed_df[\"ph_band\"] = pd.cut(ed_df[\"first_ph\"], bins=bins_ph, labels=labels_ph)\n",
    "\n",
    "bins_hco3 = [-1, 24, 30, 999]\n",
    "labels_hco3 = [\"<24\",\"24–29\",\"≥30\"]\n",
    "ed_df[\"hco3_band\"] = pd.cut(ed_df[\"first_hco3\"], bins=bins_hco3, labels=labels_hco3)\n",
    "\n",
    "bins_lac = [-1, 2, 4, 999]\n",
    "labels_lac = [\"<2\",\"2–4\",\">4\"]\n",
    "ed_df[\"lactate_band\"] = pd.cut(ed_df[\"first_lactate\"], bins=bins_lac, labels=labels_lac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA / audits\n",
    "\n",
    "**Rationale:** Validate joins, missingness, lab completeness, and produce reproducibility artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# T1 — uniqueness and join explosion guard\n",
    "if ed_df[\"ed_stay_id\"].nunique() != len(ed_df):\n",
    "    raise ValueError(\"ed_stay_id not unique after merges\")\n",
    "\n",
    "# T2 — missingness summary for new fields\n",
    "new_fields = [c for c in TARGET_FIELDS if c in ed_df.columns]\n",
    "miss = pd.DataFrame({\n",
    "    \"field\": new_fields,\n",
    "    \"missing_n\": [int(ed_df[c].isna().sum()) for c in new_fields],\n",
    "    \"missing_pct\": [float(ed_df[c].isna().mean()) for c in new_fields],\n",
    "})\n",
    "print(miss.sort_values(\"missing_pct\", ascending=False).head(30))\n",
    "\n",
    "# T3 — lab capture completeness\n",
    "pct_any_6h = float(p06[\"ed_stay_id\"].nunique() / max(ed_df[\"ed_stay_id\"].nunique(),1))\n",
    "pct_any_24h = float(p24[\"ed_stay_id\"].nunique() / max(ed_df[\"ed_stay_id\"].nunique(),1))\n",
    "print(\"% any gas panel 0–6h:\", round(pct_any_6h*100,1))\n",
    "print(\"% any gas panel 0–24h:\", round(pct_any_24h*100,1))\n",
    "print(\"% source unknown (panel-level):\", round(panel_source_unknown_rate*100,1))\n",
    "\n",
    "# T4 — QA summary artifact\n",
    "qa_summary = {\n",
    "    \"ed_rows\": int(len(ed_df)),\n",
    "    \"ed_unique\": int(ed_df[\"ed_stay_id\"].nunique()),\n",
    "    \"icu_link_rate\": float(ed_df[\"icu_intime_first\"].notna().mean()) if \"icu_intime_first\" in ed_df.columns else None,\n",
    "    \"pct_any_gas_0_6h\": pct_any_6h,\n",
    "    \"pct_any_gas_0_24h\": pct_any_24h,\n",
    "    \"source_unknown_rate\": panel_source_unknown_rate,\n",
    "}\n",
    "qa_path = WORK_DIR / \"qa_summary.json\"\n",
    "qa_path.write_text(json.dumps(qa_summary, indent=2))\n",
    "print(\"Wrote:\", qa_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs (ED-stay cohort + long tables)\n",
    "\n",
    "**Rationale:** Persist ED-stay analytic datasets and supporting long tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "cohort_path = WORK_DIR / \"cohort_ed_stay.parquet\"\n",
    "ed_df.to_parquet(cohort_path, index=False)\n",
    "print(\"Wrote:\", cohort_path)\n",
    "\n",
    "ed_vitals_long.to_parquet(WORK_DIR / \"ed_vitals_long.parquet\", index=False)\n",
    "labs_long.to_parquet(WORK_DIR / \"labs_long.parquet\", index=False)\n",
    "panel.to_parquet(WORK_DIR / \"gas_panels.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also export to Excel (tabular dataset)\n",
    "from datetime import datetime\n",
    "\n",
    "out_dir = DATA_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "xlsx_path = out_dir / f\"mimic_hypercap_EXT_EDstay_bq_gas_{timestamp}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as xw:\n",
    "    ed_df.to_excel(xw, sheet_name=\"cohort_ed_stay\", index=False)\n",
    "    # Optional: include QA tables if present\n",
    "    try:\n",
    "        miss.to_excel(xw, sheet_name=\"missingness\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"Saved:\", xlsx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776739a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Excel outputs requested: all encounters + ED chief-complaint only\n",
    "from datetime import datetime\n",
    "\n",
    "out_dir = DATA_DIR\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 1) All encounters meeting inclusion criteria (admission-level), with ED linkage flags\n",
    "ed_link = (\n",
    "    ed_df.groupby(\"hadm_id\", as_index=False)\n",
    "         .agg(ed_stay_id_first=(\"ed_stay_id\", \"first\"), n_ed_stays=(\"ed_stay_id\", \"nunique\"))\n",
    ")\n",
    "all_encounters = df.merge(ed_link, on=\"hadm_id\", how=\"left\")\n",
    "all_encounters[\"has_ed_encounter\"] = all_encounters[\"n_ed_stays\"].fillna(0).astype(int).gt(0).astype(int)\n",
    "all_encounters[\"encounter_source\"] = all_encounters[\"has_ed_encounter\"].map({1: \"ED-linked\", 0: \"Inpatient-only\"})\n",
    "\n",
    "all_path = out_dir / f\"mimic_hypercap_EXT_all_encounters_bq_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(all_path, engine=\"openpyxl\") as xw:\n",
    "    all_encounters.to_excel(xw, sheet_name=\"all_encounters\", index=False)\n",
    "print(\"Saved:\", all_path)\n",
    "\n",
    "# 2) ED chief-complaint-only (ED-stay level)\n",
    "if \"ed_triage_cc\" not in ed_df.columns:\n",
    "    raise KeyError(\"Column 'ed_triage_cc' not found in ed_df. Ensure ED triage merge ran.\")\n",
    "\n",
    "mask_cc = ed_df[\"ed_triage_cc\"].notna() & (ed_df[\"ed_triage_cc\"].astype(str).str.strip() != \"\")\n",
    "ed_cc_only = ed_df.loc[mask_cc].copy()\n",
    "\n",
    "cc_path = out_dir / f\"mimic_hypercap_EXT_EDcc_only_edstay_bq_{timestamp}.xlsx\"\n",
    "with pd.ExcelWriter(cc_path, engine=\"openpyxl\") as xw:\n",
    "    ed_cc_only.to_excel(xw, sheet_name=\"ed_cc_only\", index=False)\n",
    "print(\"Saved:\", cc_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimiciv-tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
