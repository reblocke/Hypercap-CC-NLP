[NbConvertApp] Searching ['/Users/blocke/.jupyter', '/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/.venv/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files
[NbConvertApp] Looking for jupyter_config in /etc/jupyter
[NbConvertApp] Looking for jupyter_config in /usr/local/etc/jupyter
[NbConvertApp] Looking for jupyter_config in /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/.venv/etc/jupyter
[NbConvertApp] Looking for jupyter_config in /Users/blocke/.jupyter
[NbConvertApp] Looking for jupyter_nbconvert_config in /etc/jupyter
[NbConvertApp] Looking for jupyter_nbconvert_config in /usr/local/etc/jupyter
[NbConvertApp] Looking for jupyter_nbconvert_config in /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/.venv/etc/jupyter
[NbConvertApp] Looking for jupyter_nbconvert_config in /Users/blocke/.jupyter
[NbConvertApp] Looping through config variables with prefix "JUPYTER_NBCONVERT"
[NbConvertApp] Converting notebook MIMICIV_hypercap_EXT_cohort.ipynb to notebook
[NbConvertApp] Notebook name is 'MIMICIV_hypercap_EXT_cohort'
[NbConvertApp] Applying preprocessor: ClearOutputPreprocessor
[NbConvertApp] Applying preprocessor: ExecutePreprocessor
[NbConvertApp] Instantiating kernel 'Python (hypercap-cc-nlp)' with kernel provisioner: local-provisioner
[NbConvertApp] Starting kernel: ['/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/.venv/bin/python', '-Xfrozen_modules=off', '-m', 'ipykernel_launcher', '-f', '/private/var/folders/vf/n84t7b8171lf64smq4ddvw1m0000gn/T/tmpnk2hhlto.json']
[NbConvertApp] Connecting to: tcp://127.0.0.1:56158
[NbConvertApp] connecting iopub channel to tcp://127.0.0.1:56155
[NbConvertApp] Connecting to: tcp://127.0.0.1:56155
[NbConvertApp] connecting shell channel to tcp://127.0.0.1:56154
[NbConvertApp] Connecting to: tcp://127.0.0.1:56154
[NbConvertApp] connecting stdin channel to tcp://127.0.0.1:56156
[NbConvertApp] Connecting to: tcp://127.0.0.1:56156
[NbConvertApp] connecting heartbeat channel to tcp://127.0.0.1:56157
[NbConvertApp] connecting control channel to tcp://127.0.0.1:56158
[NbConvertApp] Connecting to: tcp://127.0.0.1:56158
[NbConvertApp] Skipping non-executing cell 0
[NbConvertApp] Skipping non-executing cell 1
[NbConvertApp] Skipping non-executing cell 2
[NbConvertApp] Skipping non-executing cell 3
[NbConvertApp] Executing cell:
# Purpose: Build ABG/VBG hypercapnia threshold flags from lab and ICU POC pCO2 measurements.

import sys
print(sys.executable)

# Central SQL registry (define all query templates here)
SQL = {}

def sql(name: str) -> str:
    if name not in SQL:
        raise KeyError(f"SQL template not found: {name}")
    return SQL[name]

# SQL templates (populated below in-place to keep notebook linear)
# Names: admit_sql, co2_thresholds_sql, cohort_icd_sql, counts_sql, demo_sql, ditems_sql, ed_counts_sql, ed_first_vitals_sql, ed_spine_sql, ed_to_icu_sql, ed_triage_sql, ed_vitals_sql, icd_sql, icu_meta_sql, icu_sql, labitems_sql, labs_sql, vent_chart_sql, vent_sql

[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Build ABG/VBG hypercapnia threshold flags from lab and ICU POC pCO2 measurements.\n\nimport sys\nprint(sys.executable)\n\n# Central SQL registry (define all query templates here)\nSQL = {}\n\ndef sql(name: str) -> str:\n    if name not in SQL:\n        raise KeyError(f"SQL template not found: {name}")\n    return SQL[name]\n\n# SQL templates (populated below in-place to keep notebook linear)\n# Names: admit_sql, co2_thresholds_sql, cohort_icd_sql, counts_sql, demo_sql, ditems_sql, ed_counts_sql, ed_first_vitals_sql, ed_spine_sql, ed_to_icu_sql, ed_triage_sql, ed_vitals_sql, icd_sql, icu_meta_sql, icu_sql, labitems_sql, labs_sql, vent_chart_sql, vent_sql\n', 'execution_count': 1}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': '/Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP/.venv/bin/python\n'}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 5
[NbConvertApp] Skipping non-executing cell 6
[NbConvertApp] Skipping non-executing cell 7
[NbConvertApp] Skipping non-executing cell 8
[NbConvertApp] Skipping non-executing cell 9
[NbConvertApp] Executing cell:
# Purpose: Set up project paths, environment variables, and BigQuery client connections for reproducible execution.

# --- Imports & environment
import os, re, json, math, textwrap
from pathlib import Path

import numpy as np
import pandas as pd

from google.cloud import bigquery
from google.oauth2 import service_account
from dotenv import load_dotenv

load_dotenv()

WORK_DIR = Path(os.getenv("WORK_DIR", Path.cwd())).expanduser().resolve()
DATA_DIR = WORK_DIR / "MIMIC tabular data"
DATA_DIR.mkdir(parents=True, exist_ok=True)

# ---- Backend selection (we use BigQuery)
BACKEND = os.getenv("MIMIC_BACKEND", "bigquery").strip().lower()
assert BACKEND == "bigquery", "This notebook is BigQuery-specific."

WORK_PROJECT = os.getenv("WORK_PROJECT", "").strip()  # your billing project
PHYS = os.getenv("BQ_PHYSIONET_PROJECT", "physionet-data").strip()  # hosting project (read-only)

# Dataset preferences: resolved to accessible datasets in the next setup cell.
HOSP = os.getenv("BQ_DATASET_HOSP", "mimiciv_3_1_hosp").strip()
ICU  = os.getenv("BQ_DATASET_ICU",  "mimiciv_3_1_icu").strip()
ED   = os.getenv("BQ_DATASET_ED",   "").strip()

# BigQuery client
client = bigquery.Client(project=WORK_PROJECT)

print("Project:", WORK_PROJECT)
print("PhysioNet host:", PHYS)
print("HOSP (pref):", HOSP, "ICU (pref):", ICU, "ED (pref):", ED)
print("WORK_DIR:", WORK_DIR)

[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Set up project paths, environment variables, and BigQuery client connections for reproducible execution.\n\n# --- Imports & environment\nimport os, re, json, math, textwrap\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nfrom google.cloud import bigquery\nfrom google.oauth2 import service_account\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nWORK_DIR = Path(os.getenv("WORK_DIR", Path.cwd())).expanduser().resolve()\nDATA_DIR = WORK_DIR / "MIMIC tabular data"\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\n# ---- Backend selection (we use BigQuery)\nBACKEND = os.getenv("MIMIC_BACKEND", "bigquery").strip().lower()\nassert BACKEND == "bigquery", "This notebook is BigQuery-specific."\n\nWORK_PROJECT = os.getenv("WORK_PROJECT", "").strip()  # your billing project\nPHYS = os.getenv("BQ_PHYSIONET_PROJECT", "physionet-data").strip()  # hosting project (read-only)\n\n# Dataset preferences: resolved to accessible datasets in the next setup cell.\nHOSP = os.getenv("BQ_DATASET_HOSP", "mimiciv_3_1_hosp").strip()\nICU  = os.getenv("BQ_DATASET_ICU",  "mimiciv_3_1_icu").strip()\nED   = os.getenv("BQ_DATASET_ED",   "").strip()\n\n# BigQuery client\nclient = bigquery.Client(project=WORK_PROJECT)\n\nprint("Project:", WORK_PROJECT)\nprint("PhysioNet host:", PHYS)\nprint("HOSP (pref):", HOSP, "ICU (pref):", ICU, "ED (pref):", ED)\nprint("WORK_DIR:", WORK_DIR)\n', 'execution_count': 2}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'Project: mimic-hypercapnia\nPhysioNet host: physionet-data\nHOSP (pref): mimiciv_3_1_hosp ICU (pref): mimiciv_3_1_icu ED (pref): mimiciv_ed\nWORK_DIR: /Users/blocke/Box Sync/Residency Personal Files/Scholarly Work/Locke Research Projects/Hypercap-CC-NLP\n'}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Executing cell:
# Purpose: Define reusable BigQuery helpers and resolve dataset names across known naming variants.

from datetime import datetime, timezone

# --- Helper: run SQL with optional named parameters
def run_sql_bq(sql: str, params: dict | None = None) -> pd.DataFrame:
    job_config = bigquery.QueryJobConfig()
    if params:
        bq_params = []
        for k, v in params.items():
            if isinstance(v, (list, tuple, np.ndarray, pd.Series)):
                # BigQuery ARRAY<INT64> if all ints; else ARRAY<STRING>
                v_list = list(v)
                if all(isinstance(x, (int, np.integer)) for x in v_list):
                    bq_params.append(bigquery.ArrayQueryParameter(k, "INT64", list(map(int, v_list))))
                else:
                    bq_params.append(bigquery.ArrayQueryParameter(k, "STRING", list(map(str, v_list))))
            else:
                # scalar
                if isinstance(v, (int, np.integer)):
                    bq_params.append(bigquery.ScalarQueryParameter(k, "INT64", int(v)))
                elif isinstance(v, float):
                    bq_params.append(bigquery.ScalarQueryParameter(k, "FLOAT64", float(v)))
                else:
                    bq_params.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))
        job_config.query_parameters = bq_params
    job = client.query(sql, job_config=job_config)
    try:
        return job.result().to_dataframe(create_bqstorage_client=True)
    except TypeError:
        return job.result().to_dataframe()

# --- Helper: test if a fully-qualified table exists and is accessible
def table_exists(fqtn: str) -> bool:
    try:
        _ = run_sql_bq(f"SELECT 1 FROM `{fqtn}` LIMIT 1")
        return True
    except Exception:
        return False

def resolve_dataset(preferred: str, candidates: list[str], probe_table: str, label: str) -> tuple[str, str]:
    # Keep preferred first, then try known aliases.
    ordered = []
    if preferred:
        ordered.append(preferred)
    for cand in candidates:
        if cand not in ordered:
            ordered.append(cand)

    for dataset in ordered:
        fqtn = f"{PHYS}.{dataset}.{probe_table}"
        if table_exists(fqtn):
            return dataset, fqtn

    raise RuntimeError(
        f"No accessible {label} dataset found for probe table '{probe_table}'. Tried: {ordered}"
    )

# Resolve HOSP/ICU/ED names so notebook runs across v3.1 naming variants.
HOSP, HOSP_PROBE = resolve_dataset(
    HOSP,
    ["mimiciv_3_1_hosp", "mimiciv_v3_1_hosp", "mimiciv_hosp"],
    "admissions",
    "HOSP",
)
ICU, ICU_PROBE = resolve_dataset(
    ICU,
    ["mimiciv_3_1_icu", "mimiciv_v3_1_icu", "mimiciv_icu"],
    "icustays",
    "ICU",
)
ED, ED_PROBE = resolve_dataset(
    ED,
    ["mimiciv_ed", "mimiciv_3_1_ed", "mimiciv_v3_1_ed"],
    "edstays",
    "ED",
)

RUN_METADATA = {
    "run_started_utc": datetime.now(timezone.utc).isoformat(),
    "work_project": WORK_PROJECT,
    "physionet_project": PHYS,
    "datasets": {"hosp": HOSP, "icu": ICU, "ed": ED},
    "probe_tables": {"hosp": HOSP_PROBE, "icu": ICU_PROBE, "ed": ED_PROBE},
    "notebook": "MIMICIV_hypercap_EXT_cohort.ipynb",
}

print("Resolved datasets:", RUN_METADATA["datasets"])
print("Dataset probes:", RUN_METADATA["probe_tables"])

[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define reusable BigQuery helpers and resolve dataset names across known naming variants.\n\nfrom datetime import datetime, timezone\n\n# --- Helper: run SQL with optional named parameters\ndef run_sql_bq(sql: str, params: dict | None = None) -> pd.DataFrame:\n    job_config = bigquery.QueryJobConfig()\n    if params:\n        bq_params = []\n        for k, v in params.items():\n            if isinstance(v, (list, tuple, np.ndarray, pd.Series)):\n                # BigQuery ARRAY<INT64> if all ints; else ARRAY<STRING>\n                v_list = list(v)\n                if all(isinstance(x, (int, np.integer)) for x in v_list):\n                    bq_params.append(bigquery.ArrayQueryParameter(k, "INT64", list(map(int, v_list))))\n                else:\n                    bq_params.append(bigquery.ArrayQueryParameter(k, "STRING", list(map(str, v_list))))\n            else:\n                # scalar\n                if isinstance(v, (int, np.integer)):\n                    bq_params.append(bigquery.ScalarQueryParameter(k, "INT64", int(v)))\n                elif isinstance(v, float):\n                    bq_params.append(bigquery.ScalarQueryParameter(k, "FLOAT64", float(v)))\n                else:\n                    bq_params.append(bigquery.ScalarQueryParameter(k, "STRING", str(v)))\n        job_config.query_parameters = bq_params\n    job = client.query(sql, job_config=job_config)\n    try:\n        return job.result().to_dataframe(create_bqstorage_client=True)\n    except TypeError:\n        return job.result().to_dataframe()\n\n# --- Helper: test if a fully-qualified table exists and is accessible\ndef table_exists(fqtn: str) -> bool:\n    try:\n        _ = run_sql_bq(f"SELECT 1 FROM `{fqtn}` LIMIT 1")\n        return True\n    except Exception:\n        return False\n\ndef resolve_dataset(preferred: str, candidates: list[str], probe_table: str, label: str) -> tuple[str, str]:\n    # Keep preferred first, then try known aliases.\n    ordered = []\n    if preferred:\n        ordered.append(preferred)\n    for cand in candidates:\n        if cand not in ordered:\n            ordered.append(cand)\n\n    for dataset in ordered:\n        fqtn = f"{PHYS}.{dataset}.{probe_table}"\n        if table_exists(fqtn):\n            return dataset, fqtn\n\n    raise RuntimeError(\n        f"No accessible {label} dataset found for probe table \'{probe_table}\'. Tried: {ordered}"\n    )\n\n# Resolve HOSP/ICU/ED names so notebook runs across v3.1 naming variants.\nHOSP, HOSP_PROBE = resolve_dataset(\n    HOSP,\n    ["mimiciv_3_1_hosp", "mimiciv_v3_1_hosp", "mimiciv_hosp"],\n    "admissions",\n    "HOSP",\n)\nICU, ICU_PROBE = resolve_dataset(\n    ICU,\n    ["mimiciv_3_1_icu", "mimiciv_v3_1_icu", "mimiciv_icu"],\n    "icustays",\n    "ICU",\n)\nED, ED_PROBE = resolve_dataset(\n    ED,\n    ["mimiciv_ed", "mimiciv_3_1_ed", "mimiciv_v3_1_ed"],\n    "edstays",\n    "ED",\n)\n\nRUN_METADATA = {\n    "run_started_utc": datetime.now(timezone.utc).isoformat(),\n    "work_project": WORK_PROJECT,\n    "physionet_project": PHYS,\n    "datasets": {"hosp": HOSP, "icu": ICU, "ed": ED},\n    "probe_tables": {"hosp": HOSP_PROBE, "icu": ICU_PROBE, "ed": ED_PROBE},\n    "notebook": "MIMICIV_hypercap_EXT_cohort.ipynb",\n}\n\nprint("Resolved datasets:", RUN_METADATA["datasets"])\nprint("Dataset probes:", RUN_METADATA["probe_tables"])\n', 'execution_count': 3}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': "Resolved datasets: {'hosp': 'mimiciv_3_1_hosp', 'icu': 'mimiciv_3_1_icu', 'ed': 'mimiciv_ed'}\nDataset probes: {'hosp': 'physionet-data.mimiciv_3_1_hosp.admissions', 'icu': 'physionet-data.mimiciv_3_1_icu.icustays', 'ed': 'physionet-data.mimiciv_ed.edstays'}\n"}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Executing cell:
# Purpose: Create reusable data-quality and merge guardrail helpers to prevent silent join errors.

# --- Helper utilities for reproducibility and safe joins
def require_cols(df: pd.DataFrame, cols: list[str], name: str) -> None:
    missing = [c for c in cols if c not in df.columns]
    if missing:
        raise KeyError(f"{name} missing columns: {missing}")

def assert_unique(df: pd.DataFrame, key: str, name: str) -> None:
    if df[key].duplicated().any():
        n = int(df[key].duplicated().sum())
        raise ValueError(f"{name} has {n} duplicate {key} values")

def safe_merge(left: pd.DataFrame, right: pd.DataFrame, on: list[str] | str, how: str, name: str) -> pd.DataFrame:
    # guard against accidental duplicate columns
    overlap = set(left.columns) & set(right.columns)
    if isinstance(on, str):
        on_cols = {on}
    else:
        on_cols = set(on)
    overlap = overlap - on_cols
    if overlap:
        raise ValueError(f"{name} merge would duplicate columns: {sorted(overlap)}")
    return left.merge(right, on=on, how=how)

def check_ranges(df: pd.DataFrame, ranges: dict[str, tuple[float, float]]) -> pd.DataFrame:
    rows = []
    for col, (lo, hi) in ranges.items():
        if col not in df.columns:
            continue
        bad = df[col].notna() & ((df[col] < lo) | (df[col] > hi))
        rows.append({"col": col, "n_bad": int(bad.sum())})
    return pd.DataFrame(rows)


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Create reusable data-quality and merge guardrail helpers to prevent silent join errors.\n\n# --- Helper utilities for reproducibility and safe joins\ndef require_cols(df: pd.DataFrame, cols: list[str], name: str) -> None:\n    missing = [c for c in cols if c not in df.columns]\n    if missing:\n        raise KeyError(f"{name} missing columns: {missing}")\n\ndef assert_unique(df: pd.DataFrame, key: str, name: str) -> None:\n    if df[key].duplicated().any():\n        n = int(df[key].duplicated().sum())\n        raise ValueError(f"{name} has {n} duplicate {key} values")\n\ndef safe_merge(left: pd.DataFrame, right: pd.DataFrame, on: list[str] | str, how: str, name: str) -> pd.DataFrame:\n    # guard against accidental duplicate columns\n    overlap = set(left.columns) & set(right.columns)\n    if isinstance(on, str):\n        on_cols = {on}\n    else:\n        on_cols = set(on)\n    overlap = overlap - on_cols\n    if overlap:\n        raise ValueError(f"{name} merge would duplicate columns: {sorted(overlap)}")\n    return left.merge(right, on=on, how=how)\n\ndef check_ranges(df: pd.DataFrame, ranges: dict[str, tuple[float, float]]) -> pd.DataFrame:\n    rows = []\n    for col, (lo, hi) in ranges.items():\n        if col not in df.columns:\n            continue\n        bad = df[col].notna() & ((df[col] < lo) | (df[col] > hi))\n        rows.append({"col": col, "n_bad": int(bad.sum())})\n    return pd.DataFrame(rows)\n\n', 'execution_count': 4}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 13
[NbConvertApp] Skipping non-executing cell 14
[NbConvertApp] Executing cell:
# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.

# Target ICD codes (dotless, uppercase)
ICD10_CODES = ['J9602','J9612','J9622','J9692','E662']
ICD9_CODES  = ['27803']

SQL["cohort_icd_sql"] = f"""
-- ICD-based cohort flags per admission
WITH target_codes AS (
  SELECT 'J9602' AS code, 10 AS ver UNION ALL
  SELECT 'J9612', 10 UNION ALL
  SELECT 'J9622', 10 UNION ALL
  SELECT 'J9692', 10 UNION ALL
  SELECT 'E662',  10 UNION ALL
  SELECT '27803', 9
),

-- Hospital ICDs restricted to target codes
hosp_dx AS (
  SELECT
    d.subject_id,
    d.hadm_id,
    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,
    d.icd_version
  FROM `{PHYS}.{HOSP}.diagnoses_icd` d
  JOIN target_codes t
    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))
  WHERE d.hadm_id IS NOT NULL
),

-- Hospital flags per admission
hosp_flags AS (
  SELECT
    subject_id, hadm_id,
    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,
    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,
    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,
    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,
    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,
    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803
  FROM hosp_dx
  GROUP BY subject_id, hadm_id
),

-- ED ICDs restricted to target codes (map to hadm via edstays)
ed_dx AS (
  SELECT
    s.subject_id,
    s.hadm_id,
    s.stay_id,
    s.intime AS ed_intime,
    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,
    d.icd_version
  FROM `{PHYS}.{ED}.diagnosis` d
  JOIN `{PHYS}.{ED}.edstays` s
    ON s.subject_id = d.subject_id AND s.stay_id = d.stay_id
  JOIN target_codes t
    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))
  WHERE s.hadm_id IS NOT NULL
),

-- ED flags per ED stay (so we can both: OR flags across stays and also pick earliest stay_id)
ed_flags_by_stay AS (
  SELECT
    subject_id, hadm_id, stay_id, MIN(ed_intime) AS ed_intime,
    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,
    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,
    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,
    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,
    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,
    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803
  FROM ed_dx
  GROUP BY subject_id, hadm_id, stay_id
),

-- OR the ED flags across all ED stays mapped to the same hadm
ed_flags_or AS (
  SELECT
    subject_id, hadm_id,
    MAX(ICD10_J9602) AS ICD10_J9602,
    MAX(ICD10_J9612) AS ICD10_J9612,
    MAX(ICD10_J9622) AS ICD10_J9622,
    MAX(ICD10_J9692) AS ICD10_J9692,
    MAX(ICD10_E662 ) AS ICD10_E662,
    MAX(ICD9_27803) AS ICD9_27803
  FROM ed_flags_by_stay
  GROUP BY subject_id, hadm_id
),

-- Earliest ED stay_id per hadm (NO UNNEST of aggregates; use [OFFSET(0)])
ed_earliest AS (
  SELECT
    subject_id,
    hadm_id,
    (ARRAY_AGG(STRUCT(stay_id, ed_intime) ORDER BY ed_intime LIMIT 1))[OFFSET(0)].stay_id AS stay_id
  FROM ed_flags_by_stay
  GROUP BY subject_id, hadm_id
),

-- Bring flags and earliest stay_id together
ed_by_hadm AS (
  SELECT
    f.subject_id,
    f.hadm_id,
    e.stay_id,
    f.ICD10_J9602,
    f.ICD10_J9612,
    f.ICD10_J9622,
    f.ICD10_J9692,
    f.ICD10_E662,
    f.ICD9_27803
  FROM ed_flags_or f
  LEFT JOIN ed_earliest e
    USING (subject_id, hadm_id)
),

-- Combine ED and hospital flags at the admission level
combined AS (
  SELECT
    COALESCE(h.subject_id, e.subject_id) AS subject_id,
    COALESCE(h.hadm_id,     e.hadm_id)   AS hadm_id,
    GREATEST(IFNULL(h.ICD10_J9602,0), IFNULL(e.ICD10_J9602,0)) AS ICD10_J9602,
    GREATEST(IFNULL(h.ICD10_J9612,0), IFNULL(e.ICD10_J9612,0)) AS ICD10_J9612,
    GREATEST(IFNULL(h.ICD10_J9622,0), IFNULL(e.ICD10_J9622,0)) AS ICD10_J9622,
    GREATEST(IFNULL(h.ICD10_J9692,0), IFNULL(e.ICD10_J9692,0)) AS ICD10_J9692,
    GREATEST(IFNULL(h.ICD10_E662 ,0), IFNULL(e.ICD10_E662 ,0)) AS ICD10_E662,
    GREATEST(IFNULL(h.ICD9_27803,0), IFNULL(e.ICD9_27803,0)) AS ICD9_27803,
    IF((IFNULL(h.ICD10_J9602,0)+IFNULL(h.ICD10_J9612,0)+IFNULL(h.ICD10_J9622,0)+IFNULL(h.ICD10_J9692,0)+IFNULL(h.ICD10_E662,0)+IFNULL(h.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_hosp,
    IF((IFNULL(e.ICD10_J9602,0)+IFNULL(e.ICD10_J9612,0)+IFNULL(e.ICD10_J9622,0)+IFNULL(e.ICD10_J9692,0)+IFNULL(e.ICD10_E662,0)+IFNULL(e.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_ed
  FROM hosp_flags h
  FULL OUTER JOIN ed_by_hadm e
    ON h.hadm_id = e.hadm_id
)

SELECT
  subject_id, hadm_id,
  ICD10_J9602, ICD10_J9612, ICD10_J9622, ICD10_J9692, ICD10_E662, ICD9_27803,
  IF((ICD10_J9602+ICD10_J9612+ICD10_J9622+ICD10_J9692+ICD10_E662+ICD9_27803) > 0, 1, 0) AS any_hypercap_icd,
  any_hypercap_icd_hosp,
  any_hypercap_icd_ed,
  CASE
    WHEN any_hypercap_icd_hosp=1 AND any_hypercap_icd_ed=1 THEN 'ED+HOSP'
    WHEN any_hypercap_icd_ed=1 THEN 'ED'
    WHEN any_hypercap_icd_hosp=1 THEN 'HOSP'
    ELSE 'NONE'
  END AS icd_source
FROM combined
"""

cohort_icd = run_sql_bq(sql("cohort_icd_sql"))
print("ICD cohort admissions:", len(cohort_icd))
cohort_icd.head(3)


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.\n\n# Target ICD codes (dotless, uppercase)\nICD10_CODES = [\'J9602\',\'J9612\',\'J9622\',\'J9692\',\'E662\']\nICD9_CODES  = [\'27803\']\n\nSQL["cohort_icd_sql"] = f"""\n-- ICD-based cohort flags per admission\nWITH target_codes AS (\n  SELECT \'J9602\' AS code, 10 AS ver UNION ALL\n  SELECT \'J9612\', 10 UNION ALL\n  SELECT \'J9622\', 10 UNION ALL\n  SELECT \'J9692\', 10 UNION ALL\n  SELECT \'E662\',  10 UNION ALL\n  SELECT \'27803\', 9\n),\n\n-- Hospital ICDs restricted to target codes\nhosp_dx AS (\n  SELECT\n    d.subject_id,\n    d.hadm_id,\n    UPPER(REPLACE(d.icd_code, \'.\', \'\')) AS code_norm,\n    d.icd_version\n  FROM `{PHYS}.{HOSP}.diagnoses_icd` d\n  JOIN target_codes t\n    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, \'.\', \'\'))\n  WHERE d.hadm_id IS NOT NULL\n),\n\n-- Hospital flags per admission\nhosp_flags AS (\n  SELECT\n    subject_id, hadm_id,\n    MAX(IF(icd_version=10 AND code_norm=\'J9602\',1,0)) AS ICD10_J9602,\n    MAX(IF(icd_version=10 AND code_norm=\'J9612\',1,0)) AS ICD10_J9612,\n    MAX(IF(icd_version=10 AND code_norm=\'J9622\',1,0)) AS ICD10_J9622,\n    MAX(IF(icd_version=10 AND code_norm=\'J9692\',1,0)) AS ICD10_J9692,\n    MAX(IF(icd_version=10 AND code_norm=\'E662\', 1,0)) AS ICD10_E662,\n    MAX(IF(icd_version=9  AND code_norm=\'27803\',1,0)) AS ICD9_27803\n  FROM hosp_dx\n  GROUP BY subject_id, hadm_id\n),\n\n-- ED ICDs restricted to target codes (map to hadm via edstays)\ned_dx AS (\n  SELECT\n    s.subject_id,\n    s.hadm_id,\n    s.stay_id,\n    s.intime AS ed_intime,\n    UPPER(REPLACE(d.icd_code, \'.\', \'\')) AS code_norm,\n    d.icd_version\n  FROM `{PHYS}.{ED}.diagnosis` d\n  JOIN `{PHYS}.{ED}.edstays` s\n    ON s.subject_id = d.subject_id AND s.stay_id = d.stay_id\n  JOIN target_codes t\n    ON t.ver = d.icd_version AND t.code = UPPER(REPLACE(d.icd_code, \'.\', \'\'))\n  WHERE s.hadm_id IS NOT NULL\n),\n\n-- ED flags per ED stay (so we can both: OR flags across stays and also pick earliest stay_id)\ned_flags_by_stay AS (\n  SELECT\n    subject_id, hadm_id, stay_id, MIN(ed_intime) AS ed_intime,\n    MAX(IF(icd_version=10 AND code_norm=\'J9602\',1,0)) AS ICD10_J9602,\n    MAX(IF(icd_version=10 AND code_norm=\'J9612\',1,0)) AS ICD10_J9612,\n    MAX(IF(icd_version=10 AND code_norm=\'J9622\',1,0)) AS ICD10_J9622,\n    MAX(IF(icd_version=10 AND code_norm=\'J9692\',1,0)) AS ICD10_J9692,\n    MAX(IF(icd_version=10 AND code_norm=\'E662\', 1,0)) AS ICD10_E662,\n    MAX(IF(icd_version=9  AND code_norm=\'27803\',1,0)) AS ICD9_27803\n  FROM ed_dx\n  GROUP BY subject_id, hadm_id, stay_id\n),\n\n-- OR the ED flags across all ED stays mapped to the same hadm\ned_flags_or AS (\n  SELECT\n    subject_id, hadm_id,\n    MAX(ICD10_J9602) AS ICD10_J9602,\n    MAX(ICD10_J9612) AS ICD10_J9612,\n    MAX(ICD10_J9622) AS ICD10_J9622,\n    MAX(ICD10_J9692) AS ICD10_J9692,\n    MAX(ICD10_E662 ) AS ICD10_E662,\n    MAX(ICD9_27803) AS ICD9_27803\n  FROM ed_flags_by_stay\n  GROUP BY subject_id, hadm_id\n),\n\n-- Earliest ED stay_id per hadm (NO UNNEST of aggregates; use [OFFSET(0)])\ned_earliest AS (\n  SELECT\n    subject_id,\n    hadm_id,\n    (ARRAY_AGG(STRUCT(stay_id, ed_intime) ORDER BY ed_intime LIMIT 1))[OFFSET(0)].stay_id AS stay_id\n  FROM ed_flags_by_stay\n  GROUP BY subject_id, hadm_id\n),\n\n-- Bring flags and earliest stay_id together\ned_by_hadm AS (\n  SELECT\n    f.subject_id,\n    f.hadm_id,\n    e.stay_id,\n    f.ICD10_J9602,\n    f.ICD10_J9612,\n    f.ICD10_J9622,\n    f.ICD10_J9692,\n    f.ICD10_E662,\n    f.ICD9_27803\n  FROM ed_flags_or f\n  LEFT JOIN ed_earliest e\n    USING (subject_id, hadm_id)\n),\n\n-- Combine ED and hospital flags at the admission level\ncombined AS (\n  SELECT\n    COALESCE(h.subject_id, e.subject_id) AS subject_id,\n    COALESCE(h.hadm_id,     e.hadm_id)   AS hadm_id,\n    GREATEST(IFNULL(h.ICD10_J9602,0), IFNULL(e.ICD10_J9602,0)) AS ICD10_J9602,\n    GREATEST(IFNULL(h.ICD10_J9612,0), IFNULL(e.ICD10_J9612,0)) AS ICD10_J9612,\n    GREATEST(IFNULL(h.ICD10_J9622,0), IFNULL(e.ICD10_J9622,0)) AS ICD10_J9622,\n    GREATEST(IFNULL(h.ICD10_J9692,0), IFNULL(e.ICD10_J9692,0)) AS ICD10_J9692,\n    GREATEST(IFNULL(h.ICD10_E662 ,0), IFNULL(e.ICD10_E662 ,0)) AS ICD10_E662,\n    GREATEST(IFNULL(h.ICD9_27803,0), IFNULL(e.ICD9_27803,0)) AS ICD9_27803,\n    IF((IFNULL(h.ICD10_J9602,0)+IFNULL(h.ICD10_J9612,0)+IFNULL(h.ICD10_J9622,0)+IFNULL(h.ICD10_J9692,0)+IFNULL(h.ICD10_E662,0)+IFNULL(h.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_hosp,\n    IF((IFNULL(e.ICD10_J9602,0)+IFNULL(e.ICD10_J9612,0)+IFNULL(e.ICD10_J9622,0)+IFNULL(e.ICD10_J9692,0)+IFNULL(e.ICD10_E662,0)+IFNULL(e.ICD9_27803,0)) > 0, 1, 0) AS any_hypercap_icd_ed\n  FROM hosp_flags h\n  FULL OUTER JOIN ed_by_hadm e\n    ON h.hadm_id = e.hadm_id\n)\n\nSELECT\n  subject_id, hadm_id,\n  ICD10_J9602, ICD10_J9612, ICD10_J9622, ICD10_J9692, ICD10_E662, ICD9_27803,\n  IF((ICD10_J9602+ICD10_J9612+ICD10_J9622+ICD10_J9692+ICD10_E662+ICD9_27803) > 0, 1, 0) AS any_hypercap_icd,\n  any_hypercap_icd_hosp,\n  any_hypercap_icd_ed,\n  CASE\n    WHEN any_hypercap_icd_hosp=1 AND any_hypercap_icd_ed=1 THEN \'ED+HOSP\'\n    WHEN any_hypercap_icd_ed=1 THEN \'ED\'\n    WHEN any_hypercap_icd_hosp=1 THEN \'HOSP\'\n    ELSE \'NONE\'\n  END AS icd_source\nFROM combined\n"""\n\ncohort_icd = run_sql_bq(sql("cohort_icd_sql"))\nprint("ICD cohort admissions:", len(cohort_icd))\ncohort_icd.head(3)\n\n', 'execution_count': 5}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'ICD cohort admissions: 4237\n'}
[NbConvertApp] msg_type: execute_result
[NbConvertApp] content: {'data': {'text/plain': '   subject_id   hadm_id  ICD10_J9602  ICD10_J9612  ICD10_J9622  ICD10_J9692  \\\n0    10485425  21207827            0            0            1            0   \n1    16826447  21830147            0            1            0            0   \n2    11482582  22869017            0            0            0            0   \n\n   ICD10_E662  ICD9_27803  any_hypercap_icd  any_hypercap_icd_hosp  \\\n0           1           0                 1                      1   \n1           1           0                 1                      1   \n2           0           1                 1                      1   \n\n   any_hypercap_icd_ed icd_source  \n0                    0       HOSP  \n1                    0       HOSP  \n2                    0       HOSP  ', 'text/html': '<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>subject_id</th>\n      <th>hadm_id</th>\n      <th>ICD10_J9602</th>\n      <th>ICD10_J9612</th>\n      <th>ICD10_J9622</th>\n      <th>ICD10_J9692</th>\n      <th>ICD10_E662</th>\n      <th>ICD9_27803</th>\n      <th>any_hypercap_icd</th>\n      <th>any_hypercap_icd_hosp</th>\n      <th>any_hypercap_icd_ed</th>\n      <th>icd_source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10485425</td>\n      <td>21207827</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>HOSP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16826447</td>\n      <td>21830147</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>HOSP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11482582</td>\n      <td>22869017</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>HOSP</td>\n    </tr>\n  </tbody>\n</table>\n</div>'}, 'metadata': {}, 'execution_count': 5}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 16
[NbConvertApp] Skipping non-executing cell 17
[NbConvertApp] Executing cell:
# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.

SQL["co2_thresholds_sql"] = f"""
/* ---- LAB (HOSP) pCO2 across entire dataset ---- */
WITH hosp_cand AS (
  SELECT
    le.hadm_id, le.charttime, le.specimen_id,
    COALESCE(
      CAST(le.valuenum AS FLOAT64),
      SAFE_CAST(REGEXP_EXTRACT(LOWER(le.value), r'(-?\d+(?:\.\d+)?)') AS FLOAT64)
    ) AS val,
    LOWER(REPLACE(COALESCE(le.valueuom,''),' ','')) AS uom_nospace,
    LOWER(di.label) AS lbl,
    LOWER(COALESCE(di.fluid,'')) AS fl
  FROM `{PHYS}.{HOSP}.labevents` le
  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid
  WHERE (le.valuenum IS NOT NULL OR le.value IS NOT NULL)
    AND (
      LOWER(COALESCE(di.category,'')) LIKE '%blood gas%' OR
      LOWER(di.label) LIKE '%pco2%' OR
      REGEXP_CONTAINS(LOWER(di.label), r'\bpa?\s*co(?:2|₂)\b')
    )
    AND NOT REGEXP_CONTAINS(LOWER(di.label),
        r'(et\s*co2|end[- ]?tidal|t\s*co2|tco2|total\s*co2|hco3|bicar)')
),
hosp_spec AS (
  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val
  FROM `{PHYS}.{HOSP}.labevents` le
  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid
  WHERE le.specimen_id IS NOT NULL
    AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')
),
hosp_pco2 AS (
  SELECT
    c.hadm_id, c.charttime,
    CASE
      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\bart\b') THEN 'arterial'
      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'
      WHEN REGEXP_CONTAINS(c.fl, r'arter') THEN 'arterial'
      WHEN REGEXP_CONTAINS(c.fl, r'ven') THEN 'venous'
      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\b(abg|art|arterial|a[- ]?line)\b') THEN 'arterial'
      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\b(vbg|ven|venous|mixed|central)\b') THEN 'venous'
      ELSE 'other'
    END AS site,
    CASE WHEN c.uom_nospace='kpa' THEN c.val*7.50062 ELSE c.val END AS pco2_mmHg
  FROM hosp_cand c
  LEFT JOIN hosp_spec s USING (specimen_id)
  WHERE c.val IS NOT NULL
),
hosp_pco2_std AS (
  SELECT hadm_id, site, charttime, pco2_mmHg
  FROM hosp_pco2
  WHERE site IN ('arterial','venous','other') AND pco2_mmHg BETWEEN 5 AND 200
),

/* ---- ICU (POC) pCO2 across entire dataset ---- */
icu_raw AS (
  SELECT
    ie.hadm_id,
    ce.stay_id,
    ce.charttime,
    LOWER(di.label) AS lbl,
    LOWER(REPLACE(COALESCE(ce.valueuom,''),' ','')) AS uom_nospace,
    LOWER(COALESCE(ce.value,'')) AS valstr,
    COALESCE(
      CAST(ce.valuenum AS FLOAT64),
      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r'(-?\d+(?:\.\d+)?)') AS FLOAT64)
    ) AS val
  FROM `{PHYS}.{ICU}.chartevents` ce
  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid
  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id
),
icu_cand AS (
  SELECT
    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,
    CASE
      WHEN (
            REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\s*co\s*(?:2|₂)([^a-z]|$)')
            OR uom_nospace IN ('mmhg','kpa')
            OR REGEXP_CONTAINS(valstr, r'\b(mm\s*hg|kpa)\b')
           )
           AND NOT REGEXP_CONTAINS(lbl,
               r'(et\s*co2|end[- ]?tidal|t\s*co2|tco2|total\s*co2|hco3|bicar|v\s*co2|vco2|co2\s*(prod|elimin|production|elimination))')
      THEN 'pco2'
      ELSE NULL
    END AS analyte,
    CASE
      WHEN REGEXP_CONTAINS(lbl, r'\b(abg|art|arterial|a[- ]?line)\b') THEN 'arterial'
      WHEN REGEXP_CONTAINS(lbl, r'\b(vbg|ven|venous|mixed|central)\b') THEN 'venous'
      ELSE 'other'
    END AS site
  FROM icu_raw
  WHERE val IS NOT NULL
    AND (
      REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\s*co\s*(?:2|₂)([^a-z]|$)')
      OR uom_nospace IN ('mmhg','kpa')
      OR REGEXP_CONTAINS(valstr, r'\b(mm\s*hg|kpa)\b')
    )
    AND NOT REGEXP_CONTAINS(lbl,
        r'(et\s*co2|end[- ]?tidal|t\s*co2|tco2|total\s*co2|hco3|bicar|v\s*co2|vco2|co2\s*(prod|elimin|production|elimination))')
),
icu_co2_std AS (
  SELECT
    hadm_id,
    site,
    charttime,
    CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\bkpa\b') THEN val*7.50062 ELSE val END AS pco2_mmHg
  FROM icu_cand
  WHERE analyte='pco2'
    AND site IN ('arterial','venous','other')
    AND (CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\bkpa\b') THEN val*7.50062 ELSE val END) BETWEEN 5 AND 200
),

/* ---- Combine and threshold per admission ---- */
all_pco2 AS (
  SELECT * FROM hosp_pco2_std
  UNION ALL
  SELECT * FROM icu_co2_std
),
thresh AS (
  SELECT
    hadm_id,
    MAX(IF(site='arterial' AND pco2_mmHg >= 45.0, 1, 0)) AS abg_hypercap_threshold,
    MAX(IF(site='venous'   AND pco2_mmHg >= 50.0, 1, 0)) AS vbg_hypercap_threshold,
    MAX(IF(site='other'    AND pco2_mmHg >= 50.0, 1, 0)) AS other_hypercap_threshold
  FROM all_pco2
  GROUP BY hadm_id
)
SELECT * FROM thresh
"""

co2_thresh = run_sql_bq(sql("co2_thresholds_sql"))
print("Admissions meeting thresholds:", len(co2_thresh))
co2_thresh.head(3)


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.\n\nSQL["co2_thresholds_sql"] = f"""\n/* ---- LAB (HOSP) pCO2 across entire dataset ---- */\nWITH hosp_cand AS (\n  SELECT\n    le.hadm_id, le.charttime, le.specimen_id,\n    COALESCE(\n      CAST(le.valuenum AS FLOAT64),\n      SAFE_CAST(REGEXP_EXTRACT(LOWER(le.value), r\'(-?\\d+(?:\\.\\d+)?)\') AS FLOAT64)\n    ) AS val,\n    LOWER(REPLACE(COALESCE(le.valueuom,\'\'),\' \',\'\')) AS uom_nospace,\n    LOWER(di.label) AS lbl,\n    LOWER(COALESCE(di.fluid,\'\')) AS fl\n  FROM `{PHYS}.{HOSP}.labevents` le\n  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n  WHERE (le.valuenum IS NOT NULL OR le.value IS NOT NULL)\n    AND (\n      LOWER(COALESCE(di.category,\'\')) LIKE \'%blood gas%\' OR\n      LOWER(di.label) LIKE \'%pco2%\' OR\n      REGEXP_CONTAINS(LOWER(di.label), r\'\\bpa?\\s*co(?:2|₂)\\b\')\n    )\n    AND NOT REGEXP_CONTAINS(LOWER(di.label),\n        r\'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar)\')\n),\nhosp_spec AS (\n  SELECT le.specimen_id, LOWER(COALESCE(le.value,\'\')) AS spec_val\n  FROM `{PHYS}.{HOSP}.labevents` le\n  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n  WHERE le.specimen_id IS NOT NULL\n    AND REGEXP_CONTAINS(LOWER(di.label), r\'(specimen|sample)\')\n),\nhosp_pco2 AS (\n  SELECT\n    c.hadm_id, c.charttime,\n    CASE\n      WHEN REGEXP_CONTAINS(s.spec_val, r\'arter\') OR REGEXP_CONTAINS(s.spec_val, r\'\\bart\\b\') THEN \'arterial\'\n      WHEN REGEXP_CONTAINS(s.spec_val, r\'ven|mixed|central\') THEN \'venous\'\n      WHEN REGEXP_CONTAINS(c.fl, r\'arter\') THEN \'arterial\'\n      WHEN REGEXP_CONTAINS(c.fl, r\'ven\') THEN \'venous\'\n      WHEN c.fl LIKE \'%arterial%\' OR REGEXP_CONTAINS(c.lbl, r\'\\b(abg|art|arterial|a[- ]?line)\\b\') THEN \'arterial\'\n      WHEN c.fl LIKE \'%ven%\'      OR REGEXP_CONTAINS(c.lbl, r\'\\b(vbg|ven|venous|mixed|central)\\b\') THEN \'venous\'\n      ELSE \'other\'\n    END AS site,\n    CASE WHEN c.uom_nospace=\'kpa\' THEN c.val*7.50062 ELSE c.val END AS pco2_mmHg\n  FROM hosp_cand c\n  LEFT JOIN hosp_spec s USING (specimen_id)\n  WHERE c.val IS NOT NULL\n),\nhosp_pco2_std AS (\n  SELECT hadm_id, site, charttime, pco2_mmHg\n  FROM hosp_pco2\n  WHERE site IN (\'arterial\',\'venous\',\'other\') AND pco2_mmHg BETWEEN 5 AND 200\n),\n\n/* ---- ICU (POC) pCO2 across entire dataset ---- */\nicu_raw AS (\n  SELECT\n    ie.hadm_id,\n    ce.stay_id,\n    ce.charttime,\n    LOWER(di.label) AS lbl,\n    LOWER(REPLACE(COALESCE(ce.valueuom,\'\'),\' \',\'\')) AS uom_nospace,\n    LOWER(COALESCE(ce.value,\'\')) AS valstr,\n    COALESCE(\n      CAST(ce.valuenum AS FLOAT64),\n      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r\'(-?\\d+(?:\\.\\d+)?)\') AS FLOAT64)\n    ) AS val\n  FROM `{PHYS}.{ICU}.chartevents` ce\n  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n),\nicu_cand AS (\n  SELECT\n    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,\n    CASE\n      WHEN (\n            REGEXP_CONTAINS(lbl, r\'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)\')\n            OR uom_nospace IN (\'mmhg\',\'kpa\')\n            OR REGEXP_CONTAINS(valstr, r\'\\b(mm\\s*hg|kpa)\\b\')\n           )\n           AND NOT REGEXP_CONTAINS(lbl,\n               r\'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))\')\n      THEN \'pco2\'\n      ELSE NULL\n    END AS analyte,\n    CASE\n      WHEN REGEXP_CONTAINS(lbl, r\'\\b(abg|art|arterial|a[- ]?line)\\b\') THEN \'arterial\'\n      WHEN REGEXP_CONTAINS(lbl, r\'\\b(vbg|ven|venous|mixed|central)\\b\') THEN \'venous\'\n      ELSE \'other\'\n    END AS site\n  FROM icu_raw\n  WHERE val IS NOT NULL\n    AND (\n      REGEXP_CONTAINS(lbl, r\'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)\')\n      OR uom_nospace IN (\'mmhg\',\'kpa\')\n      OR REGEXP_CONTAINS(valstr, r\'\\b(mm\\s*hg|kpa)\\b\')\n    )\n    AND NOT REGEXP_CONTAINS(lbl,\n        r\'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))\')\n),\nicu_co2_std AS (\n  SELECT\n    hadm_id,\n    site,\n    charttime,\n    CASE WHEN uom_nospace=\'kpa\' OR REGEXP_CONTAINS(valstr, r\'\\bkpa\\b\') THEN val*7.50062 ELSE val END AS pco2_mmHg\n  FROM icu_cand\n  WHERE analyte=\'pco2\'\n    AND site IN (\'arterial\',\'venous\',\'other\')\n    AND (CASE WHEN uom_nospace=\'kpa\' OR REGEXP_CONTAINS(valstr, r\'\\bkpa\\b\') THEN val*7.50062 ELSE val END) BETWEEN 5 AND 200\n),\n\n/* ---- Combine and threshold per admission ---- */\nall_pco2 AS (\n  SELECT * FROM hosp_pco2_std\n  UNION ALL\n  SELECT * FROM icu_co2_std\n),\nthresh AS (\n  SELECT\n    hadm_id,\n    MAX(IF(site=\'arterial\' AND pco2_mmHg >= 45.0, 1, 0)) AS abg_hypercap_threshold,\n    MAX(IF(site=\'venous\'   AND pco2_mmHg >= 50.0, 1, 0)) AS vbg_hypercap_threshold,\n    MAX(IF(site=\'other\'    AND pco2_mmHg >= 50.0, 1, 0)) AS other_hypercap_threshold\n  FROM all_pco2\n  GROUP BY hadm_id\n)\nSELECT * FROM thresh\n"""\n\nco2_thresh = run_sql_bq(sql("co2_thresholds_sql"))\nprint("Admissions meeting thresholds:", len(co2_thresh))\nco2_thresh.head(3)\n\n', 'execution_count': 6}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'Admissions meeting thresholds: 124690\n'}
[NbConvertApp] msg_type: execute_result
[NbConvertApp] content: {'data': {'text/plain': '    hadm_id  abg_hypercap_threshold  vbg_hypercap_threshold  \\\n0  21801929                       0                       0   \n1  26912823                       0                       0   \n2  22630089                       0                       0   \n\n   other_hypercap_threshold  \n0                         1  \n1                         1  \n2                         1  ', 'text/html': '<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hadm_id</th>\n      <th>abg_hypercap_threshold</th>\n      <th>vbg_hypercap_threshold</th>\n      <th>other_hypercap_threshold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21801929</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26912823</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22630089</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>'}, 'metadata': {}, 'execution_count': 6}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 19
[NbConvertApp] Skipping non-executing cell 20
[NbConvertApp] Executing cell:
# Purpose: Combine ICD and gas-threshold ascertainment routes to produce the final hadm inclusion list.

# Outer-join because thresholds can identify hadm_id with no ICD codes and vice versa
cohort_any = cohort_icd.merge(co2_thresh, how="outer", on="hadm_id")

# Fill missing flags with 0 where appropriate
icd_cols = ["ICD10_J9602","ICD10_J9612","ICD10_J9622","ICD10_J9692","ICD10_E662","ICD9_27803","any_hypercap_icd","any_hypercap_icd_hosp","any_hypercap_icd_ed"]
for c in icd_cols:
    if c in cohort_any.columns:
        cohort_any[c] = cohort_any[c].fillna(0).astype(int)

for c in ["abg_hypercap_threshold","vbg_hypercap_threshold","other_hypercap_threshold"]:
    if c in cohort_any.columns:
        cohort_any[c] = cohort_any[c].fillna(0).astype(int)

# Final enrollment flag
cohort_any["pco2_threshold_any"] = ((cohort_any["abg_hypercap_threshold"]==1) | (cohort_any["vbg_hypercap_threshold"]==1) | (cohort_any["other_hypercap_threshold"]==1)).astype(int)
cohort_any["enrolled_any"] = ((cohort_any["any_hypercap_icd"]==1) | (cohort_any["pco2_threshold_any"]==1)).astype(int)

print("ICD-only admissions        :", int((cohort_any["any_hypercap_icd"]==1).sum()))
print("Threshold-only admissions  :", int(((cohort_any["pco2_threshold_any"]==1) & (cohort_any["any_hypercap_icd"]==0)).sum()))
print("Both ICD and threshold     :", int(((cohort_any["pco2_threshold_any"]==1) & (cohort_any["any_hypercap_icd"]==1)).sum()))
print("Total enrolled (union)     :", int((cohort_any["enrolled_any"]==1).sum()))

# New hadm list used for the rest of the notebook
hadm_list = cohort_any.loc[cohort_any["enrolled_any"]==1, "hadm_id"].dropna().astype("int64").tolist()
len(hadm_list)


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Combine ICD and gas-threshold ascertainment routes to produce the final hadm inclusion list.\n\n# Outer-join because thresholds can identify hadm_id with no ICD codes and vice versa\ncohort_any = cohort_icd.merge(co2_thresh, how="outer", on="hadm_id")\n\n# Fill missing flags with 0 where appropriate\nicd_cols = ["ICD10_J9602","ICD10_J9612","ICD10_J9622","ICD10_J9692","ICD10_E662","ICD9_27803","any_hypercap_icd","any_hypercap_icd_hosp","any_hypercap_icd_ed"]\nfor c in icd_cols:\n    if c in cohort_any.columns:\n        cohort_any[c] = cohort_any[c].fillna(0).astype(int)\n\nfor c in ["abg_hypercap_threshold","vbg_hypercap_threshold","other_hypercap_threshold"]:\n    if c in cohort_any.columns:\n        cohort_any[c] = cohort_any[c].fillna(0).astype(int)\n\n# Final enrollment flag\ncohort_any["pco2_threshold_any"] = ((cohort_any["abg_hypercap_threshold"]==1) | (cohort_any["vbg_hypercap_threshold"]==1) | (cohort_any["other_hypercap_threshold"]==1)).astype(int)\ncohort_any["enrolled_any"] = ((cohort_any["any_hypercap_icd"]==1) | (cohort_any["pco2_threshold_any"]==1)).astype(int)\n\nprint("ICD-only admissions        :", int((cohort_any["any_hypercap_icd"]==1).sum()))\nprint("Threshold-only admissions  :", int(((cohort_any["pco2_threshold_any"]==1) & (cohort_any["any_hypercap_icd"]==0)).sum()))\nprint("Both ICD and threshold     :", int(((cohort_any["pco2_threshold_any"]==1) & (cohort_any["any_hypercap_icd"]==1)).sum()))\nprint("Total enrolled (union)     :", int((cohort_any["enrolled_any"]==1).sum()))\n\n# New hadm list used for the rest of the notebook\nhadm_list = cohort_any.loc[cohort_any["enrolled_any"]==1, "hadm_id"].dropna().astype("int64").tolist()\nlen(hadm_list)\n\n', 'execution_count': 7}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'ICD-only admissions        : 4237\nThreshold-only admissions  : 110943\nBoth ICD and threshold     : 3690\nTotal enrolled (union)     : 115180\n'}
[NbConvertApp] msg_type: execute_result
[NbConvertApp] content: {'data': {'text/plain': '115179'}, 'metadata': {}, 'execution_count': 7}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 22
[NbConvertApp] Skipping non-executing cell 23
[NbConvertApp] Executing cell:
# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.

params = {"hadms": hadm_list}

bg_pairs_sql = rf"""
WITH hadms AS (SELECT hadm_id FROM UNNEST(@hadms) AS hadm_id),

/* ---------------- LAB (HOSP) ---------------- */
hosp_cand AS (
  SELECT
    le.subject_id, le.hadm_id, le.charttime, le.specimen_id,
    CAST(le.valuenum AS FLOAT64) AS val,
    LOWER(COALESCE(le.valueuom,'')) AS uom,
    LOWER(di.label) AS lbl,
    LOWER(COALESCE(di.fluid,'')) AS fl,
    LOWER(COALESCE(di.category,'')) AS cat
  FROM `{PHYS}.{HOSP}.labevents`  le
  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid
  JOIN hadms h ON h.hadm_id = le.hadm_id
  WHERE le.valuenum IS NOT NULL
    AND (
         LOWER(COALESCE(di.category,'')) LIKE '%blood gas%' OR
         LOWER(di.label) LIKE '%pco2%' OR
         REGEXP_CONTAINS(LOWER(di.label), r'\bph\b') OR
         REGEXP_CONTAINS(LOWER(di.label), r'\bpa?\s*co(?:2|₂)\b')
        )
    AND NOT REGEXP_CONTAINS(LOWER(di.label), r'(et\s*co2|end[- ]?tidal|t\s*co2|tco2|total\s*co2|hco3|bicar)')
),
hosp_spec AS (
  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val
  FROM `{PHYS}.{HOSP}.labevents` le
  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid
  WHERE le.specimen_id IS NOT NULL
    AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')
),
hosp_class AS (
  SELECT
    c.hadm_id, c.charttime, c.specimen_id, c.val, c.uom, c.lbl, c.fl,
    CASE
      WHEN REGEXP_CONTAINS(c.lbl, r'\b(?:blood\s*)?ph\b') THEN 'ph'
      WHEN (c.lbl LIKE '%pco2%' OR REGEXP_CONTAINS(c.lbl, r'\bpa?\s*co(?:2|₂)\b')) THEN 'pco2'
      ELSE NULL
    END AS analyte,
    CASE
      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\bart\b') THEN 'arterial'
      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'
      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\b(abg|art|arterial|a[- ]?line)\b') THEN 'arterial'
      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\b(vbg|ven|venous|mixed|central)\b') THEN 'venous'
      ELSE 'other'
    END AS site
  FROM hosp_cand c
  LEFT JOIN hosp_spec s USING (specimen_id)
),
hosp_pairs AS (
  SELECT
    hadm_id, specimen_id,
    MIN(charttime) AS sample_time,
    MAX(IF(analyte='ph',   val, NULL)) AS ph,
    MAX(IF(analyte='pco2', val, NULL)) AS pco2_raw,
    (ARRAY_AGG(IF(analyte='pco2', uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS pco2_uom,
    (ARRAY_AGG(IF(analyte='ph',   uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS ph_uom,
    (ARRAY_AGG(site IGNORE NULLS LIMIT 1))[OFFSET(0)] AS site
  FROM hosp_class
  GROUP BY hadm_id, specimen_id
  HAVING (ph IS NOT NULL OR pco2_raw IS NOT NULL) AND site IN ('arterial','venous','other')
),
hosp_pairs_std AS (
  SELECT
    hadm_id, specimen_id, sample_time, site,
    ph, ph_uom,
    CASE WHEN pco2_uom = 'kpa' THEN pco2_raw * 7.50062 ELSE pco2_raw END AS pco2_mmHg,
    'mmhg' AS pco2_uom_norm
  FROM hosp_pairs
  WHERE (ph IS NULL OR (ph BETWEEN 6.3 AND 7.8))
    AND (pco2_raw IS NULL OR (CASE WHEN pco2_uom='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200)
),
lab_abg AS (
  SELECT hadm_id,
         ph            AS lab_abg_ph,
         ph_uom        AS lab_abg_ph_uom,
         pco2_mmHg     AS lab_abg_paco2,
         'mmhg'        AS lab_abg_paco2_uom,
         sample_time   AS lab_abg_time
  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn
        FROM hosp_pairs_std WHERE site='arterial') WHERE rn=1
),
lab_vbg AS (
  SELECT hadm_id,
         ph            AS lab_vbg_ph,
         ph_uom        AS lab_vbg_ph_uom,
         pco2_mmHg     AS lab_vbg_paco2,
         'mmhg'        AS lab_vbg_paco2_uom,
         sample_time   AS lab_vbg_time
  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn
        FROM hosp_pairs_std WHERE site='venous') WHERE rn=1
),
lab_other AS (
  SELECT hadm_id,
         ph            AS lab_other_ph,
         ph_uom        AS lab_other_ph_uom,
         pco2_mmHg     AS lab_other_paco2,
         'mmhg'        AS lab_other_paco2_uom,
         sample_time   AS lab_other_time
  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn
        FROM hosp_pairs_std WHERE site='other') WHERE rn=1
),

/* ---------------- POC (ICU) ---------------- */
icu_raw AS (
  SELECT
    ie.hadm_id, ce.stay_id, ce.charttime,
    LOWER(di.label) AS lbl,
    LOWER(REPLACE(COALESCE(ce.valueuom,''),' ','')) AS uom_nospace,
    LOWER(COALESCE(ce.value,'')) AS valstr,
    COALESCE(
      CAST(ce.valuenum AS FLOAT64),
      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r'(-?\d+(?:\.\d+)?)') AS FLOAT64)
    ) AS val
  FROM `{PHYS}.{ICU}.chartevents` ce
  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid
  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id
  JOIN hadms h ON h.hadm_id = ie.hadm_id
),
icu_cand AS (
  SELECT
    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,
    CASE
      WHEN REGEXP_CONTAINS(lbl, r'(^|[^a-z])ph([^a-z]|$)') OR (val BETWEEN 6.3 AND 7.8) THEN 'ph'
      WHEN (
             REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\s*co\s*(?:2|₂)([^a-z]|$)')
             OR uom_nospace IN ('mmhg','kpa')
             OR REGEXP_CONTAINS(valstr, r'\b(mm\s*hg|kpa)\b')
           )
           AND NOT REGEXP_CONTAINS(lbl, r'(et\s*co2|end[- ]?tidal|t\s*co2|tco2|total\s*co2|hco3|bicar|v\s*co2|vco2|co2\s*(prod|elimin|production|elimination))')
      THEN 'pco2'
      ELSE NULL
    END AS analyte,
    CASE
      WHEN REGEXP_CONTAINS(lbl, r'\b(abg|art|arterial|a[- ]?line)\b') THEN 'arterial'
      WHEN REGEXP_CONTAINS(lbl, r'\b(vbg|ven|venous|mixed|central)\b') THEN 'venous'
      ELSE 'other'
    END AS site
  FROM icu_raw
  WHERE val IS NOT NULL
    AND (
      REGEXP_CONTAINS(lbl, r'(^|[^a-z])ph([^a-z]|$)') OR
      REGEXP_CONTAINS(lbl, r'(^|[^a-z])p(?:a)?\s*co\s*(?:2|₂)([^a-z]|$)') OR
      uom_nospace IN ('mmhg','kpa') OR
      REGEXP_CONTAINS(valstr, r'\b(mm\s*hg|kpa)\b')
    )
    AND NOT REGEXP_CONTAINS(lbl, r'(et\s*co2|end[- ]?tidal|t\s*co2|tco2|total\s*co2|hco3|bicar|v\s*co2|vco2|co2\s*(prod|elimin|production|elimination))')
),
icu_ph AS (
  SELECT hadm_id, stay_id, charttime, val AS ph, site AS site_ph
  FROM icu_cand WHERE analyte='ph'
),
icu_co2 AS (
  SELECT hadm_id, stay_id, charttime, val AS pco2_raw, uom_nospace, valstr, site AS site_co2
  FROM icu_cand WHERE analyte='pco2'
),
icu_pair_win AS (
  SELECT
    p.hadm_id, p.stay_id,
    COALESCE(p.site_ph, c.site_co2) AS site,
    p.charttime AS ph_time, c.charttime AS co2_time,
    p.ph,
    CASE
      WHEN c.uom_nospace='kpa' OR REGEXP_CONTAINS(c.valstr, r'\bkpa\b') THEN 'kpa'
      WHEN c.uom_nospace='mmhg' OR REGEXP_CONTAINS(c.valstr, r'mm\s*hg') THEN 'mmhg'
      ELSE c.uom_nospace
    END AS pco2_uom_norm_raw,
    c.pco2_raw,
    ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, SECOND)) AS dt_sec
  FROM icu_ph p
  JOIN icu_co2 c
    ON c.hadm_id = p.hadm_id
   AND c.stay_id = p.stay_id
   AND (COALESCE(p.site_ph, c.site_co2) IN ('arterial','venous','other'))
   AND ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, MINUTE)) <= 10
  QUALIFY ROW_NUMBER() OVER (
    PARTITION BY p.hadm_id, p.stay_id, p.charttime
    ORDER BY dt_sec
  ) = 1
),
icu_pairs_std AS (
  SELECT
    hadm_id, stay_id, site,
    LEAST(ph_time, co2_time) AS sample_time,
    ph,
    CAST(NULL AS STRING) AS ph_uom,              -- POC pH is unitless/null
    CASE WHEN pco2_uom_norm_raw='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,
    'mmhg' AS pco2_uom_norm
  FROM icu_pair_win
  WHERE (ph BETWEEN 6.3 AND 7.8 OR ph IS NULL)
    AND (CASE WHEN pco2_uom_norm_raw='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200
),
icu_solo_pco2_std AS (
  SELECT
    hadm_id, stay_id, site_co2 AS site,
    charttime AS sample_time,
    CAST(NULL AS FLOAT64) AS ph,
    CAST(NULL AS STRING)  AS ph_uom,            -- no pH here
    CASE WHEN uom_nospace='kpa' OR REGEXP_CONTAINS(valstr, r'\bkpa\b') THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,
    'mmhg' AS pco2_uom_norm
  FROM icu_co2
  WHERE site_co2 IN ('arterial','venous','other')
    AND pco2_raw BETWEEN 5 AND 200
),
icu_all AS (
  SELECT * FROM icu_pairs_std
  UNION ALL
  SELECT * FROM icu_solo_pco2_std
),

poc_abg AS (
  SELECT hadm_id,
         ph            AS poc_abg_ph,
         ph_uom        AS poc_abg_ph_uom,
         pco2_mmHg     AS poc_abg_paco2,
         'mmhg'        AS poc_abg_paco2_uom,
         sample_time   AS poc_abg_time
  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn
        FROM icu_all WHERE site='arterial') WHERE rn=1
),
poc_vbg AS (
  SELECT hadm_id,
         ph            AS poc_vbg_ph,
         ph_uom        AS poc_vbg_ph_uom,
         pco2_mmHg     AS poc_vbg_paco2,
         'mmhg'        AS poc_vbg_paco2_uom,
         sample_time   AS poc_vbg_time
  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn
        FROM icu_all WHERE site='venous') WHERE rn=1
),
poc_other AS (
  SELECT hadm_id,
         ph            AS poc_other_ph,
         ph_uom        AS poc_other_ph_uom,
         pco2_mmHg     AS poc_other_paco2,
         'mmhg'        AS poc_other_paco2_uom,
         sample_time   AS poc_other_time
  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn
        FROM icu_all WHERE site='other') WHERE rn=1
)

/* ---------------- Final one row per hadm ---------------- */
SELECT
  h.hadm_id,
  -- LAB-ABG / LAB-VBG / LAB-OTHER
  la.lab_abg_ph, la.lab_abg_ph_uom, la.lab_abg_paco2, la.lab_abg_paco2_uom, la.lab_abg_time,
  lv.lab_vbg_ph, lv.lab_vbg_ph_uom, lv.lab_vbg_paco2, lv.lab_vbg_paco2_uom, lv.lab_vbg_time,
  lo.lab_other_ph, lo.lab_other_ph_uom, lo.lab_other_paco2, lo.lab_other_paco2_uom, lo.lab_other_time,
  -- POC-ABG / POC-VBG / POC-OTHER
  pa.poc_abg_ph, pa.poc_abg_ph_uom, pa.poc_abg_paco2, pa.poc_abg_paco2_uom, pa.poc_abg_time,
  pv.poc_vbg_ph, pv.poc_vbg_ph_uom, pv.poc_vbg_paco2, pv.poc_vbg_paco2_uom, pv.poc_vbg_time,
  po.poc_other_ph, po.poc_other_ph_uom, po.poc_other_paco2, po.poc_other_paco2_uom, po.poc_other_time,
  -- First ABG across LAB+POC
  (SELECT AS STRUCT src, t, ph, pco2
   FROM (SELECT 'LAB' AS src, la.lab_abg_time AS t, la.lab_abg_ph AS ph, la.lab_abg_paco2 AS pco2
         UNION ALL
         SELECT 'POC', pa.poc_abg_time, pa.poc_abg_ph, pa.poc_abg_paco2)
   WHERE t IS NOT NULL
   ORDER BY t LIMIT 1) AS first_abg,
  -- First VBG across LAB+POC
  (SELECT AS STRUCT src, t, ph, pco2
   FROM (SELECT 'LAB' AS src, lv.lab_vbg_time AS t, lv.lab_vbg_ph AS ph, lv.lab_vbg_paco2 AS pco2
         UNION ALL
         SELECT 'POC', pv.poc_vbg_time, pv.poc_vbg_ph, pv.poc_vbg_paco2)
   WHERE t IS NOT NULL
   ORDER BY t LIMIT 1) AS first_vbg,
  -- First OTHER-source pCO2 across LAB+POC
  (SELECT AS STRUCT src, t, ph, pco2
   FROM (SELECT 'LAB' AS src, lo.lab_other_time AS t, lo.lab_other_ph AS ph, lo.lab_other_paco2 AS pco2
         UNION ALL
         SELECT 'POC', po.poc_other_time, po.poc_other_ph, po.poc_other_paco2)
   WHERE t IS NOT NULL
   ORDER BY t LIMIT 1) AS first_other
FROM hadms h
LEFT JOIN lab_abg la USING (hadm_id)
LEFT JOIN lab_vbg lv USING (hadm_id)
LEFT JOIN lab_other lo USING (hadm_id)
LEFT JOIN poc_abg pa USING (hadm_id)
LEFT JOIN poc_vbg pv USING (hadm_id)
LEFT JOIN poc_other po USING (hadm_id)
"""

bg_pairs = run_sql_bq(bg_pairs_sql, params)

# Flatten STRUCTs for first_abg, first_vbg, and first_other
for col in ["first_abg","first_vbg","first_other"]:
    if col in bg_pairs.columns:
        bg_pairs[f"{col}_src"]  = bg_pairs[col].apply(lambda x: x.get("src") if isinstance(x, dict) else None)
        bg_pairs[f"{col}_time"] = bg_pairs[col].apply(lambda x: x.get("t")   if isinstance(x, dict) else None)
        bg_pairs[f"{col}_ph"]   = bg_pairs[col].apply(lambda x: x.get("ph")  if isinstance(x, dict) else None)
        bg_pairs[f"{col}_pco2"] = bg_pairs[col].apply(lambda x: x.get("pco2")if isinstance(x, dict) else None)
        bg_pairs = bg_pairs.drop(columns=[col])

bg_pairs.head(3)

[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.\n\nparams = {"hadms": hadm_list}\n\nbg_pairs_sql = rf"""\nWITH hadms AS (SELECT hadm_id FROM UNNEST(@hadms) AS hadm_id),\n\n/* ---------------- LAB (HOSP) ---------------- */\nhosp_cand AS (\n  SELECT\n    le.subject_id, le.hadm_id, le.charttime, le.specimen_id,\n    CAST(le.valuenum AS FLOAT64) AS val,\n    LOWER(COALESCE(le.valueuom,\'\')) AS uom,\n    LOWER(di.label) AS lbl,\n    LOWER(COALESCE(di.fluid,\'\')) AS fl,\n    LOWER(COALESCE(di.category,\'\')) AS cat\n  FROM `{PHYS}.{HOSP}.labevents`  le\n  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n  JOIN hadms h ON h.hadm_id = le.hadm_id\n  WHERE le.valuenum IS NOT NULL\n    AND (\n         LOWER(COALESCE(di.category,\'\')) LIKE \'%blood gas%\' OR\n         LOWER(di.label) LIKE \'%pco2%\' OR\n         REGEXP_CONTAINS(LOWER(di.label), r\'\\bph\\b\') OR\n         REGEXP_CONTAINS(LOWER(di.label), r\'\\bpa?\\s*co(?:2|₂)\\b\')\n        )\n    AND NOT REGEXP_CONTAINS(LOWER(di.label), r\'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar)\')\n),\nhosp_spec AS (\n  SELECT le.specimen_id, LOWER(COALESCE(le.value,\'\')) AS spec_val\n  FROM `{PHYS}.{HOSP}.labevents` le\n  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n  WHERE le.specimen_id IS NOT NULL\n    AND REGEXP_CONTAINS(LOWER(di.label), r\'(specimen|sample)\')\n),\nhosp_class AS (\n  SELECT\n    c.hadm_id, c.charttime, c.specimen_id, c.val, c.uom, c.lbl, c.fl,\n    CASE\n      WHEN REGEXP_CONTAINS(c.lbl, r\'\\b(?:blood\\s*)?ph\\b\') THEN \'ph\'\n      WHEN (c.lbl LIKE \'%pco2%\' OR REGEXP_CONTAINS(c.lbl, r\'\\bpa?\\s*co(?:2|₂)\\b\')) THEN \'pco2\'\n      ELSE NULL\n    END AS analyte,\n    CASE\n      WHEN REGEXP_CONTAINS(s.spec_val, r\'arter\') OR REGEXP_CONTAINS(s.spec_val, r\'\\bart\\b\') THEN \'arterial\'\n      WHEN REGEXP_CONTAINS(s.spec_val, r\'ven|mixed|central\') THEN \'venous\'\n      WHEN c.fl LIKE \'%arterial%\' OR REGEXP_CONTAINS(c.lbl, r\'\\b(abg|art|arterial|a[- ]?line)\\b\') THEN \'arterial\'\n      WHEN c.fl LIKE \'%ven%\'      OR REGEXP_CONTAINS(c.lbl, r\'\\b(vbg|ven|venous|mixed|central)\\b\') THEN \'venous\'\n      ELSE \'other\'\n    END AS site\n  FROM hosp_cand c\n  LEFT JOIN hosp_spec s USING (specimen_id)\n),\nhosp_pairs AS (\n  SELECT\n    hadm_id, specimen_id,\n    MIN(charttime) AS sample_time,\n    MAX(IF(analyte=\'ph\',   val, NULL)) AS ph,\n    MAX(IF(analyte=\'pco2\', val, NULL)) AS pco2_raw,\n    (ARRAY_AGG(IF(analyte=\'pco2\', uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS pco2_uom,\n    (ARRAY_AGG(IF(analyte=\'ph\',   uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS ph_uom,\n    (ARRAY_AGG(site IGNORE NULLS LIMIT 1))[OFFSET(0)] AS site\n  FROM hosp_class\n  GROUP BY hadm_id, specimen_id\n  HAVING (ph IS NOT NULL OR pco2_raw IS NOT NULL) AND site IN (\'arterial\',\'venous\',\'other\')\n),\nhosp_pairs_std AS (\n  SELECT\n    hadm_id, specimen_id, sample_time, site,\n    ph, ph_uom,\n    CASE WHEN pco2_uom = \'kpa\' THEN pco2_raw * 7.50062 ELSE pco2_raw END AS pco2_mmHg,\n    \'mmhg\' AS pco2_uom_norm\n  FROM hosp_pairs\n  WHERE (ph IS NULL OR (ph BETWEEN 6.3 AND 7.8))\n    AND (pco2_raw IS NULL OR (CASE WHEN pco2_uom=\'kpa\' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200)\n),\nlab_abg AS (\n  SELECT hadm_id,\n         ph            AS lab_abg_ph,\n         ph_uom        AS lab_abg_ph_uom,\n         pco2_mmHg     AS lab_abg_paco2,\n         \'mmhg\'        AS lab_abg_paco2_uom,\n         sample_time   AS lab_abg_time\n  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n        FROM hosp_pairs_std WHERE site=\'arterial\') WHERE rn=1\n),\nlab_vbg AS (\n  SELECT hadm_id,\n         ph            AS lab_vbg_ph,\n         ph_uom        AS lab_vbg_ph_uom,\n         pco2_mmHg     AS lab_vbg_paco2,\n         \'mmhg\'        AS lab_vbg_paco2_uom,\n         sample_time   AS lab_vbg_time\n  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n        FROM hosp_pairs_std WHERE site=\'venous\') WHERE rn=1\n),\nlab_other AS (\n  SELECT hadm_id,\n         ph            AS lab_other_ph,\n         ph_uom        AS lab_other_ph_uom,\n         pco2_mmHg     AS lab_other_paco2,\n         \'mmhg\'        AS lab_other_paco2_uom,\n         sample_time   AS lab_other_time\n  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n        FROM hosp_pairs_std WHERE site=\'other\') WHERE rn=1\n),\n\n/* ---------------- POC (ICU) ---------------- */\nicu_raw AS (\n  SELECT\n    ie.hadm_id, ce.stay_id, ce.charttime,\n    LOWER(di.label) AS lbl,\n    LOWER(REPLACE(COALESCE(ce.valueuom,\'\'),\' \',\'\')) AS uom_nospace,\n    LOWER(COALESCE(ce.value,\'\')) AS valstr,\n    COALESCE(\n      CAST(ce.valuenum AS FLOAT64),\n      SAFE_CAST(REGEXP_EXTRACT(LOWER(ce.value), r\'(-?\\d+(?:\\.\\d+)?)\') AS FLOAT64)\n    ) AS val\n  FROM `{PHYS}.{ICU}.chartevents` ce\n  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n  JOIN hadms h ON h.hadm_id = ie.hadm_id\n),\nicu_cand AS (\n  SELECT\n    hadm_id, stay_id, charttime, lbl, uom_nospace, valstr, val,\n    CASE\n      WHEN REGEXP_CONTAINS(lbl, r\'(^|[^a-z])ph([^a-z]|$)\') OR (val BETWEEN 6.3 AND 7.8) THEN \'ph\'\n      WHEN (\n             REGEXP_CONTAINS(lbl, r\'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)\')\n             OR uom_nospace IN (\'mmhg\',\'kpa\')\n             OR REGEXP_CONTAINS(valstr, r\'\\b(mm\\s*hg|kpa)\\b\')\n           )\n           AND NOT REGEXP_CONTAINS(lbl, r\'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))\')\n      THEN \'pco2\'\n      ELSE NULL\n    END AS analyte,\n    CASE\n      WHEN REGEXP_CONTAINS(lbl, r\'\\b(abg|art|arterial|a[- ]?line)\\b\') THEN \'arterial\'\n      WHEN REGEXP_CONTAINS(lbl, r\'\\b(vbg|ven|venous|mixed|central)\\b\') THEN \'venous\'\n      ELSE \'other\'\n    END AS site\n  FROM icu_raw\n  WHERE val IS NOT NULL\n    AND (\n      REGEXP_CONTAINS(lbl, r\'(^|[^a-z])ph([^a-z]|$)\') OR\n      REGEXP_CONTAINS(lbl, r\'(^|[^a-z])p(?:a)?\\s*co\\s*(?:2|₂)([^a-z]|$)\') OR\n      uom_nospace IN (\'mmhg\',\'kpa\') OR\n      REGEXP_CONTAINS(valstr, r\'\\b(mm\\s*hg|kpa)\\b\')\n    )\n    AND NOT REGEXP_CONTAINS(lbl, r\'(et\\s*co2|end[- ]?tidal|t\\s*co2|tco2|total\\s*co2|hco3|bicar|v\\s*co2|vco2|co2\\s*(prod|elimin|production|elimination))\')\n),\nicu_ph AS (\n  SELECT hadm_id, stay_id, charttime, val AS ph, site AS site_ph\n  FROM icu_cand WHERE analyte=\'ph\'\n),\nicu_co2 AS (\n  SELECT hadm_id, stay_id, charttime, val AS pco2_raw, uom_nospace, valstr, site AS site_co2\n  FROM icu_cand WHERE analyte=\'pco2\'\n),\nicu_pair_win AS (\n  SELECT\n    p.hadm_id, p.stay_id,\n    COALESCE(p.site_ph, c.site_co2) AS site,\n    p.charttime AS ph_time, c.charttime AS co2_time,\n    p.ph,\n    CASE\n      WHEN c.uom_nospace=\'kpa\' OR REGEXP_CONTAINS(c.valstr, r\'\\bkpa\\b\') THEN \'kpa\'\n      WHEN c.uom_nospace=\'mmhg\' OR REGEXP_CONTAINS(c.valstr, r\'mm\\s*hg\') THEN \'mmhg\'\n      ELSE c.uom_nospace\n    END AS pco2_uom_norm_raw,\n    c.pco2_raw,\n    ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, SECOND)) AS dt_sec\n  FROM icu_ph p\n  JOIN icu_co2 c\n    ON c.hadm_id = p.hadm_id\n   AND c.stay_id = p.stay_id\n   AND (COALESCE(p.site_ph, c.site_co2) IN (\'arterial\',\'venous\',\'other\'))\n   AND ABS(TIMESTAMP_DIFF(c.charttime, p.charttime, MINUTE)) <= 10\n  QUALIFY ROW_NUMBER() OVER (\n    PARTITION BY p.hadm_id, p.stay_id, p.charttime\n    ORDER BY dt_sec\n  ) = 1\n),\nicu_pairs_std AS (\n  SELECT\n    hadm_id, stay_id, site,\n    LEAST(ph_time, co2_time) AS sample_time,\n    ph,\n    CAST(NULL AS STRING) AS ph_uom,              -- POC pH is unitless/null\n    CASE WHEN pco2_uom_norm_raw=\'kpa\' THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n    \'mmhg\' AS pco2_uom_norm\n  FROM icu_pair_win\n  WHERE (ph BETWEEN 6.3 AND 7.8 OR ph IS NULL)\n    AND (CASE WHEN pco2_uom_norm_raw=\'kpa\' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200\n),\nicu_solo_pco2_std AS (\n  SELECT\n    hadm_id, stay_id, site_co2 AS site,\n    charttime AS sample_time,\n    CAST(NULL AS FLOAT64) AS ph,\n    CAST(NULL AS STRING)  AS ph_uom,            -- no pH here\n    CASE WHEN uom_nospace=\'kpa\' OR REGEXP_CONTAINS(valstr, r\'\\bkpa\\b\') THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n    \'mmhg\' AS pco2_uom_norm\n  FROM icu_co2\n  WHERE site_co2 IN (\'arterial\',\'venous\',\'other\')\n    AND pco2_raw BETWEEN 5 AND 200\n),\nicu_all AS (\n  SELECT * FROM icu_pairs_std\n  UNION ALL\n  SELECT * FROM icu_solo_pco2_std\n),\n\npoc_abg AS (\n  SELECT hadm_id,\n         ph            AS poc_abg_ph,\n         ph_uom        AS poc_abg_ph_uom,\n         pco2_mmHg     AS poc_abg_paco2,\n         \'mmhg\'        AS poc_abg_paco2_uom,\n         sample_time   AS poc_abg_time\n  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n        FROM icu_all WHERE site=\'arterial\') WHERE rn=1\n),\npoc_vbg AS (\n  SELECT hadm_id,\n         ph            AS poc_vbg_ph,\n         ph_uom        AS poc_vbg_ph_uom,\n         pco2_mmHg     AS poc_vbg_paco2,\n         \'mmhg\'        AS poc_vbg_paco2_uom,\n         sample_time   AS poc_vbg_time\n  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n        FROM icu_all WHERE site=\'venous\') WHERE rn=1\n),\npoc_other AS (\n  SELECT hadm_id,\n         ph            AS poc_other_ph,\n         ph_uom        AS poc_other_ph_uom,\n         pco2_mmHg     AS poc_other_paco2,\n         \'mmhg\'        AS poc_other_paco2_uom,\n         sample_time   AS poc_other_time\n  FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n        FROM icu_all WHERE site=\'other\') WHERE rn=1\n)\n\n/* ---------------- Final one row per hadm ---------------- */\nSELECT\n  h.hadm_id,\n  -- LAB-ABG / LAB-VBG / LAB-OTHER\n  la.lab_abg_ph, la.lab_abg_ph_uom, la.lab_abg_paco2, la.lab_abg_paco2_uom, la.lab_abg_time,\n  lv.lab_vbg_ph, lv.lab_vbg_ph_uom, lv.lab_vbg_paco2, lv.lab_vbg_paco2_uom, lv.lab_vbg_time,\n  lo.lab_other_ph, lo.lab_other_ph_uom, lo.lab_other_paco2, lo.lab_other_paco2_uom, lo.lab_other_time,\n  -- POC-ABG / POC-VBG / POC-OTHER\n  pa.poc_abg_ph, pa.poc_abg_ph_uom, pa.poc_abg_paco2, pa.poc_abg_paco2_uom, pa.poc_abg_time,\n  pv.poc_vbg_ph, pv.poc_vbg_ph_uom, pv.poc_vbg_paco2, pv.poc_vbg_paco2_uom, pv.poc_vbg_time,\n  po.poc_other_ph, po.poc_other_ph_uom, po.poc_other_paco2, po.poc_other_paco2_uom, po.poc_other_time,\n  -- First ABG across LAB+POC\n  (SELECT AS STRUCT src, t, ph, pco2\n   FROM (SELECT \'LAB\' AS src, la.lab_abg_time AS t, la.lab_abg_ph AS ph, la.lab_abg_paco2 AS pco2\n         UNION ALL\n         SELECT \'POC\', pa.poc_abg_time, pa.poc_abg_ph, pa.poc_abg_paco2)\n   WHERE t IS NOT NULL\n   ORDER BY t LIMIT 1) AS first_abg,\n  -- First VBG across LAB+POC\n  (SELECT AS STRUCT src, t, ph, pco2\n   FROM (SELECT \'LAB\' AS src, lv.lab_vbg_time AS t, lv.lab_vbg_ph AS ph, lv.lab_vbg_paco2 AS pco2\n         UNION ALL\n         SELECT \'POC\', pv.poc_vbg_time, pv.poc_vbg_ph, pv.poc_vbg_paco2)\n   WHERE t IS NOT NULL\n   ORDER BY t LIMIT 1) AS first_vbg,\n  -- First OTHER-source pCO2 across LAB+POC\n  (SELECT AS STRUCT src, t, ph, pco2\n   FROM (SELECT \'LAB\' AS src, lo.lab_other_time AS t, lo.lab_other_ph AS ph, lo.lab_other_paco2 AS pco2\n         UNION ALL\n         SELECT \'POC\', po.poc_other_time, po.poc_other_ph, po.poc_other_paco2)\n   WHERE t IS NOT NULL\n   ORDER BY t LIMIT 1) AS first_other\nFROM hadms h\nLEFT JOIN lab_abg la USING (hadm_id)\nLEFT JOIN lab_vbg lv USING (hadm_id)\nLEFT JOIN lab_other lo USING (hadm_id)\nLEFT JOIN poc_abg pa USING (hadm_id)\nLEFT JOIN poc_vbg pv USING (hadm_id)\nLEFT JOIN poc_other po USING (hadm_id)\n"""\n\nbg_pairs = run_sql_bq(bg_pairs_sql, params)\n\n# Flatten STRUCTs for first_abg, first_vbg, and first_other\nfor col in ["first_abg","first_vbg","first_other"]:\n    if col in bg_pairs.columns:\n        bg_pairs[f"{col}_src"]  = bg_pairs[col].apply(lambda x: x.get("src") if isinstance(x, dict) else None)\n        bg_pairs[f"{col}_time"] = bg_pairs[col].apply(lambda x: x.get("t")   if isinstance(x, dict) else None)\n        bg_pairs[f"{col}_ph"]   = bg_pairs[col].apply(lambda x: x.get("ph")  if isinstance(x, dict) else None)\n        bg_pairs[f"{col}_pco2"] = bg_pairs[col].apply(lambda x: x.get("pco2")if isinstance(x, dict) else None)\n        bg_pairs = bg_pairs.drop(columns=[col])\n\nbg_pairs.head(3)\n', 'execution_count': 8}
[NbConvertApp] msg_type: execute_result
[NbConvertApp] content: {'data': {'text/plain': '    hadm_id  lab_abg_ph lab_abg_ph_uom  lab_abg_paco2 lab_abg_paco2_uom  \\\n0  20000094         NaN           None            NaN              None   \n1  20000147        7.41          units           35.0              mmhg   \n2  20000235        7.45          units           43.0              mmhg   \n\n         lab_abg_time  lab_vbg_ph lab_vbg_ph_uom  lab_vbg_paco2  \\\n0                 NaT        7.41          units           47.0   \n1 2121-08-30 17:38:00         NaN           None            NaN   \n2 2139-11-27 11:46:00         NaN           None            NaN   \n\n  lab_vbg_paco2_uom  ... first_abg_ph  first_abg_pco2 first_vbg_src  \\\n0              mmhg  ...          NaN             NaN           LAB   \n1              None  ...         7.41            35.0           POC   \n2              None  ...         7.45            43.0          None   \n\n       first_vbg_time first_vbg_ph first_vbg_pco2  first_other_src  \\\n0 2150-03-02 15:53:00         7.41           47.0              POC   \n1 2121-08-30 22:00:00          NaN           20.0              POC   \n2                 NaT          NaN            NaN              LAB   \n\n     first_other_time  first_other_ph first_other_pco2  \n0 2150-03-02 15:21:00             NaN             41.0  \n1 2121-08-31 15:05:00             NaN             78.0  \n2 2139-11-13 06:35:00             7.0              NaN  \n\n[3 rows x 43 columns]', 'text/html': '<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hadm_id</th>\n      <th>lab_abg_ph</th>\n      <th>lab_abg_ph_uom</th>\n      <th>lab_abg_paco2</th>\n      <th>lab_abg_paco2_uom</th>\n      <th>lab_abg_time</th>\n      <th>lab_vbg_ph</th>\n      <th>lab_vbg_ph_uom</th>\n      <th>lab_vbg_paco2</th>\n      <th>lab_vbg_paco2_uom</th>\n      <th>...</th>\n      <th>first_abg_ph</th>\n      <th>first_abg_pco2</th>\n      <th>first_vbg_src</th>\n      <th>first_vbg_time</th>\n      <th>first_vbg_ph</th>\n      <th>first_vbg_pco2</th>\n      <th>first_other_src</th>\n      <th>first_other_time</th>\n      <th>first_other_ph</th>\n      <th>first_other_pco2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000094</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>7.41</td>\n      <td>units</td>\n      <td>47.0</td>\n      <td>mmhg</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LAB</td>\n      <td>2150-03-02 15:53:00</td>\n      <td>7.41</td>\n      <td>47.0</td>\n      <td>POC</td>\n      <td>2150-03-02 15:21:00</td>\n      <td>NaN</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20000147</td>\n      <td>7.41</td>\n      <td>units</td>\n      <td>35.0</td>\n      <td>mmhg</td>\n      <td>2121-08-30 17:38:00</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>...</td>\n      <td>7.41</td>\n      <td>35.0</td>\n      <td>POC</td>\n      <td>2121-08-30 22:00:00</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>POC</td>\n      <td>2121-08-31 15:05:00</td>\n      <td>NaN</td>\n      <td>78.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000235</td>\n      <td>7.45</td>\n      <td>units</td>\n      <td>43.0</td>\n      <td>mmhg</td>\n      <td>2139-11-27 11:46:00</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>...</td>\n      <td>7.45</td>\n      <td>43.0</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>LAB</td>\n      <td>2139-11-13 06:35:00</td>\n      <td>7.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 43 columns</p>\n</div>'}, 'metadata': {}, 'execution_count': 8}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 25
[NbConvertApp] Skipping non-executing cell 26
[NbConvertApp] Executing cell:
# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.


SQL["demo_sql"] = f"""
WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)
SELECT
  a.hadm_id,
  a.subject_id,
  a.admittime,
  a.dischtime,
  a.deathtime,
  a.admission_type,
  a.admission_location,
  a.discharge_location,
  a.insurance,
  -- LOS (days)
  TIMESTAMP_DIFF(a.dischtime, a.admittime, HOUR) / 24.0 AS hosp_los_days,
  -- in-hospital death
  IF(a.deathtime IS NOT NULL, 1, 0) AS death_in_hosp,
  -- demographics
  p.gender,
  SAFE_CAST(ROUND(p.anchor_age + (EXTRACT(YEAR FROM a.admittime) - p.anchor_year), 1) AS FLOAT64) AS age_at_admit,
  -- 30-day all-cause mortality from admission
  IF(p.dod IS NOT NULL AND DATE_DIFF(DATE(p.dod), DATE(a.admittime), DAY) BETWEEN 0 AND 30, 1, 0) AS death_30d
FROM `{PHYS}.{HOSP}.admissions` a
JOIN hadms h USING (hadm_id)
JOIN `{PHYS}.{HOSP}.patients` p USING (subject_id)
"""
demo = run_sql_bq(sql("demo_sql"), {"hadms": hadm_list})
print("Demo rows:", len(demo))
demo.head(3)


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.\n\n\nSQL["demo_sql"] = f"""\nWITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x)\nSELECT\n  a.hadm_id,\n  a.subject_id,\n  a.admittime,\n  a.dischtime,\n  a.deathtime,\n  a.admission_type,\n  a.admission_location,\n  a.discharge_location,\n  a.insurance,\n  -- LOS (days)\n  TIMESTAMP_DIFF(a.dischtime, a.admittime, HOUR) / 24.0 AS hosp_los_days,\n  -- in-hospital death\n  IF(a.deathtime IS NOT NULL, 1, 0) AS death_in_hosp,\n  -- demographics\n  p.gender,\n  SAFE_CAST(ROUND(p.anchor_age + (EXTRACT(YEAR FROM a.admittime) - p.anchor_year), 1) AS FLOAT64) AS age_at_admit,\n  -- 30-day all-cause mortality from admission\n  IF(p.dod IS NOT NULL AND DATE_DIFF(DATE(p.dod), DATE(a.admittime), DAY) BETWEEN 0 AND 30, 1, 0) AS death_30d\nFROM `{PHYS}.{HOSP}.admissions` a\nJOIN hadms h USING (hadm_id)\nJOIN `{PHYS}.{HOSP}.patients` p USING (subject_id)\n"""\ndemo = run_sql_bq(sql("demo_sql"), {"hadms": hadm_list})\nprint("Demo rows:", len(demo))\ndemo.head(3)\n\n', 'execution_count': 9}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'Demo rows: 115179\n'}
[NbConvertApp] msg_type: execute_result
[NbConvertApp] content: {'data': {'text/plain': '    hadm_id  subject_id           admittime           dischtime  \\\n0  26713233    10106244 2147-05-09 10:34:00 2147-05-12 13:43:00   \n1  27961368    15443666 2168-12-30 23:30:00 2169-01-05 16:02:00   \n2  23485217    10584718 2165-02-12 15:41:00 2165-03-06 08:20:00   \n\n            deathtime     admission_type  \\\n0                 NaT       DIRECT EMER.   \n1                 NaT  OBSERVATION ADMIT   \n2 2165-03-06 08:20:00           EW EMER.   \n\n                       admission_location discharge_location insurance  \\\n0                      PHYSICIAN REFERRAL               HOME   Private   \n1                          EMERGENCY ROOM   HOME HEALTH CARE  Medicare   \n2  TRANSFER FROM SKILLED NURSING FACILITY               DIED  Medicare   \n\n   hosp_los_days  death_in_hosp gender  age_at_admit  death_30d  \n0       3.125000              0      F          63.0          0  \n1       5.708333              0      F          76.0          0  \n2      21.708333              1      M          78.0          1  ', 'text/html': '<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hadm_id</th>\n      <th>subject_id</th>\n      <th>admittime</th>\n      <th>dischtime</th>\n      <th>deathtime</th>\n      <th>admission_type</th>\n      <th>admission_location</th>\n      <th>discharge_location</th>\n      <th>insurance</th>\n      <th>hosp_los_days</th>\n      <th>death_in_hosp</th>\n      <th>gender</th>\n      <th>age_at_admit</th>\n      <th>death_30d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26713233</td>\n      <td>10106244</td>\n      <td>2147-05-09 10:34:00</td>\n      <td>2147-05-12 13:43:00</td>\n      <td>NaT</td>\n      <td>DIRECT EMER.</td>\n      <td>PHYSICIAN REFERRAL</td>\n      <td>HOME</td>\n      <td>Private</td>\n      <td>3.125000</td>\n      <td>0</td>\n      <td>F</td>\n      <td>63.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27961368</td>\n      <td>15443666</td>\n      <td>2168-12-30 23:30:00</td>\n      <td>2169-01-05 16:02:00</td>\n      <td>NaT</td>\n      <td>OBSERVATION ADMIT</td>\n      <td>EMERGENCY ROOM</td>\n      <td>HOME HEALTH CARE</td>\n      <td>Medicare</td>\n      <td>5.708333</td>\n      <td>0</td>\n      <td>F</td>\n      <td>76.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23485217</td>\n      <td>10584718</td>\n      <td>2165-02-12 15:41:00</td>\n      <td>2165-03-06 08:20:00</td>\n      <td>2165-03-06 08:20:00</td>\n      <td>EW EMER.</td>\n      <td>TRANSFER FROM SKILLED NURSING FACILITY</td>\n      <td>DIED</td>\n      <td>Medicare</td>\n      <td>21.708333</td>\n      <td>1</td>\n      <td>M</td>\n      <td>78.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>'}, 'metadata': {}, 'execution_count': 9}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Executing cell:
# Purpose: Create reusable data-quality and merge guardrail helpers to prevent silent join errors.

# ==== Drop-in: safe merge utilities (one cell, run once) ====
import pandas as pd
from typing import Iterable, Optional, Literal

def _ensure_Int64(s: pd.Series) -> pd.Series:
    """Coerce to pandas nullable Int64 (preserves NA)."""
    return pd.to_numeric(s, errors="coerce").astype("Int64")

def strip_subject_cols(fr: pd.DataFrame) -> pd.DataFrame:
    """Remove any subject_id-like columns from a frame (e.g., 'subject_id', 'Subject_ID')."""
    return fr.drop(columns=[c for c in fr.columns if c.lower().startswith("subject_id")],
                   errors="ignore")

def safe_merge_on_hadm(
    left: pd.DataFrame,
    right: pd.DataFrame,
    *,
    right_name: str,
    take: Optional[Iterable[str]] = None,
    order_by: Optional[Iterable[str]] = None,
    check_subject: Literal[False, "warn", "raise"] = False,
) -> pd.DataFrame:
    """
    Left-merge 'right' into 'left' on hadm_id, returning a copy of left with right's columns.
    - Dedupes right on hadm_id (optionally using order_by to pick the first row).
    - Optionally restricts right columns via `take`.
    - Optionally audits subject_id agreement before dropping subject_id from right.
    - Always strips subject_id-like columns from the right to prevent *_x/_y suffixes.
    - Raises if any *_x/_y suffixes still appear (indicates overlapping names besides hadm_id).
    """
    if "hadm_id" not in left.columns:
        raise KeyError(f"left frame lacks hadm_id before merging {right_name}")
    if "hadm_id" not in right.columns:
        raise KeyError(f"{right_name} lacks hadm_id")

    L = left.copy()
    R = right.copy()

    # Standardize dtypes of keys
    L["hadm_id"] = _ensure_Int64(L["hadm_id"])
    R["hadm_id"] = _ensure_Int64(R["hadm_id"])
    if "subject_id" in L.columns:
        L["subject_id"] = _ensure_Int64(L["subject_id"])
    if "subject_id" in R.columns:
        R["subject_id"] = _ensure_Int64(R["subject_id"])

    # Dedupe RIGHT by hadm_id (optionally order_by first)
    if order_by:
        R = (R.sort_values(list(order_by))
               .drop_duplicates(subset=["hadm_id"], keep="first"))
    else:
        R = R.drop_duplicates(subset=["hadm_id"], keep="first")

    # Optional subject_id consistency audit (before stripping)
    if check_subject and ("subject_id" in L.columns) and ("subject_id" in R.columns):
        # Join only on hadm_id where both sides have subject_id
        tmp = (L[["hadm_id", "subject_id"]]
                 .merge(R[["hadm_id", "subject_id"]],
                        on="hadm_id", how="inner", suffixes=("_L","_R")))
        mism = (tmp["subject_id_L"].notna() & tmp["subject_id_R"].notna() &
                (tmp["subject_id_L"] != tmp["subject_id_R"]))
        n_mism = int(mism.sum())
        if n_mism > 0:
            sample_ids = tmp.loc[mism, "hadm_id"].head(10).tolist()
            msg = (f"[{right_name}] subject_id mismatch on {n_mism} hadm_id(s). "
                   f"Examples: {sample_ids}")
            if check_subject == "raise":
                raise ValueError(msg)
            else:
                print("WARNING:", msg)

    # Limit right columns (avoid accidental overlaps)
    if take is not None:
        keep = ["hadm_id"] + [c for c in take if c != "hadm_id"]
        R = R[[c for c in keep if c in R.columns]]

    # Always strip subject_id-like columns from right to prevent *_x/_y
    R = strip_subject_cols(R)

    # Final merge
    out = L.merge(R, on="hadm_id", how="left", suffixes=("", ""))

    # Guard: no suffixes should be present
    bad = [c for c in out.columns if c.endswith("_x") or c.endswith("_y")]
    if bad:
        raise RuntimeError(
            f"Merge with {right_name} produced suffixed columns {bad}. "
            "You likely have overlapping column names other than hadm_id."
        )
    return out

print("Safe merge helpers loaded.")

[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Create reusable data-quality and merge guardrail helpers to prevent silent join errors.\n\n# ==== Drop-in: safe merge utilities (one cell, run once) ====\nimport pandas as pd\nfrom typing import Iterable, Optional, Literal\n\ndef _ensure_Int64(s: pd.Series) -> pd.Series:\n    """Coerce to pandas nullable Int64 (preserves NA)."""\n    return pd.to_numeric(s, errors="coerce").astype("Int64")\n\ndef strip_subject_cols(fr: pd.DataFrame) -> pd.DataFrame:\n    """Remove any subject_id-like columns from a frame (e.g., \'subject_id\', \'Subject_ID\')."""\n    return fr.drop(columns=[c for c in fr.columns if c.lower().startswith("subject_id")],\n                   errors="ignore")\n\ndef safe_merge_on_hadm(\n    left: pd.DataFrame,\n    right: pd.DataFrame,\n    *,\n    right_name: str,\n    take: Optional[Iterable[str]] = None,\n    order_by: Optional[Iterable[str]] = None,\n    check_subject: Literal[False, "warn", "raise"] = False,\n) -> pd.DataFrame:\n    """\n    Left-merge \'right\' into \'left\' on hadm_id, returning a copy of left with right\'s columns.\n    - Dedupes right on hadm_id (optionally using order_by to pick the first row).\n    - Optionally restricts right columns via `take`.\n    - Optionally audits subject_id agreement before dropping subject_id from right.\n    - Always strips subject_id-like columns from the right to prevent *_x/_y suffixes.\n    - Raises if any *_x/_y suffixes still appear (indicates overlapping names besides hadm_id).\n    """\n    if "hadm_id" not in left.columns:\n        raise KeyError(f"left frame lacks hadm_id before merging {right_name}")\n    if "hadm_id" not in right.columns:\n        raise KeyError(f"{right_name} lacks hadm_id")\n\n    L = left.copy()\n    R = right.copy()\n\n    # Standardize dtypes of keys\n    L["hadm_id"] = _ensure_Int64(L["hadm_id"])\n    R["hadm_id"] = _ensure_Int64(R["hadm_id"])\n    if "subject_id" in L.columns:\n        L["subject_id"] = _ensure_Int64(L["subject_id"])\n    if "subject_id" in R.columns:\n        R["subject_id"] = _ensure_Int64(R["subject_id"])\n\n    # Dedupe RIGHT by hadm_id (optionally order_by first)\n    if order_by:\n        R = (R.sort_values(list(order_by))\n               .drop_duplicates(subset=["hadm_id"], keep="first"))\n    else:\n        R = R.drop_duplicates(subset=["hadm_id"], keep="first")\n\n    # Optional subject_id consistency audit (before stripping)\n    if check_subject and ("subject_id" in L.columns) and ("subject_id" in R.columns):\n        # Join only on hadm_id where both sides have subject_id\n        tmp = (L[["hadm_id", "subject_id"]]\n                 .merge(R[["hadm_id", "subject_id"]],\n                        on="hadm_id", how="inner", suffixes=("_L","_R")))\n        mism = (tmp["subject_id_L"].notna() & tmp["subject_id_R"].notna() &\n                (tmp["subject_id_L"] != tmp["subject_id_R"]))\n        n_mism = int(mism.sum())\n        if n_mism > 0:\n            sample_ids = tmp.loc[mism, "hadm_id"].head(10).tolist()\n            msg = (f"[{right_name}] subject_id mismatch on {n_mism} hadm_id(s). "\n                   f"Examples: {sample_ids}")\n            if check_subject == "raise":\n                raise ValueError(msg)\n            else:\n                print("WARNING:", msg)\n\n    # Limit right columns (avoid accidental overlaps)\n    if take is not None:\n        keep = ["hadm_id"] + [c for c in take if c != "hadm_id"]\n        R = R[[c for c in keep if c in R.columns]]\n\n    # Always strip subject_id-like columns from right to prevent *_x/_y\n    R = strip_subject_cols(R)\n\n    # Final merge\n    out = L.merge(R, on="hadm_id", how="left", suffixes=("", ""))\n\n    # Guard: no suffixes should be present\n    bad = [c for c in out.columns if c.endswith("_x") or c.endswith("_y")]\n    if bad:\n        raise RuntimeError(\n            f"Merge with {right_name} produced suffixed columns {bad}. "\n            "You likely have overlapping column names other than hadm_id."\n        )\n    return out\n\nprint("Safe merge helpers loaded.")\n', 'execution_count': 10}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'Safe merge helpers loaded.\n'}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 29
[NbConvertApp] Skipping non-executing cell 30
[NbConvertApp] Executing cell:
# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.

race_eth_sql = rf"""
WITH hadms AS (
  SELECT x AS hadm_id
  FROM UNNEST(@hadms) AS x
),

-- Hospital admission "race" text
hosp AS (
  SELECT a.hadm_id, LOWER(TRIM(a.race)) AS race_hosp_raw
  FROM `{PHYS}.{HOSP}.admissions` a
  JOIN hadms hm USING (hadm_id)
),

-- Earliest ED stay leading to the admission; take its "race" text if present
ed_first AS (
  SELECT
    e.hadm_id,
    (ARRAY_AGG(STRUCT(e.intime AS intime, LOWER(TRIM(e.race)) AS race_ed_raw)
               ORDER BY e.intime ASC LIMIT 1))[OFFSET(0)] AS pick
  FROM `{PHYS}.{ED}.edstays` e
  JOIN hadms hm USING (hadm_id)
  GROUP BY e.hadm_id
),
ed AS (
  SELECT hadm_id, pick.race_ed_raw
  FROM ed_first
),

-- Combine ED + Hospital for maximum coverage
comb AS (
  SELECT
    hm.hadm_id,
    ho.race_hosp_raw,
    ed.race_ed_raw,
    TRIM(REGEXP_REPLACE(CONCAT(COALESCE(ho.race_hosp_raw,''), ' ', COALESCE(ed.race_ed_raw,'')), r'\s+', ' ')) AS race_text_any
  FROM hadms hm
  LEFT JOIN hosp ho USING (hadm_id)
  LEFT JOIN ed   ed USING (hadm_id)
),

-- Tokenization to OMB families + Hispanic ethnicity
tok AS (
  SELECT
    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,

    -- Ethnicity (Hispanic)
    REGEXP_CONTAINS(race_text_any, r'\b(hispanic|latinx|latino|latina)\b') AS is_hisp,

    -- Race families (use boundaries to reduce false positives)
    REGEXP_CONTAINS(race_text_any, r'american\s+indian|\balaska\b') AS is_aian,
    REGEXP_CONTAINS(race_text_any, r'\basian\b') AS is_asian,
    REGEXP_CONTAINS(race_text_any, r'\b(black|african\s+american)\b') AS is_black,
    REGEXP_CONTAINS(race_text_any, r'hawaiian|pacific\s+islander') AS is_nhopi,
    REGEXP_CONTAINS(race_text_any, r'\bwhite\b|caucasian') AS is_white,

    -- Unknown/other indicators
    REGEXP_CONTAINS(race_text_any, r'unknown|other|declined|unable|not\s+reported|missing|null') AS is_unknown_any,

    -- Multi-race hints
    REGEXP_CONTAINS(race_text_any, r'(two|2)\s+or\s+more|multi|biracial|multiracial') AS is_multi_hint
  FROM comb
),

-- Decide ethnicity per NIH
ethn AS (
  SELECT
    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,
    CASE
      WHEN is_hisp THEN 'Hispanic or Latino'
      WHEN (race_text_any IS NULL OR race_text_any = '' OR is_unknown_any) THEN 'Unknown or Not Reported'
      ELSE 'Not Hispanic or Latino'
    END AS nih_ethnicity,
    (CAST(is_aian AS INT64) + CAST(is_asian AS INT64) + CAST(is_black AS INT64)
     + CAST(is_nhopi AS INT64) + CAST(is_white AS INT64)) AS race_hits,
    is_aian, is_asian, is_black, is_nhopi, is_white, is_multi_hint, is_unknown_any
  FROM tok
),

-- Decide race per NIH/OMB (1997)
race_assign AS (
  SELECT
    hadm_id, race_hosp_raw, race_ed_raw, race_text_any, nih_ethnicity,
    CASE
      WHEN race_hits >= 2 OR is_multi_hint THEN 'More than one race'
      WHEN is_aian THEN 'American Indian or Alaska Native'
      WHEN is_asian THEN 'Asian'
      WHEN is_black THEN 'Black or African American'
      WHEN is_nhopi THEN 'Native Hawaiian or Other Pacific Islander'
      WHEN is_white THEN 'White'
      WHEN is_unknown_any OR race_text_any IS NULL OR race_text_any = '' THEN 'Unknown or Not Reported'
      ELSE 'Unknown or Not Reported'
    END AS nih_race
  FROM ethn
)

SELECT hadm_id, race_hosp_raw, race_ed_raw, nih_race, nih_ethnicity
FROM race_assign
"""
race_eth = run_sql_bq(race_eth_sql, {"hadms": hadm_list})
print("Race/Eth rows:", len(race_eth))
race_eth.head(3)


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.\n\nrace_eth_sql = rf"""\nWITH hadms AS (\n  SELECT x AS hadm_id\n  FROM UNNEST(@hadms) AS x\n),\n\n-- Hospital admission "race" text\nhosp AS (\n  SELECT a.hadm_id, LOWER(TRIM(a.race)) AS race_hosp_raw\n  FROM `{PHYS}.{HOSP}.admissions` a\n  JOIN hadms hm USING (hadm_id)\n),\n\n-- Earliest ED stay leading to the admission; take its "race" text if present\ned_first AS (\n  SELECT\n    e.hadm_id,\n    (ARRAY_AGG(STRUCT(e.intime AS intime, LOWER(TRIM(e.race)) AS race_ed_raw)\n               ORDER BY e.intime ASC LIMIT 1))[OFFSET(0)] AS pick\n  FROM `{PHYS}.{ED}.edstays` e\n  JOIN hadms hm USING (hadm_id)\n  GROUP BY e.hadm_id\n),\ned AS (\n  SELECT hadm_id, pick.race_ed_raw\n  FROM ed_first\n),\n\n-- Combine ED + Hospital for maximum coverage\ncomb AS (\n  SELECT\n    hm.hadm_id,\n    ho.race_hosp_raw,\n    ed.race_ed_raw,\n    TRIM(REGEXP_REPLACE(CONCAT(COALESCE(ho.race_hosp_raw,\'\'), \' \', COALESCE(ed.race_ed_raw,\'\')), r\'\\s+\', \' \')) AS race_text_any\n  FROM hadms hm\n  LEFT JOIN hosp ho USING (hadm_id)\n  LEFT JOIN ed   ed USING (hadm_id)\n),\n\n-- Tokenization to OMB families + Hispanic ethnicity\ntok AS (\n  SELECT\n    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,\n\n    -- Ethnicity (Hispanic)\n    REGEXP_CONTAINS(race_text_any, r\'\\b(hispanic|latinx|latino|latina)\\b\') AS is_hisp,\n\n    -- Race families (use boundaries to reduce false positives)\n    REGEXP_CONTAINS(race_text_any, r\'american\\s+indian|\\balaska\\b\') AS is_aian,\n    REGEXP_CONTAINS(race_text_any, r\'\\basian\\b\') AS is_asian,\n    REGEXP_CONTAINS(race_text_any, r\'\\b(black|african\\s+american)\\b\') AS is_black,\n    REGEXP_CONTAINS(race_text_any, r\'hawaiian|pacific\\s+islander\') AS is_nhopi,\n    REGEXP_CONTAINS(race_text_any, r\'\\bwhite\\b|caucasian\') AS is_white,\n\n    -- Unknown/other indicators\n    REGEXP_CONTAINS(race_text_any, r\'unknown|other|declined|unable|not\\s+reported|missing|null\') AS is_unknown_any,\n\n    -- Multi-race hints\n    REGEXP_CONTAINS(race_text_any, r\'(two|2)\\s+or\\s+more|multi|biracial|multiracial\') AS is_multi_hint\n  FROM comb\n),\n\n-- Decide ethnicity per NIH\nethn AS (\n  SELECT\n    hadm_id, race_hosp_raw, race_ed_raw, race_text_any,\n    CASE\n      WHEN is_hisp THEN \'Hispanic or Latino\'\n      WHEN (race_text_any IS NULL OR race_text_any = \'\' OR is_unknown_any) THEN \'Unknown or Not Reported\'\n      ELSE \'Not Hispanic or Latino\'\n    END AS nih_ethnicity,\n    (CAST(is_aian AS INT64) + CAST(is_asian AS INT64) + CAST(is_black AS INT64)\n     + CAST(is_nhopi AS INT64) + CAST(is_white AS INT64)) AS race_hits,\n    is_aian, is_asian, is_black, is_nhopi, is_white, is_multi_hint, is_unknown_any\n  FROM tok\n),\n\n-- Decide race per NIH/OMB (1997)\nrace_assign AS (\n  SELECT\n    hadm_id, race_hosp_raw, race_ed_raw, race_text_any, nih_ethnicity,\n    CASE\n      WHEN race_hits >= 2 OR is_multi_hint THEN \'More than one race\'\n      WHEN is_aian THEN \'American Indian or Alaska Native\'\n      WHEN is_asian THEN \'Asian\'\n      WHEN is_black THEN \'Black or African American\'\n      WHEN is_nhopi THEN \'Native Hawaiian or Other Pacific Islander\'\n      WHEN is_white THEN \'White\'\n      WHEN is_unknown_any OR race_text_any IS NULL OR race_text_any = \'\' THEN \'Unknown or Not Reported\'\n      ELSE \'Unknown or Not Reported\'\n    END AS nih_race\n  FROM ethn\n)\n\nSELECT hadm_id, race_hosp_raw, race_ed_raw, nih_race, nih_ethnicity\nFROM race_assign\n"""\nrace_eth = run_sql_bq(race_eth_sql, {"hadms": hadm_list})\nprint("Race/Eth rows:", len(race_eth))\nrace_eth.head(3)\n\n', 'execution_count': 11}
[NbConvertApp] msg_type: stream
[NbConvertApp] content: {'name': 'stdout', 'text': 'Race/Eth rows: 115179\n'}
[NbConvertApp] msg_type: execute_result
[NbConvertApp] content: {'data': {'text/plain': '    hadm_id           race_hosp_raw race_ed_raw nih_race  \\\n0  20000094                   white        None    White   \n1  20000147  white - other european        None    White   \n2  20000235                   white        None    White   \n\n             nih_ethnicity  \n0   Not Hispanic or Latino  \n1  Unknown or Not Reported  \n2   Not Hispanic or Latino  ', 'text/html': '<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border="1" class="dataframe">\n  <thead>\n    <tr style="text-align: right;">\n      <th></th>\n      <th>hadm_id</th>\n      <th>race_hosp_raw</th>\n      <th>race_ed_raw</th>\n      <th>nih_race</th>\n      <th>nih_ethnicity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20000094</td>\n      <td>white</td>\n      <td>None</td>\n      <td>White</td>\n      <td>Not Hispanic or Latino</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20000147</td>\n      <td>white - other european</td>\n      <td>None</td>\n      <td>White</td>\n      <td>Unknown or Not Reported</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000235</td>\n      <td>white</td>\n      <td>None</td>\n      <td>White</td>\n      <td>Not Hispanic or Latino</td>\n    </tr>\n  </tbody>\n</table>\n</div>'}, 'metadata': {}, 'execution_count': 11}
[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'idle'}
[NbConvertApp] Skipping non-executing cell 32
[NbConvertApp] Skipping non-executing cell 33
[NbConvertApp] Executing cell:
# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.

# ED triage
SQL["ed_triage_sql"] = f"""
WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),
edmap AS (
  SELECT stay_id, hadm_id, intime
  FROM `{PHYS}.{ED}.edstays`
  WHERE hadm_id IN (SELECT hadm_id FROM hadms)
),
tri AS (
  SELECT stay_id, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint
  FROM `{PHYS}.{ED}.triage`
),
tri_by_stay AS (
  SELECT m.hadm_id, m.intime, t.*
  FROM edmap m
  JOIN tri t USING (stay_id)
),
tri_by_hadm AS (
  SELECT
    hadm_id,
    (ARRAY_AGG(STRUCT(intime, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint)
               ORDER BY intime LIMIT 1))[OFFSET(0)] AS pick
  FROM tri_by_stay
  GROUP BY hadm_id
)
SELECT
  hadm_id,
  pick.temperature    AS ed_triage_temp,
  pick.heartrate      AS ed_triage_hr,
  pick.resprate       AS ed_triage_rr,
  pick.o2sat          AS ed_triage_o2sat,
  pick.sbp            AS ed_triage_sbp,
  pick.dbp            AS ed_triage_dbp,
  pick.pain           AS ed_triage_pain,
  pick.acuity         AS ed_triage_acuity,
  pick.chiefcomplaint AS ed_triage_cc
FROM tri_by_hadm
"""
ed_triage = run_sql_bq(sql("ed_triage_sql"), {"hadms": hadm_list})
print("ED triage rows:", len(ed_triage))

# First ED vitals
SQL["ed_first_vitals_sql"] = f"""
WITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),
edmap AS (
  SELECT stay_id, hadm_id
  FROM `{PHYS}.{ED}.edstays`
  WHERE hadm_id IN (SELECT hadm_id FROM hadms)
),
vs AS (
  SELECT stay_id, charttime, temperature, heartrate, resprate, o2sat, sbp, dbp, rhythm, pain
  FROM `{PHYS}.{ED}.vitalsign`
),
first_vs AS (
  SELECT
    m.hadm_id,
    (ARRAY_AGG(STRUCT(v.charttime, v.temperature, v.heartrate, v.resprate, v.o2sat, v.sbp, v.dbp, v.rhythm, v.pain)
               ORDER BY v.charttime LIMIT 1))[OFFSET(0)] AS pick
  FROM edmap m JOIN vs v USING (stay_id)
  GROUP BY m.hadm_id
)
SELECT
  hadm_id,
  pick.charttime   AS ed_first_vitals_time,
  pick.temperature AS ed_first_temp,
  pick.heartrate   AS ed_first_hr,
  pick.resprate    AS ed_first_rr,
  pick.o2sat       AS ed_first_o2sat,
  pick.sbp         AS ed_first_sbp,
  pick.dbp         AS ed_first_dbp,
  pick.rhythm      AS ed_first_rhythm,
  pick.pain        AS ed_first_pain
FROM first_vs
"""
ed_first = run_sql_bq(sql("ed_first_vitals_sql"), {"hadms": hadm_list})
print("ED first vitals rows:", len(ed_first))


[NbConvertApp] msg_type: status
[NbConvertApp] content: {'execution_state': 'busy'}
[NbConvertApp] msg_type: execute_input
[NbConvertApp] content: {'code': '# Purpose: Define a reusable BigQuery execution helper so SQL calls are consistent across notebook stages.\n\n# ED triage\nSQL["ed_triage_sql"] = f"""\nWITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\nedmap AS (\n  SELECT stay_id, hadm_id, intime\n  FROM `{PHYS}.{ED}.edstays`\n  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n),\ntri AS (\n  SELECT stay_id, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint\n  FROM `{PHYS}.{ED}.triage`\n),\ntri_by_stay AS (\n  SELECT m.hadm_id, m.intime, t.*\n  FROM edmap m\n  JOIN tri t USING (stay_id)\n),\ntri_by_hadm AS (\n  SELECT\n    hadm_id,\n    (ARRAY_AGG(STRUCT(intime, temperature, heartrate, resprate, o2sat, sbp, dbp, pain, acuity, chiefcomplaint)\n               ORDER BY intime LIMIT 1))[OFFSET(0)] AS pick\n  FROM tri_by_stay\n  GROUP BY hadm_id\n)\nSELECT\n  hadm_id,\n  pick.temperature    AS ed_triage_temp,\n  pick.heartrate      AS ed_triage_hr,\n  pick.resprate       AS ed_triage_rr,\n  pick.o2sat          AS ed_triage_o2sat,\n  pick.sbp            AS ed_triage_sbp,\n  pick.dbp            AS ed_triage_dbp,\n  pick.pain           AS ed_triage_pain,\n  pick.acuity         AS ed_triage_acuity,\n  pick.chiefcomplaint AS ed_triage_cc\nFROM tri_by_hadm\n"""\ned_triage = run_sql_bq(sql("ed_triage_sql"), {"hadms": hadm_list})\nprint("ED triage rows:", len(ed_triage))\n\n# First ED vitals\nSQL["ed_first_vitals_sql"] = f"""\nWITH hadms AS (SELECT x AS hadm_id FROM UNNEST(@hadms) AS x),\nedmap AS (\n  SELECT stay_id, hadm_id\n  FROM `{PHYS}.{ED}.edstays`\n  WHERE hadm_id IN (SELECT hadm_id FROM hadms)\n),\nvs AS (\n  SELECT stay_id, charttime, temperature, heartrate, resprate, o2sat, sbp, dbp, rhythm, pain\n  FROM `{PHYS}.{ED}.vitalsign`\n),\nfirst_vs AS (\n  SELECT\n    m.hadm_id,\n    (ARRAY_AGG(STRUCT(v.charttime, v.temperature, v.heartrate, v.resprate, v.o2sat, v.sbp, v.dbp, v.rhythm, v.pain)\n               ORDER BY v.charttime LIMIT 1))[OFFSET(0)] AS pick\n  FROM edmap m JOIN vs v USING (stay_id)\n  GROUP BY m.hadm_id\n)\nSELECT\n  hadm_id,\n  pick.charttime   AS ed_first_vitals_time,\n  pick.temperature AS ed_first_temp,\n  pick.heartrate   AS ed_first_hr,\n  pick.resprate    AS ed_first_rr,\n  pick.o2sat       AS ed_first_o2sat,\n  pick.sbp         AS ed_first_sbp,\n  pick.dbp         AS ed_first_dbp,\n  pick.rhythm      AS ed_first_rhythm,\n  pick.pain        AS ed_first_pain\nFROM first_vs\n"""\ned_first = run_sql_bq(sql("ed_first_vitals_sql"), {"hadms": hadm_list})\nprint("ED first vitals rows:", len(ed_first))\n\n', 'execution_count': 12}
