{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9022eea1",
   "metadata": {},
   "source": [
    "# Workbook for MIMIC Hypercapnia Presenting Chief Concern Analysis\n",
    "\n",
    "This notebook is a deterministic analysis workflow for the NLP-augmented hypercapnia cohort workbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a86a58",
   "metadata": {},
   "source": [
    "## Environment Gate\n",
    "\n",
    "Fail fast if required packages are missing. Use `uv sync` to repair the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "required_packages = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"statsmodels\",\n",
    "    \"openpyxl\",\n",
    "]\n",
    "missing = [pkg for pkg in required_packages if importlib.util.find_spec(pkg) is None]\n",
    "if missing:\n",
    "    raise ModuleNotFoundError(\n",
    "        \"Missing required packages: \"\n",
    "        + \", \".join(missing)\n",
    "        + \". Run `uv sync` from the repository root and rerun the notebook.\"\n",
    "    )\n",
    "print(\"Environment check passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe7741",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Use a single canonical workbook path under `MIMIC tabular data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "WORK_DIR = Path(os.getenv(\"WORK_DIR\", Path.cwd())).expanduser().resolve()\n",
    "SRC_DIR = WORK_DIR / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "analysis_core = importlib.import_module(\"hypercap_cc_nlp.analysis_core\")\n",
    "binary_crosstab_yes_no = analysis_core.binary_crosstab_yes_no\n",
    "classify_icd_category_vectorized = analysis_core.classify_icd_category_vectorized\n",
    "classify_inclusion_type_vectorized = analysis_core.classify_inclusion_type_vectorized\n",
    "ensure_required_columns = analysis_core.ensure_required_columns\n",
    "resolve_analysis_paths = analysis_core.resolve_analysis_paths\n",
    "symptom_distribution_by_overlap = analysis_core.symptom_distribution_by_overlap\n",
    "to_binary_flag = analysis_core.to_binary_flag\n",
    "\n",
    "ANALYSIS_INPUT_FILENAME = os.getenv(\n",
    "    \"ANALYSIS_INPUT_FILENAME\",\n",
    "    \"2025-10-14 MIMICIV all with CC_with_NLP.xlsx\",\n",
    ")\n",
    "ANALYSIS_INPUT_PATH = resolve_analysis_paths(WORK_DIR, ANALYSIS_INPUT_FILENAME)\n",
    "OUTPUT_DIR = WORK_DIR\n",
    "\n",
    "HYPERCAP_CRITERIA = [\n",
    "    \"any_hypercap_icd\",\n",
    "    \"abg_hypercap_threshold\",\n",
    "    \"vbg_hypercap_threshold\",\n",
    "    \"pco2_threshold_any\",\n",
    "]\n",
    "\n",
    "SYMPTOM_COL = \"RFV1_name\"\n",
    "\n",
    "df = pd.read_excel(ANALYSIS_INPUT_PATH, engine=\"openpyxl\")\n",
    "ensure_required_columns(df, [SYMPTOM_COL, \"any_hypercap_icd\", \"pco2_threshold_any\"])\n",
    "\n",
    "for column in HYPERCAP_CRITERIA:\n",
    "    ensure_required_columns(df, [column])\n",
    "    df[column] = to_binary_flag(df[column])\n",
    "\n",
    "print(f\"Loaded {ANALYSIS_INPUT_PATH.name}: {df.shape[0]:,} rows x {df.shape[1]:,} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1233c8",
   "metadata": {},
   "source": [
    "## Descriptive Checks\n",
    "\n",
    "Compute core cohort summaries with guarded column checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_candidates = [col for col in df.columns if col.lower().startswith(\"gender\")]\n",
    "if not gender_candidates:\n",
    "    raise KeyError(\"No gender-like column found. Expected a column starting with 'gender'.\")\n",
    "gender_col = gender_candidates[0]\n",
    "\n",
    "gender_summary = (\n",
    "    df[gender_col]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(gender_col)\n",
    "    .to_frame(\"Count\")\n",
    ")\n",
    "gender_summary[\"Percent\"] = (gender_summary[\"Count\"] / len(df) * 100).round(1)\n",
    "\n",
    "age_summary = pd.Series(\n",
    "    {\n",
    "        \"Mean\": round(float(df[\"age\"].mean()), 2),\n",
    "        \"SD\": round(float(df[\"age\"].std()), 2),\n",
    "        \"Q1\": round(float(df[\"age\"].quantile(0.25)), 2),\n",
    "        \"Q3\": round(float(df[\"age\"].quantile(0.75)), 2),\n",
    "    },\n",
    "    name=\"Age (years)\",\n",
    ")\n",
    "\n",
    "hypercap_prevalence = pd.DataFrame(\n",
    "    {\n",
    "        \"Count\": [int(df[col].sum()) for col in HYPERCAP_CRITERIA],\n",
    "        \"Percent\": [round(float(df[col].mean() * 100), 1) for col in HYPERCAP_CRITERIA],\n",
    "    },\n",
    "    index=HYPERCAP_CRITERIA,\n",
    ")\n",
    "\n",
    "display(gender_summary)\n",
    "display(age_summary.to_frame())\n",
    "display(hypercap_prevalence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58792ff4",
   "metadata": {},
   "source": [
    "## ICD And Inclusion Categories\n",
    "\n",
    "Use vectorized helper functions to avoid row-wise `apply(axis=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fad0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"icd_category\"] = classify_icd_category_vectorized(df)\n",
    "df[\"inclusion_type\"] = classify_inclusion_type_vectorized(\n",
    "    df[\"any_hypercap_icd\"],\n",
    "    df[\"pco2_threshold_any\"],\n",
    ")\n",
    "\n",
    "icd_category_summary = (\n",
    "    df[\"icd_category\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(\"ICD Category\")\n",
    "    .to_frame(\"Count\")\n",
    ")\n",
    "icd_category_summary[\"Percent\"] = (icd_category_summary[\"Count\"] / len(df) * 100).round(1)\n",
    "\n",
    "inclusion_summary = (\n",
    "    df[\"inclusion_type\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(\"Inclusion Type\")\n",
    "    .to_frame(\"Count\")\n",
    ")\n",
    "inclusion_summary[\"Percent\"] = (inclusion_summary[\"Count\"] / len(df) * 100).round(1)\n",
    "\n",
    "display(icd_category_summary)\n",
    "display(inclusion_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62856b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_non_null = df.dropna(subset=[SYMPTOM_COL]).copy()\n",
    "top_symptom_labels = symptom_non_null[SYMPTOM_COL].value_counts().head(10).index\n",
    "symptom_non_null[\"symptom_group\"] = symptom_non_null[SYMPTOM_COL].where(\n",
    "    symptom_non_null[SYMPTOM_COL].isin(top_symptom_labels),\n",
    "    \"Other\",\n",
    ")\n",
    "\n",
    "crosstab_tables = {}\n",
    "for definition in HYPERCAP_CRITERIA:\n",
    "    definition_table = binary_crosstab_yes_no(symptom_non_null, \"symptom_group\", definition)\n",
    "    crosstab_tables[definition] = definition_table.sort_values(\"Percent_yes\", ascending=False)\n",
    "\n",
    "display(crosstab_tables[\"pco2_threshold_any\"].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c5539",
   "metadata": {},
   "source": [
    "## Symptom Composition By Hypercapnia Definition\n",
    "\n",
    "Generate counts, percentages, and clipped Wald 95% confidence intervals; export stable tables for downstream reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_long_df = symptom_non_null.melt(\n",
    "    id_vars=[\"symptom_group\"],\n",
    "    value_vars=HYPERCAP_CRITERIA,\n",
    "    var_name=\"Hypercapnia_Definition\",\n",
    "    value_name=\"Positive\",\n",
    ")\n",
    "definition_positive_df = definition_long_df.loc[definition_long_df[\"Positive\"].eq(1)].copy()\n",
    "\n",
    "definition_counts_df = (\n",
    "    definition_positive_df.groupby([\"Hypercapnia_Definition\", \"symptom_group\"], dropna=False)\n",
    "    .size()\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "definition_counts_df[\"Total\"] = definition_counts_df.groupby(\"Hypercapnia_Definition\")[\"Count\"].transform(\"sum\")\n",
    "definition_counts_df[\"Percent\"] = definition_counts_df[\"Count\"] / definition_counts_df[\"Total\"] * 100\n",
    "\n",
    "p_hat = (definition_counts_df[\"Percent\"] / 100).clip(0, 1)\n",
    "n_obs = definition_counts_df[\"Total\"].replace(0, np.nan)\n",
    "se = np.sqrt((p_hat * (1 - p_hat)) / n_obs).fillna(0)\n",
    "definition_counts_df[\"CI_lower\"] = ((p_hat - 1.96 * se).clip(0, 1) * 100).round(2)\n",
    "definition_counts_df[\"CI_upper\"] = ((p_hat + 1.96 * se).clip(0, 1) * 100).round(2)\n",
    "definition_counts_df[\"Percent\"] = definition_counts_df[\"Percent\"].round(2)\n",
    "\n",
    "definition_counts_df = definition_counts_df.sort_values(\n",
    "    [\"Hypercapnia_Definition\", \"Count\"],\n",
    "    ascending=[True, False],\n",
    ")\n",
    "\n",
    "definition_pivot_df = definition_counts_df.pivot_table(\n",
    "    index=\"symptom_group\",\n",
    "    columns=\"Hypercapnia_Definition\",\n",
    "    values=\"Percent\",\n",
    "    fill_value=0,\n",
    ").round(2)\n",
    "\n",
    "definition_output_path = OUTPUT_DIR / \"Symptom_Composition_by_Hypercapnia_Definition.xlsx\"\n",
    "pivot_output_path = OUTPUT_DIR / \"Symptom_Composition_Pivot_ChartReady.xlsx\"\n",
    "definition_counts_df.to_excel(definition_output_path, index=False)\n",
    "definition_pivot_df.to_excel(pivot_output_path)\n",
    "\n",
    "display(definition_counts_df.head(12))\n",
    "print(f\"Exported: {definition_output_path}\")\n",
    "print(f\"Exported: {pivot_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4925a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "composition_plot_df = definition_pivot_df.T.loc[HYPERCAP_CRITERIA]\n",
    "\n",
    "ax = composition_plot_df.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(10, 6),\n",
    "    width=0.8,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "ax.set_title(\"Symptom Composition within Each Hypercapnia Definition (%)\")\n",
    "ax.set_xlabel(\"Hypercapnia Definition\")\n",
    "ax.set_ylabel(\"Percent of Patients\")\n",
    "ax.tick_params(axis=\"x\", labelrotation=15)\n",
    "ax.legend(title=\"Symptom Group\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1793f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_for_ci = (\n",
    "    definition_counts_df.groupby(\"symptom_group\")[\"Count\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(5)\n",
    "    .index\n",
    ")\n",
    "ci_plot_df = definition_counts_df.loc[definition_counts_df[\"symptom_group\"].isin(top_for_ci)].copy()\n",
    "symptom_order = list(top_for_ci)\n",
    "definition_order = HYPERCAP_CRITERIA\n",
    "\n",
    "x = np.arange(len(symptom_order))\n",
    "width = 0.18\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "for idx, definition in enumerate(definition_order):\n",
    "    subset = (\n",
    "        ci_plot_df.loc[ci_plot_df[\"Hypercapnia_Definition\"].eq(definition)]\n",
    "        .set_index(\"symptom_group\")\n",
    "        .reindex(symptom_order)\n",
    "        .fillna(0)\n",
    "    )\n",
    "    x_pos = x + (idx - (len(definition_order) - 1) / 2) * width\n",
    "    y = subset[\"Percent\"].to_numpy()\n",
    "    lower = subset[\"CI_lower\"].to_numpy()\n",
    "    upper = subset[\"CI_upper\"].to_numpy()\n",
    "\n",
    "    ax.bar(x_pos, y, width=width, label=definition, alpha=0.85)\n",
    "    ax.errorbar(\n",
    "        x_pos,\n",
    "        y,\n",
    "        yerr=[y - lower, upper - y],\n",
    "        fmt=\"none\",\n",
    "        ecolor=\"black\",\n",
    "        elinewidth=1,\n",
    "        capsize=2,\n",
    "    )\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(symptom_order, rotation=25, ha=\"right\")\n",
    "ax.set_ylabel(\"Percent of Patients\")\n",
    "ax.set_xlabel(\"Symptom Group\")\n",
    "ax.set_title(\"Top Symptom Group Percentages by Hypercapnia Definition (95% CI)\")\n",
    "ax.legend(title=\"Definition\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf3429",
   "metadata": {},
   "source": [
    "## Symptom Distribution By Ascertainment Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_required = [\n",
    "    SYMPTOM_COL,\n",
    "    \"abg_hypercap_threshold\",\n",
    "    \"vbg_hypercap_threshold\",\n",
    "    \"any_hypercap_icd\",\n",
    "    \"pco2_threshold_any\",\n",
    "]\n",
    "ensure_required_columns(df, overlap_required)\n",
    "\n",
    "abg_flag = to_binary_flag(df[\"abg_hypercap_threshold\"])\n",
    "vbg_flag = to_binary_flag(df[\"vbg_hypercap_threshold\"])\n",
    "icd_flag = to_binary_flag(df[\"any_hypercap_icd\"])\n",
    "gas_flag = to_binary_flag(df[\"pco2_threshold_any\"])\n",
    "\n",
    "abg_vbg_labels = np.select(\n",
    "    [\n",
    "        abg_flag.eq(1) & vbg_flag.eq(0),\n",
    "        abg_flag.eq(0) & vbg_flag.eq(1),\n",
    "        abg_flag.eq(1) & vbg_flag.eq(1),\n",
    "    ],\n",
    "    [\"ABG-only\", \"VBG-only\", \"ABG+VBG\"],\n",
    "    default=\"No-gas\",\n",
    ")\n",
    "\n",
    "icd_gas_labels = np.select(\n",
    "    [\n",
    "        icd_flag.eq(1) & gas_flag.eq(1),\n",
    "        icd_flag.eq(1) & gas_flag.eq(0),\n",
    "        icd_flag.eq(0) & gas_flag.eq(1),\n",
    "    ],\n",
    "    [\"ICD+Gas\", \"ICD-only\", \"Gas-only\"],\n",
    "    default=\"Neither\",\n",
    ")\n",
    "\n",
    "overlap_df = df.copy()\n",
    "overlap_df[\"abg_vbg_overlap\"] = abg_vbg_labels\n",
    "overlap_df[\"icd_gas_overlap\"] = icd_gas_labels\n",
    "\n",
    "gas_positive_df = overlap_df.loc[abg_flag.eq(1) | vbg_flag.eq(1)].copy()\n",
    "abg_vbg_counts_df, abg_vbg_pivot_df = symptom_distribution_by_overlap(\n",
    "    gas_positive_df,\n",
    "    group_col=\"abg_vbg_overlap\",\n",
    "    symptom_col=SYMPTOM_COL,\n",
    "    top_k=10,\n",
    ")\n",
    "icd_gas_counts_df, icd_gas_pivot_df = symptom_distribution_by_overlap(\n",
    "    overlap_df,\n",
    "    group_col=\"icd_gas_overlap\",\n",
    "    symptom_col=SYMPTOM_COL,\n",
    "    top_k=10,\n",
    ")\n",
    "\n",
    "abg_vbg_output_path = OUTPUT_DIR / \"Symptom_Composition_by_ABG_VBG_Overlap.xlsx\"\n",
    "icd_gas_output_path = OUTPUT_DIR / \"Symptom_Composition_by_ICD_Gas_Overlap.xlsx\"\n",
    "abg_vbg_pivot_df.to_excel(abg_vbg_output_path)\n",
    "icd_gas_pivot_df.to_excel(icd_gas_output_path)\n",
    "\n",
    "print(\"Symptom distribution by ABG/VBG overlap (gas-positive):\")\n",
    "display(abg_vbg_pivot_df.head(15))\n",
    "print(\"Symptom distribution by ICD/Gas overlap:\")\n",
    "display(icd_gas_pivot_df.head(15))\n",
    "print(f\"Exported: {abg_vbg_output_path}\")\n",
    "print(f\"Exported: {icd_gas_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57ddda",
   "metadata": {},
   "source": [
    "## Association Model\n",
    "\n",
    "Logistic regression of respiratory symptom flag on hypercapnia definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a18a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df.dropna(subset=[SYMPTOM_COL]).copy()\n",
    "model_df[\"is_respiratory\"] = model_df[SYMPTOM_COL].astype(str).str.contains(\n",
    "    r\"\\brespir\", case=False, na=False\n",
    ").astype(int)\n",
    "\n",
    "design_matrix = sm.add_constant(model_df[HYPERCAP_CRITERIA], has_constant=\"add\")\n",
    "outcome = model_df[\"is_respiratory\"]\n",
    "logit_result = sm.Logit(outcome, design_matrix, missing=\"drop\").fit(disp=False)\n",
    "\n",
    "or_table = pd.DataFrame(\n",
    "    {\n",
    "        \"OR\": np.exp(logit_result.params),\n",
    "        \"CI_lo\": np.exp(logit_result.conf_int()[0]),\n",
    "        \"CI_hi\": np.exp(logit_result.conf_int()[1]),\n",
    "        \"p\": logit_result.pvalues,\n",
    "    }\n",
    ").round(3)\n",
    "\n",
    "display(or_table.loc[HYPERCAP_CRITERIA])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296db262",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_plot_df = or_table.loc[HYPERCAP_CRITERIA]\n",
    "y_positions = np.arange(len(or_plot_df))[::-1]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hlines(y=y_positions, xmin=or_plot_df[\"CI_lo\"], xmax=or_plot_df[\"CI_hi\"], linewidth=1.5)\n",
    "plt.plot(or_plot_df[\"OR\"], y_positions, \"o\")\n",
    "plt.vlines(1, ymin=-1, ymax=len(or_plot_df), linestyles=\"dashed\")\n",
    "plt.yticks(y_positions, or_plot_df.index)\n",
    "plt.xlabel(\"Odds ratio for respiratory symptom\")\n",
    "plt.title(\"Adjusted ORs (95% CI)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd223d49",
   "metadata": {},
   "source": [
    "## Export Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90692732",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_outputs = [\n",
    "    definition_output_path,\n",
    "    pivot_output_path,\n",
    "    abg_vbg_output_path,\n",
    "    icd_gas_output_path,\n",
    "]\n",
    "\n",
    "verification_rows = []\n",
    "for output_path in expected_outputs:\n",
    "    verification_rows.append(\n",
    "        {\n",
    "            \"path\": str(output_path),\n",
    "            \"exists\": output_path.exists(),\n",
    "            \"size_bytes\": output_path.stat().st_size if output_path.exists() else 0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "output_verification = pd.DataFrame(verification_rows)\n",
    "display(output_verification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypercap-cc-nlp",
   "language": "python",
   "name": "hypercap-cc-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
