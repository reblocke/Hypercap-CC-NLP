{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c646e8",
   "metadata": {},
   "source": [
    "# MIMIC‑IV on BigQuery\n",
    "\n",
    "## Environment Bootstrap & Smoke Test\n",
    "\n",
    "Purpose: make a clean, reproducible start on a new machine.\n",
    "\n",
    "Outcome: verify auth, project config, and dataset access; provide a reusable BigQuery runner for the build notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022b416",
   "metadata": {},
   "source": [
    "## 0. Prerequisites (one-time)\n",
    "\n",
    "**Accounts & access**\n",
    "- PhysioNet access to MIMIC‑IV on BigQuery; in BigQuery Console star project `physionet-data`.\n",
    "- A Google Cloud **Project ID** with BigQuery API enabled (this is your **billing** project).\n",
    "\n",
    "**CLI & environment**\n",
    "- Google Cloud SDK (gcloud) installed and on PATH.\n",
    "- Conda environment created from `environment.yml` and Jupyter kernel selected.\n",
    "- A project‑local **`.env`** with the variables below.\n",
    "\n",
    "**.env variables**\n",
    "```ini\n",
    "MIMIC_BACKEND=bigquery\n",
    "WORK_PROJECT=mimic-hypercapnia #or another <your-billing-project-id>\n",
    "BQ_PHYSIONET_PROJECT=physionet-data\n",
    "BQ_DATASET_HOSP=mimiciv_3_1_hosp\n",
    "BQ_DATASET_ICU=mimiciv_3_1_icu\n",
    "BQ_DATASET_ED=mimiciv_ed\n",
    "# GOOGLE_APPLICATION_CREDENTIALS=/Users/<you>/.config/gcloud/application_default_credentials.json\n",
    "```\n",
    "\n",
    "**Command line quickstart**\n",
    "```bash\n",
    "brew install --cask google-cloud-sdk\n",
    "gcloud init\n",
    "gcloud auth application-default login\n",
    "gcloud services enable bigquery.googleapis.com --project <your-billing-project-id>\n",
    "ls -l ~/.config/gcloud/application_default_credentials.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb3810",
   "metadata": {},
   "source": [
    "## 1. Load configuration from `.env` and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36831ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env\n",
      "WORK_PROJECT: mimic-hypercapnia\n",
      "PHYSIONET project: physionet-data\n",
      "Datasets -> HOSP: mimiciv_3_1_hosp | ICU: mimiciv_3_1_icu | ED: mimiciv_ed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    for candidate in [\".env\", \".env.local\"]:\n",
    "        if Path(candidate).exists():\n",
    "            load_dotenv(candidate, override=False)\n",
    "            print(f\"Loaded {candidate}\")\n",
    "except Exception as e:\n",
    "    print(\"Note: python-dotenv not loaded:\", e)\n",
    "\n",
    "adc = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if adc:\n",
    "    expanded = os.path.expanduser(adc)\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = expanded\n",
    "    print(\"GOOGLE_APPLICATION_CREDENTIALS:\", expanded, \"(exists:\", Path(expanded).exists(), \")\")\n",
    "\n",
    "WORK_PROJECT = os.getenv(\"WORK_PROJECT\")\n",
    "PHYS = os.getenv(\"BQ_PHYSIONET_PROJECT\", \"physionet-data\")\n",
    "HOSP = os.getenv(\"BQ_DATASET_HOSP\", \"mimiciv_3_1_hosp\")\n",
    "ICU  = os.getenv(\"BQ_DATASET_ICU\",  \"mimiciv_3_1_icu\")\n",
    "ED   = os.getenv(\"BQ_DATASET_ED\",   \"mimiciv_ed\")\n",
    "\n",
    "print(\"WORK_PROJECT:\", WORK_PROJECT)\n",
    "print(\"PHYSIONET project:\", PHYS)\n",
    "print(\"Datasets -> HOSP:\", HOSP, \"| ICU:\", ICU, \"| ED:\", ED)\n",
    "\n",
    "if WORK_PROJECT in (None, \"\", \"your-gcp-project-id\", \"YOUR_GCP_PROJECT_ID\"):\n",
    "    raise RuntimeError(\"Set WORK_PROJECT in .env to your actual GCP Project ID (not the display name).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cce1d",
   "metadata": {},
   "source": [
    "## 2. Optional: silence gRPC ALTS warnings\n",
    "\n",
    "The ALTS messages you may see are harmless:\n",
    "```\n",
    "ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
    "```\n",
    "Silence them for this kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003d10c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gRPC verbosity disabled for this process.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"NONE\"\n",
    "os.environ[\"GRPC_LOG_SEVERITY_LEVEL\"] = \"ERROR\"\n",
    "print(\"gRPC verbosity disabled for this process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0273b",
   "metadata": {},
   "source": [
    "## 3. Create BigQuery client and run a trivial query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fd9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery client project: mimic-hypercapnia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ok\n",
       "0   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "client = bigquery.Client(project=WORK_PROJECT)\n",
    "print(\"BigQuery client project:\", client.project)\n",
    "smoke = client.query(\"SELECT 1 AS ok\").result().to_dataframe()\n",
    "smoke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec4cb5",
   "metadata": {},
   "source": [
    "## 4. Dataset checks — counts and peeks\n",
    "\n",
    "Use the dataset names exactly as shown in Explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32323551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) AS n FROM `physionet-data.mimiciv_3_1_hosp.admissions`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>546028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n\n",
       "0  546028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) AS n FROM `physionet-data.mimiciv_3_1_icu.icustays`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n\n",
       "0  94458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql1 = f\"SELECT COUNT(*) AS n FROM `{PHYS}.{HOSP}.admissions`\"\n",
    "sql2 = f\"SELECT COUNT(*) AS n FROM `{PHYS}.{ICU}.icustays`\"\n",
    "df1 = client.query(sql1).result().to_dataframe()\n",
    "df2 = client.query(sql2).result().to_dataframe()\n",
    "print(sql1) ; display(df1)\n",
    "print(sql2) ; display(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c2c960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10078138</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>2110</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10180372</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>2110</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10686175</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>2110</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10851602</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>2110</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10902424</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>2110</td>\n",
       "      <td>2017 - 2019</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id gender  anchor_age  anchor_year anchor_year_group  dod\n",
       "0    10078138      F          18         2110       2017 - 2019  NaT\n",
       "1    10180372      M          18         2110       2008 - 2010  NaT\n",
       "2    10686175      M          18         2110       2011 - 2013  NaT\n",
       "3    10851602      F          18         2110       2014 - 2016  NaT\n",
       "4    10902424      F          18         2110       2017 - 2019  NaT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_pat = f\"SELECT * FROM `{PHYS}.{HOSP}.patients` LIMIT 5\"\n",
    "client.query(sql_pat).result().to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec79fc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) AS n FROM `physionet-data.mimiciv_ed.edstays`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>425087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n\n",
       "0  425087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    sql_ed = f\"SELECT COUNT(*) AS n FROM `{PHYS}.{ED}.edstays`\"\n",
    "    df_ed = client.query(sql_ed).result().to_dataframe()\n",
    "    print(sql_ed) ; display(df_ed)\n",
    "except Exception as e:\n",
    "    print(\"ED dataset check skipped or failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcd4ba",
   "metadata": {},
   "source": [
    "## 5. Reusable runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9861a0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>546028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n\n",
       "0  546028"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_sql_bq(sql: str):\n",
    "    job = client.query(sql)\n",
    "    return job.result().to_dataframe()\n",
    "\n",
    "run_sql_bq(f\"SELECT COUNT(*) AS n FROM `{PHYS}.{HOSP}.admissions`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ee95b",
   "metadata": {},
   "source": [
    "## 6. Troubleshooting quicklist\n",
    "\n",
    "- **ProjectId must be non-empty** → Set `WORK_PROJECT` in `.env`; enable BigQuery API.\n",
    "- **Access Denied** → Use dataset names from Explorer; confirm approved account; query billing project is yours.\n",
    "- **ADC file not found** → `gcloud auth application-default login`; avoid `~` unless expanded.\n",
    "- **ALTS warnings** → harmless; silenced by env vars above.\n",
    "- **Kernel/env mismatch** → `pip show google-cloud-bigquery` must succeed in this kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6778d9",
   "metadata": {},
   "source": [
    "## Code to recreate the MIMIC tabular dataset\n",
    "\n",
    "**Goal**: Reproduce the legacy `MIMIC_hypercap.xlsx` using BigQuery (no Summit).\n",
    "\n",
    "**Inputs**: Access to `physionet-data` BigQuery project and datasets `mimiciv_3_1_hosp`, `mimiciv_3_1_icu`, and your ED dataset.  (`mimiciv_ed`)\n",
    "\n",
    "**Output**: A single wide table with ICD flags, demographics, ED triage, outcomes, and first blood gas values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99e688",
   "metadata": {},
   "source": [
    "### 1. Configuration and BigQuery runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d1743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env\n",
      "Billing project: mimic-hypercapnia\n",
      "Datasets -> {'HOSP': 'mimiciv_3_1_hosp', 'ICU': 'mimiciv_3_1_icu', 'ED': 'mimiciv_ed'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Optional: silence gRPC ALTS warnings (harmless otherwise)\n",
    "os.environ.setdefault(\"GRPC_VERBOSITY\", \"NONE\")\n",
    "os.environ.setdefault(\"GRPC_LOG_SEVERITY_LEVEL\", \"ERROR\")\n",
    "\n",
    "# Load .env\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    for candidate in [\".env\", \".env.local\"]:\n",
    "        if Path(candidate).exists():\n",
    "            load_dotenv(candidate, override=False)\n",
    "            print(f\"Loaded {candidate}\")\n",
    "except Exception as e:\n",
    "    print(\"Note: python-dotenv not loaded:\", e)\n",
    "\n",
    "# Expand '~' in ADC if present\n",
    "adc = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if adc:\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.path.expanduser(adc)\n",
    "\n",
    "WORK_PROJECT = os.getenv(\"WORK_PROJECT\")\n",
    "PHYS = os.getenv(\"BQ_PHYSIONET_PROJECT\", \"physionet-data\")\n",
    "HOSP = os.getenv(\"BQ_DATASET_HOSP\", \"mimiciv_3_1_hosp\")\n",
    "ICU  = os.getenv(\"BQ_DATASET_ICU\",  \"mimiciv_3_1_icu\")\n",
    "ED   = os.getenv(\"BQ_DATASET_ED\",   \"mimiciv_ed\")\n",
    "\n",
    "assert WORK_PROJECT not in (None, \"\", \"your-gcp-project-id\", \"YOUR_GCP_PROJECT_ID\"), \"Set WORK_PROJECT to your billing project id\"\n",
    "print(\"Billing project:\", WORK_PROJECT)\n",
    "print(\"Datasets ->\", {\"HOSP\": HOSP, \"ICU\": ICU, \"ED\": ED})\n",
    "\n",
    "client = bigquery.Client(project=WORK_PROJECT)\n",
    "\n",
    "def run_sql_bq(sql: str, params: dict | None = None) -> pd.DataFrame:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    bq_params = []\n",
    "    if params:\n",
    "        for name, val in params.items():\n",
    "            if isinstance(val, list):\n",
    "                # infer list type as INT64 if contents are ints, else STRING\n",
    "                if all(isinstance(x, (int,)) or (isinstance(x, float) and float(x).is_integer()) for x in val if x is not None):\n",
    "                    bq_params.append(bigquery.ArrayQueryParameter(name, \"INT64\", [int(x) for x in val if x is not None]))\n",
    "                else:\n",
    "                    bq_params.append(bigquery.ArrayQueryParameter(name, \"STRING\", [None if x is None else str(x) for x in val]))\n",
    "            else:\n",
    "                # scalar\n",
    "                if isinstance(val, (int,)) or (isinstance(val, float) and float(val).is_integer()):\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(name, \"INT64\", int(val)))\n",
    "                else:\n",
    "                    bq_params.append(bigquery.ScalarQueryParameter(name, \"STRING\", str(val)))\n",
    "        job_config.query_parameters = bq_params\n",
    "    job = client.query(sql, job_config=job_config)\n",
    "    return job.result().to_dataframe(create_bqstorage_client=True)\n",
    "\n",
    "def require_hadm(df: pd.DataFrame, name=\"table\"):\n",
    "    if \"hadm_id\" in df.columns:\n",
    "        return df\n",
    "    if df.index.name == \"hadm_id\":\n",
    "        return df.reset_index()\n",
    "    raise KeyError(f\"{name} has no 'hadm_id'. Ensure you're operating on the admission-level table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c29a55",
   "metadata": {},
   "source": [
    "### 2. Cohort by ICD codes (ED diagnosis + Inpatient diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633462f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD lists (dotless, uppercase)\n",
    "ICD10_CODES = ['J9602','J9612','J9622','J9692','E662']\n",
    "ICD9_CODES  = ['27803']\n",
    "\n",
    "cohort_sql = f\"\"\"\n",
    "-- Target hypercapnic respiratory failure codes\n",
    "WITH target_codes AS (\n",
    "  SELECT 'J9602' AS code, 10 AS ver UNION ALL\n",
    "  SELECT 'J9612', 10 UNION ALL\n",
    "  SELECT 'J9622', 10 UNION ALL\n",
    "  SELECT 'J9692', 10 UNION ALL\n",
    "  SELECT 'E662',  10 UNION ALL\n",
    "  SELECT '27803', 9\n",
    "),\n",
    "\n",
    "-- Hospital diagnoses restricted to target codes\n",
    "hosp_dx AS (\n",
    "  SELECT\n",
    "    d.subject_id,\n",
    "    d.hadm_id,\n",
    "    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,\n",
    "    d.icd_version\n",
    "  FROM `{PHYS}.{HOSP}.diagnoses_icd` d\n",
    "  JOIN target_codes t\n",
    "    ON t.ver = d.icd_version\n",
    "   AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))\n",
    "  WHERE d.hadm_id IS NOT NULL\n",
    "),\n",
    "\n",
    "hosp_flags AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,\n",
    "    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,\n",
    "    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803\n",
    "  FROM hosp_dx\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- ED diagnoses restricted to target codes, mapped to the admission\n",
    "ed_dx AS (\n",
    "  SELECT\n",
    "    s.subject_id,\n",
    "    s.hadm_id,\n",
    "    s.stay_id,\n",
    "    s.intime AS ed_intime,\n",
    "    UPPER(REPLACE(d.icd_code, '.', '')) AS code_norm,\n",
    "    d.icd_version\n",
    "  FROM `{PHYS}.{ED}.diagnosis` d\n",
    "  JOIN `{PHYS}.{ED}.edstays` s\n",
    "    ON s.subject_id = d.subject_id AND s.stay_id = d.stay_id\n",
    "  JOIN target_codes t\n",
    "    ON t.ver = d.icd_version\n",
    "   AND t.code = UPPER(REPLACE(d.icd_code, '.', ''))\n",
    "  WHERE s.hadm_id IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Flags per ED stay (if multiple ED stays map to the same HADM, keep flags for each)\n",
    "ed_flags_by_stay AS (\n",
    "  SELECT\n",
    "    subject_id, hadm_id, stay_id, MIN(ed_intime) AS ed_intime,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9602',1,0)) AS ICD10_J9602,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9612',1,0)) AS ICD10_J9612,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9622',1,0)) AS ICD10_J9622,\n",
    "    MAX(IF(icd_version=10 AND code_norm='J9692',1,0)) AS ICD10_J9692,\n",
    "    MAX(IF(icd_version=10 AND code_norm='E662', 1,0)) AS ICD10_E662,\n",
    "    MAX(IF(icd_version=9  AND code_norm='27803',1,0)) AS ICD9_27803\n",
    "  FROM ed_dx\n",
    "  GROUP BY subject_id, hadm_id, stay_id\n",
    "),\n",
    "\n",
    "-- Collapse to one ED stay per admission (earliest intime) and OR the flags\n",
    "ed_by_hadm AS (\n",
    "  SELECT\n",
    "    subject_id,\n",
    "    hadm_id,\n",
    "    (ARRAY_AGG(stay_id ORDER BY ed_intime LIMIT 1))[OFFSET(0)] AS stay_id,\n",
    "    MAX(ICD10_J9602) AS ICD10_J9602,\n",
    "    MAX(ICD10_J9612) AS ICD10_J9612,\n",
    "    MAX(ICD10_J9622) AS ICD10_J9622,\n",
    "    MAX(ICD10_J9692) AS ICD10_J9692,\n",
    "    MAX(ICD10_E662 ) AS ICD10_E662,\n",
    "    MAX(ICD9_27803) AS ICD9_27803\n",
    "  FROM ed_flags_by_stay\n",
    "  GROUP BY subject_id, hadm_id\n",
    "),\n",
    "\n",
    "-- Combine ED and hospital flags at the admission level\n",
    "combined AS (\n",
    "  SELECT\n",
    "    COALESCE(h.subject_id, e.subject_id) AS subject_id,\n",
    "    e.stay_id,  -- ED stay leading to the admission (if any)\n",
    "    COALESCE(h.hadm_id, e.hadm_id) AS hadm_id,\n",
    "    GREATEST(IFNULL(h.ICD10_J9602,0), IFNULL(e.ICD10_J9602,0)) AS ICD10_J9602,\n",
    "    GREATEST(IFNULL(h.ICD10_J9612,0), IFNULL(e.ICD10_J9612,0)) AS ICD10_J9612,\n",
    "    GREATEST(IFNULL(h.ICD10_J9622,0), IFNULL(e.ICD10_J9622,0)) AS ICD10_J9622,\n",
    "    GREATEST(IFNULL(h.ICD10_J9692,0), IFNULL(e.ICD10_J9692,0)) AS ICD10_J9692,\n",
    "    GREATEST(IFNULL(h.ICD10_E662 ,0), IFNULL(e.ICD10_E662 ,0)) AS ICD10_E662,\n",
    "    GREATEST(IFNULL(h.ICD9_27803,0), IFNULL(e.ICD9_27803,0)) AS ICD9_27803\n",
    "  FROM hosp_flags h\n",
    "  FULL OUTER JOIN ed_by_hadm e\n",
    "    ON h.hadm_id = e.hadm_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  subject_id, stay_id, hadm_id,\n",
    "  ICD10_J9602, ICD10_J9612, ICD10_J9622, ICD10_J9692, ICD10_E662, ICD9_27803,\n",
    "  IF((ICD10_J9602+ICD10_J9612+ICD10_J9622+ICD10_J9692+ICD10_E662+ICD9_27803) > 0, 1, 0) AS any_hypercap_icd\n",
    "FROM combined\n",
    "WHERE (ICD10_J9602+ICD10_J9612+ICD10_J9622+ICD10_J9692+ICD10_E662+ICD9_27803) > 0\n",
    "\"\"\"\n",
    "cohort = run_sql_bq(cohort_sql)\n",
    "cohort.head()\n",
    "\n",
    "flags = [\"ICD10_J9602\",\"ICD10_J9612\",\"ICD10_J9622\",\"ICD10_J9692\",\"ICD10_E662\",\"ICD9_27803\"]\n",
    "\n",
    "# 1) any_hypercap_icd must imply at least one component flag\n",
    "bad = cohort[(cohort[\"any_hypercap_icd\"] == 1) & (cohort[flags].sum(axis=1) == 0)]\n",
    "assert bad.empty, f\"Inconsistent flags: {len(bad)} rows have any=1 but all component flags=0\"\n",
    "\n",
    "# 2) one line per admission\n",
    "assert cohort[\"hadm_id\"].isna().sum() == 0, \"Cohort produced rows without hadm_id\"\n",
    "assert cohort[\"hadm_id\"].nunique() == len(cohort), \"Cohort has duplicate hadm_id rows\"\n",
    "\n",
    "# 3) recompute hadm_list for downstream lab extraction\n",
    "hadm_list = sorted(cohort[\"hadm_id\"].dropna().unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8565cd",
   "metadata": {},
   "source": [
    "note: \"\"\"If physionet-data.mimiciv_derived.bg is available in your region/project, you can source the Lab pairs from there (already specimen‑pivoted) and keep only the ICU POC branch from above. The MIMIC code and SOFA concept reference this table.\"\"\" - [ ] TODO: look into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c19524",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"hadms\": hadm_list}\n",
    "\n",
    "bg_pairs_sql = f\"\"\"\n",
    "WITH hadms AS (SELECT hadm_id FROM UNNEST(@hadms) AS hadm_id),\n",
    "\n",
    "/* ---------------- LAB (HOSP) ---------------- */\n",
    "hosp_cand AS (\n",
    "  SELECT\n",
    "    le.subject_id, le.hadm_id, le.charttime, le.specimen_id,\n",
    "    CAST(le.valuenum AS FLOAT64) AS val, LOWER(COALESCE(le.valueuom,'')) AS uom,\n",
    "    LOWER(di.label) AS lbl, LOWER(COALESCE(di.fluid,'')) AS fl, LOWER(COALESCE(di.category,'')) AS cat\n",
    "  FROM `{PHYS}.{HOSP}.labevents`  le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  JOIN hadms h ON h.hadm_id = le.hadm_id\n",
    "  WHERE le.valuenum IS NOT NULL\n",
    "    AND (cat LIKE '%blood gas%' OR lbl LIKE '%pco2%' OR REGEXP_CONTAINS(lbl, r'\\\\bph\\\\b'))\n",
    "    AND (\n",
    "          REGEXP_CONTAINS(lbl, r'\\\\bph\\\\b')\n",
    "       OR REGEXP_CONTAINS(lbl, r'\\\\bpa?\\\\s*co(?:2|₂)\\\\b')\n",
    "       OR lbl LIKE '%pco2%' OR lbl LIKE '%paco2%'\n",
    "        )\n",
    "    AND NOT REGEXP_CONTAINS(lbl, r'(tco2|total|content|bicar|etco2|end[- ]?tidal)')\n",
    "),\n",
    "hosp_spec AS (\n",
    "  SELECT le.specimen_id, LOWER(COALESCE(le.value,'')) AS spec_val\n",
    "  FROM `{PHYS}.{HOSP}.labevents` le\n",
    "  JOIN `{PHYS}.{HOSP}.d_labitems` di ON di.itemid = le.itemid\n",
    "  WHERE le.specimen_id IS NOT NULL AND REGEXP_CONTAINS(LOWER(di.label), r'(specimen|sample)')\n",
    "),\n",
    "hosp_class AS (\n",
    "  SELECT\n",
    "    c.subject_id, c.hadm_id, c.charttime, c.specimen_id, c.val, c.uom, c.lbl, c.fl,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(c.lbl, r'\\\\bph\\\\b') THEN 'ph'\n",
    "      WHEN (c.lbl LIKE '%pco2%' OR REGEXP_CONTAINS(c.lbl, r'\\\\bpa?\\\\s*co(?:2|₂)\\\\b')) THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'arter') OR REGEXP_CONTAINS(s.spec_val, r'\\\\bart\\\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(s.spec_val, r'ven|mixed|central') THEN 'venous'\n",
    "      WHEN c.fl LIKE '%arterial%' OR REGEXP_CONTAINS(c.lbl, r'\\\\b(abg|art|arterial|a[- ]?line)\\\\b') THEN 'arterial'\n",
    "      WHEN c.fl LIKE '%ven%'      OR REGEXP_CONTAINS(c.lbl, r'\\\\b(vbg|ven|venous|mixed|central)\\\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM hosp_cand c\n",
    "  LEFT JOIN hosp_spec s USING (specimen_id)\n",
    "),\n",
    "hosp_pairs AS (\n",
    "  SELECT\n",
    "    hadm_id, specimen_id,\n",
    "    MIN(charttime) AS sample_time,\n",
    "    MAX(IF(analyte='ph',   val, NULL)) AS ph,\n",
    "    MAX(IF(analyte='pco2', val, NULL)) AS pco2_raw,\n",
    "    (ARRAY_AGG(IF(analyte='pco2', uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS pco2_uom,\n",
    "    (ARRAY_AGG(IF(analyte='ph',   uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS ph_uom,\n",
    "    (ARRAY_AGG(site IGNORE NULLS LIMIT 1))[OFFSET(0)] AS site\n",
    "  FROM hosp_class\n",
    "  GROUP BY hadm_id, specimen_id\n",
    "  HAVING ph IS NOT NULL AND pco2_raw IS NOT NULL AND site IN ('arterial','venous')\n",
    "),\n",
    "hosp_pairs_std AS (\n",
    "  SELECT\n",
    "    hadm_id, specimen_id, sample_time, site,\n",
    "    ph, ph_uom,\n",
    "    CASE WHEN pco2_uom = 'kpa' THEN pco2_raw * 7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    COALESCE(NULLIF(pco2_uom,''),'mmhg') AS pco2_uom_norm\n",
    "  FROM hosp_pairs\n",
    "  WHERE ph BETWEEN 6.3 AND 7.8 AND (CASE WHEN pco2_uom='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200\n",
    "),\n",
    "lab_abg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph           AS lab_abg_ph,\n",
    "         ph_uom       AS lab_abg_ph_uom,\n",
    "         pco2_mmHg    AS lab_abg_paco2,\n",
    "         pco2_uom_norm AS lab_abg_paco2_uom,\n",
    "         sample_time  AS lab_abg_time\n",
    "  FROM (\n",
    "     SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "     FROM hosp_pairs_std WHERE site='arterial'\n",
    "  ) WHERE rn=1\n",
    "),\n",
    "lab_vbg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph           AS lab_vbg_ph,\n",
    "         ph_uom       AS lab_vbg_ph_uom,\n",
    "         pco2_mmHg    AS lab_vbg_paco2,\n",
    "         pco2_uom_norm AS lab_vbg_paco2_uom,\n",
    "         sample_time  AS lab_vbg_time\n",
    "  FROM (\n",
    "     SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "     FROM hosp_pairs_std WHERE site='venous'\n",
    "  ) WHERE rn=1\n",
    "),\n",
    "\n",
    "/* ---------------- POC (ICU) ---------------- */\n",
    "icu_cand AS (\n",
    "  SELECT\n",
    "    ie.hadm_id, ce.stay_id, ce.charttime,\n",
    "    CAST(ce.valuenum AS FLOAT64) AS val, LOWER(COALESCE(ce.valueuom,'')) AS uom,\n",
    "    LOWER(di.label) AS lbl\n",
    "  FROM `{PHYS}.{ICU}.chartevents` ce\n",
    "  JOIN `{PHYS}.{ICU}.d_items`  di ON di.itemid = ce.itemid\n",
    "  JOIN `{PHYS}.{ICU}.icustays` ie ON ie.stay_id = ce.stay_id\n",
    "  JOIN hadms h ON h.hadm_id = ie.hadm_id\n",
    "  WHERE ce.valuenum IS NOT NULL\n",
    "    AND (\n",
    "          REGEXP_CONTAINS(lbl, r'\\\\bph\\\\b')\n",
    "       OR REGEXP_CONTAINS(lbl, r'\\\\bpa?\\\\s*co(?:2|₂)\\\\b')\n",
    "       OR lbl LIKE '%pco2%' OR lbl LIKE '%paco2%'\n",
    "        )\n",
    "    AND NOT REGEXP_CONTAINS(lbl, r'(tco2|total|content|bicar|etco2|end[- ]?tidal)')\n",
    "),\n",
    "icu_class AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, charttime, val, uom, lbl,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\\\bph\\\\b') THEN 'ph'\n",
    "      WHEN (lbl LIKE '%pco2%' OR REGEXP_CONTAINS(lbl, r'\\\\bpa?\\\\s*co(?:2|₂)\\\\b')) THEN 'pco2'\n",
    "      ELSE NULL\n",
    "    END AS analyte,\n",
    "    CASE\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\\\b(abg|art|arterial|a[- ]?line)\\\\b') THEN 'arterial'\n",
    "      WHEN REGEXP_CONTAINS(lbl, r'\\\\b(vbg|ven|venous|mixed|central)\\\\b') THEN 'venous'\n",
    "      ELSE NULL\n",
    "    END AS site\n",
    "  FROM icu_cand\n",
    "),\n",
    "icu_pairs AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, charttime AS sample_time,\n",
    "    MAX(IF(analyte='ph',   val, NULL)) AS ph,\n",
    "    MAX(IF(analyte='pco2', val, NULL)) AS pco2_raw,\n",
    "    (ARRAY_AGG(IF(analyte='pco2', uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS pco2_uom,\n",
    "    (ARRAY_AGG(IF(analyte='ph',   uom, NULL) IGNORE NULLS LIMIT 1))[OFFSET(0)] AS ph_uom,\n",
    "    (ARRAY_AGG(site IGNORE NULLS LIMIT 1))[OFFSET(0)] AS site\n",
    "  FROM icu_class\n",
    "  GROUP BY hadm_id, stay_id, sample_time\n",
    "  HAVING ph IS NOT NULL AND pco2_raw IS NOT NULL AND site IN ('arterial','venous')\n",
    "),\n",
    "icu_pairs_std AS (\n",
    "  SELECT\n",
    "    hadm_id, stay_id, sample_time, site,\n",
    "    ph, ph_uom,\n",
    "    CASE WHEN pco2_uom='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END AS pco2_mmHg,\n",
    "    COALESCE(NULLIF(pco2_uom,''),'mmhg') AS pco2_uom_norm\n",
    "  FROM icu_pairs\n",
    "  WHERE ph BETWEEN 6.3 AND 7.8 AND (CASE WHEN pco2_uom='kpa' THEN pco2_raw*7.50062 ELSE pco2_raw END) BETWEEN 5 AND 200\n",
    "),\n",
    "poc_abg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph           AS poc_abg_ph,\n",
    "         ph_uom       AS poc_abg_ph_uom,\n",
    "         pco2_mmHg    AS poc_abg_paco2,\n",
    "         pco2_uom_norm AS poc_abg_paco2_uom,\n",
    "         sample_time  AS poc_abg_time\n",
    "  FROM (\n",
    "     SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "     FROM icu_pairs_std WHERE site='arterial'\n",
    "  ) WHERE rn=1\n",
    "),\n",
    "poc_vbg AS (\n",
    "  SELECT hadm_id,\n",
    "         ph           AS poc_vbg_ph,\n",
    "         ph_uom       AS poc_vbg_ph_uom,\n",
    "         pco2_mmHg    AS poc_vbg_paco2,\n",
    "         pco2_uom_norm AS poc_vbg_paco2_uom,\n",
    "         sample_time  AS poc_vbg_time\n",
    "  FROM (\n",
    "     SELECT *, ROW_NUMBER() OVER (PARTITION BY hadm_id ORDER BY sample_time) rn\n",
    "     FROM icu_pairs_std WHERE site='venous'\n",
    "  ) WHERE rn=1\n",
    ")\n",
    "\n",
    "/* --------------- Final one-row-per hadm --------------- */\n",
    "SELECT\n",
    "  h.hadm_id,\n",
    "  la.lab_abg_ph, la.lab_abg_ph_uom, la.lab_abg_paco2, la.lab_abg_paco2_uom, la.lab_abg_time,\n",
    "  lv.lab_vbg_ph, lv.lab_vbg_ph_uom, lv.lab_vbg_paco2, lv.lab_vbg_paco2_uom, lv.lab_vbg_time,\n",
    "  pa.poc_abg_ph, pa.poc_abg_ph_uom, pa.poc_abg_paco2, pa.poc_abg_paco2_uom, pa.poc_abg_time,\n",
    "  pv.poc_vbg_ph, pv.poc_vbg_ph_uom, pv.poc_vbg_paco2, pv.poc_vbg_paco2_uom, pv.poc_vbg_time\n",
    "FROM hadms h\n",
    "LEFT JOIN lab_abg la USING (hadm_id)\n",
    "LEFT JOIN lab_vbg lv USING (hadm_id)\n",
    "LEFT JOIN poc_abg pa USING (hadm_id)\n",
    "LEFT JOIN poc_vbg pv USING (hadm_id)\n",
    "\"\"\"\n",
    "bg_pairs = run_sql_bq(bg_pairs_sql, params)\n",
    "bg_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to legacy names (keep LAB-VBG as extra columns if you want them)\n",
    "rename_map = {\n",
    "    # LAB ABG -> legacy \"lab_*\"\n",
    "    \"lab_abg_paco2\":      \"lab_paco2\",\n",
    "    \"lab_abg_paco2_uom\":  \"lab_paco2_uom\",\n",
    "    \"lab_abg_time\":       \"abg_time\",\n",
    "    \"lab_abg_ph\":         \"lab_ph\",\n",
    "    \"lab_abg_ph_uom\":     \"lab_ph_uom\",\n",
    "\n",
    "    # POC ABG -> legacy \"poc_*\"\n",
    "    \"poc_abg_paco2\":      \"poc_paco2\",\n",
    "    \"poc_abg_paco2_uom\":  \"poc_paco2_uom\",\n",
    "    \"poc_abg_time\":       \"poc_paco2_time\",\n",
    "    \"poc_abg_ph\":         \"poc_ph\",\n",
    "    \"poc_abg_ph_uom\":     \"poc_ph_uom\",\n",
    "\n",
    "    # POC VBG -> legacy \"poc_vbg_*\" already matches; no rename needed\n",
    "}\n",
    "bg_pairs_legacy = bg_pairs.rename(columns=rename_map).copy()\n",
    "bg_pairs_legacy[\"poc_ph_time\"] = bg_pairs_legacy[\"poc_paco2_time\"]  # co-time for POC ABG analytes\n",
    "\n",
    "# Merge into master admission-level df\n",
    "assert \"hadm_id\" in df.columns, \"df must have 'hadm_id' before merge\"\n",
    "df = df.merge(bg_pairs_legacy, on=\"hadm_id\", how=\"left\")\n",
    "\n",
    "# Sanity checks: ranges (fail fast if wrong analyte lands in wrong column)\n",
    "def in_range(s, lo, hi): \n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.notna() & (s >= lo) & (s <= hi)\n",
    "\n",
    "ph_cols  = [c for c in [\"lab_ph\",\"poc_ph\",\"poc_vbg_ph\",\"lab_vbg_ph\"] if c in df.columns]\n",
    "co2_cols = [c for c in [\"lab_paco2\",\"poc_paco2\",\"poc_vbg_paco2\",\"lab_vbg_paco2\"] if c in df.columns]\n",
    "\n",
    "for c in ph_cols:\n",
    "    bad = (~in_range(df[c], 6.3, 7.8)).sum()\n",
    "    print(f\"{c} out-of-range (should be 6.3–7.8):\", bad)\n",
    "\n",
    "for c in co2_cols:\n",
    "    bad = (~in_range(df[c], 5, 200)).sum()\n",
    "    print(f\"{c} out-of-range (should be 5–200 mmHg):\", bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca780526",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"df has no 'hadm_id'. Make sure you're merging into the admission-level table.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n",
      "\u001b[32m      4\u001b[39m         df = df.reset_index()\n",
      "\u001b[32m      5\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdf has no \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhadm_id\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Make sure you\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre merging into the admission-level table.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Also ensure bg_pairs exists and has hadm_id before merge\u001b[39;00m\n",
      "\u001b[32m      9\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhadm_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m bg_pairs.columns, \u001b[33m\"\u001b[39m\u001b[33mbg_pairs is missing \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhadm_id\u001b[39m\u001b[33m'\u001b[39m\u001b[33m – check the SQL cell.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: \"df has no 'hadm_id'. Make sure you're merging into the admission-level table.\""
     ]
    }
   ],
   "source": [
    "# Ensure the master table really has hadm_id\n",
    "if \"hadm_id\" not in df.columns:\n",
    "    if df.index.name == \"hadm_id\":\n",
    "        df = df.reset_index()\n",
    "    else:\n",
    "        raise KeyError(\"df has no 'hadm_id'. Make sure you're merging into the admission-level table.\")\n",
    "\n",
    "# Also ensure bg_pairs exists and has hadm_id before merge\n",
    "assert \"hadm_id\" in bg_pairs.columns, \"bg_pairs is missing 'hadm_id' – check the SQL cell.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96850b68",
   "metadata": {},
   "source": [
    "The ones below this might be superfulous now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f83d3",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2da03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_base = f\"MIMIC_hypercap_bq_abg_vbg_{ts}\"\n",
    "\n",
    "df.to_parquet(out_base + \".parquet\", index=False)\n",
    "try:\n",
    "    import openpyxl  # noqa\n",
    "    df.to_excel(out_base + \".xlsx\", index=False)\n",
    "except Exception as e:\n",
    "    print(\"Excel write skipped (install openpyxl to enable):\", e)\n",
    "\n",
    "print(\"Wrote:\", out_base + \".parquet\")\n",
    "print(\"Wrote:\", out_base + \".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mimiciv-tabular)",
   "language": "python",
   "name": "mimiciv-tabular"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
